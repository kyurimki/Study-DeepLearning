{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7. 합성곱 신경망(CNN)\n",
    "## 7.4 합성곱/풀링 계층 구현하기\n",
    "### 7.4.1 4차원 배열\n",
    "- CNN에서 계층 사이를 흐르는 데이터는 4차원이다.\n",
    "- 데이터의 형상이 (10, 1, 28, 28) <=> 높이 28, 너비 28, 채널 1개인 데이터가 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1, 28, 28)\n",
      "(1, 28, 28)\n",
      "(1, 28, 28)\n",
      "[[1.57706991e-01 8.98790795e-01 2.85823534e-01 3.88399708e-01\n",
      "  3.97616408e-01 5.82295403e-03 4.01014326e-01 2.01369028e-01\n",
      "  6.04078238e-01 6.74973870e-02 1.75184591e-02 7.45330274e-01\n",
      "  9.71720675e-01 3.89880507e-01 6.18780812e-01 4.85203735e-03\n",
      "  9.06857282e-01 2.67967322e-01 3.77579264e-01 6.19436110e-01\n",
      "  5.52654982e-01 3.03512129e-01 5.11215356e-01 7.95906720e-01\n",
      "  5.40470088e-01 4.49971077e-01 9.00442884e-01 1.75352491e-01]\n",
      " [7.39450198e-01 4.09132582e-01 9.45678816e-01 2.93107265e-01\n",
      "  1.71237586e-01 4.49829835e-01 9.35450601e-01 5.60695852e-01\n",
      "  4.09550917e-02 1.44466644e-01 5.16126540e-01 6.30006943e-01\n",
      "  8.41747635e-01 5.29903597e-01 8.55798476e-01 8.25244792e-01\n",
      "  8.50611188e-01 3.85217912e-01 8.26812911e-01 6.65716483e-01\n",
      "  8.02429851e-01 5.01158439e-01 4.20492556e-01 2.17581679e-01\n",
      "  4.20369854e-01 3.46909870e-01 2.28514428e-01 7.16026350e-01]\n",
      " [3.35235909e-01 4.43435045e-01 8.50900704e-01 4.90644712e-01\n",
      "  2.79865589e-01 7.99747509e-01 6.55831163e-01 1.27276864e-01\n",
      "  9.68675961e-01 4.17140860e-01 4.92951390e-01 6.37078894e-01\n",
      "  1.01356489e-01 3.66328697e-01 3.57171604e-01 3.40886926e-01\n",
      "  5.43379153e-01 4.92081978e-01 4.14520253e-01 9.18133286e-01\n",
      "  8.89520911e-01 2.66328192e-01 1.59818852e-01 3.77767934e-02\n",
      "  3.45648852e-01 1.75872595e-01 2.46472130e-01 4.35653515e-01]\n",
      " [9.14259729e-01 3.04701787e-01 7.38033053e-01 2.69624744e-01\n",
      "  7.68299332e-01 3.41886986e-01 8.53362570e-01 8.63798207e-01\n",
      "  6.88976104e-01 2.15582429e-01 7.51368796e-01 7.51732243e-01\n",
      "  6.70986138e-01 2.10728956e-01 1.57403977e-01 5.25491750e-01\n",
      "  2.16073173e-01 7.73917279e-01 4.23697144e-01 4.83493642e-01\n",
      "  8.80123032e-01 9.02076593e-01 8.77574289e-01 5.16189344e-01\n",
      "  4.00055080e-01 7.93128893e-01 8.82892349e-01 2.38259612e-01]\n",
      " [6.74314535e-01 3.37723891e-01 2.13325564e-01 6.51390600e-01\n",
      "  5.70874845e-01 5.40025580e-01 6.21727388e-01 1.48356350e-01\n",
      "  2.78419922e-01 4.63812043e-01 1.42870111e-01 3.59359902e-01\n",
      "  8.90006809e-01 1.89022919e-01 8.66729241e-01 6.91447320e-01\n",
      "  3.81413719e-01 1.58707082e-01 1.09668728e-01 9.07439117e-01\n",
      "  9.92829031e-02 7.62804074e-01 9.58558862e-01 1.85595875e-01\n",
      "  8.15215022e-01 4.91757973e-01 1.27959198e-01 1.90587674e-01]\n",
      " [3.93442689e-02 2.78241880e-01 4.95385598e-01 3.73145812e-02\n",
      "  6.91357318e-01 7.67260173e-01 6.39552473e-02 9.61556702e-01\n",
      "  2.95662641e-01 3.49315446e-01 7.67755186e-01 2.63344278e-01\n",
      "  2.79181120e-01 1.38273106e-01 9.60687266e-01 1.35475744e-01\n",
      "  1.39904320e-01 8.05969232e-01 9.36502352e-01 4.74861946e-01\n",
      "  8.28908054e-02 6.35931019e-01 8.12951904e-01 7.98501442e-01\n",
      "  3.73271483e-01 5.07012213e-01 9.71537765e-01 8.58749141e-01]\n",
      " [5.51887124e-01 2.43222832e-01 5.93725551e-01 8.89760106e-01\n",
      "  4.76386355e-01 8.13799127e-02 7.15474098e-02 7.57205622e-01\n",
      "  7.53163079e-01 7.94914577e-01 6.01428620e-01 9.45057107e-02\n",
      "  7.56741772e-01 4.75321137e-01 6.33791459e-01 5.94444373e-01\n",
      "  6.09370289e-01 2.56236131e-02 8.81661360e-01 2.77193297e-02\n",
      "  7.77165302e-01 8.32437069e-01 2.38726233e-01 2.55543477e-01\n",
      "  4.72849511e-01 2.09716002e-01 2.35890723e-01 7.46476919e-01]\n",
      " [9.96201558e-01 2.93362627e-01 3.37539905e-01 3.39356283e-01\n",
      "  9.72704873e-01 6.59228625e-01 5.20817184e-01 8.98577279e-01\n",
      "  7.57785601e-01 3.43585434e-01 4.54585884e-01 7.47214874e-01\n",
      "  4.70247060e-02 6.22378002e-01 9.52979740e-01 5.40660192e-01\n",
      "  1.20523757e-01 4.64832183e-01 1.98674730e-01 8.62063032e-01\n",
      "  5.92277119e-01 2.00723985e-01 9.51083669e-01 8.90992597e-01\n",
      "  1.61345441e-01 4.81831805e-01 6.96016017e-01 4.11262119e-01]\n",
      " [8.76104623e-02 6.59314188e-01 9.58017482e-01 6.49628155e-01\n",
      "  1.44687731e-01 8.94542910e-02 5.84572929e-02 8.53197874e-01\n",
      "  7.07958809e-01 6.86910119e-01 2.83182453e-01 5.46817953e-01\n",
      "  8.60796451e-01 1.27479254e-01 5.72937006e-01 5.17965399e-01\n",
      "  6.50090934e-02 2.47465830e-01 7.39346291e-01 9.46798218e-01\n",
      "  2.15355963e-01 6.87462282e-01 2.80550772e-01 4.63078449e-01\n",
      "  5.14616431e-02 6.20616538e-01 2.73752968e-01 1.82374326e-01]\n",
      " [1.18056302e-01 2.62465799e-01 5.65467886e-01 1.78504690e-01\n",
      "  1.18034810e-01 4.88821489e-01 3.74177195e-01 7.43259586e-01\n",
      "  4.06744138e-01 9.04048808e-01 9.16621995e-01 2.43869895e-02\n",
      "  2.65848112e-01 1.11870223e-01 4.79663418e-01 1.04846197e-01\n",
      "  1.40691252e-01 5.55968472e-01 7.64847649e-01 2.72803879e-01\n",
      "  2.77024448e-02 4.81057793e-01 2.54479543e-01 3.47733753e-01\n",
      "  8.11967732e-01 4.05614619e-02 5.02750938e-01 4.91061496e-01]\n",
      " [4.80836094e-01 1.61758118e-01 2.45772963e-01 1.93012842e-01\n",
      "  5.53639006e-01 8.56380840e-01 5.55442130e-01 9.72690890e-01\n",
      "  7.84870177e-02 9.64450190e-01 9.51690971e-01 8.44027507e-01\n",
      "  1.85620670e-01 1.26759715e-01 5.88902404e-01 8.89562828e-01\n",
      "  9.03501972e-01 7.58671265e-01 1.12461747e-01 9.57700669e-01\n",
      "  9.83432079e-01 9.63966479e-01 4.41874663e-01 3.57202417e-01\n",
      "  4.33471692e-01 1.77796413e-01 5.30730659e-01 1.02791858e-01]\n",
      " [5.92993472e-04 3.47462170e-01 6.12249971e-01 1.57244338e-01\n",
      "  3.00400190e-01 4.86787984e-01 8.95272096e-01 5.03528637e-01\n",
      "  8.00602921e-01 2.24833050e-01 8.86874499e-02 7.30878613e-01\n",
      "  6.77830080e-01 9.27324067e-01 6.42169780e-01 7.35249288e-01\n",
      "  2.36179642e-01 9.86032602e-01 6.96686671e-01 7.41720697e-01\n",
      "  7.28416106e-01 9.87317087e-01 3.61517426e-01 6.06655649e-01\n",
      "  8.14392929e-01 5.45694074e-01 4.17199912e-01 3.77805910e-01]\n",
      " [1.74290820e-01 7.59723495e-02 1.96537342e-01 5.57872786e-01\n",
      "  7.77138071e-01 9.45463739e-02 7.93298923e-02 2.38689410e-01\n",
      "  2.50823339e-01 7.73899231e-01 1.57793988e-01 2.11522756e-01\n",
      "  2.68083466e-01 3.39597950e-01 2.49814113e-01 7.60403540e-01\n",
      "  3.92310020e-01 7.50974684e-01 1.99008443e-01 1.25583664e-01\n",
      "  3.26149962e-01 8.84659242e-01 3.09164141e-01 2.90837656e-01\n",
      "  4.00785999e-01 3.05373242e-01 8.40364188e-01 5.48890091e-01]\n",
      " [2.66094529e-01 4.45397741e-01 1.09483213e-01 1.47464783e-01\n",
      "  6.10265740e-01 8.31600540e-01 3.63223385e-02 5.65926662e-01\n",
      "  2.99190320e-01 6.41596679e-01 3.94302613e-02 1.55919476e-01\n",
      "  8.90520304e-01 7.68937860e-01 7.03742864e-01 7.49752635e-01\n",
      "  7.16521567e-01 1.09590565e-01 2.86975887e-01 8.97094960e-01\n",
      "  3.44251038e-01 9.63023366e-01 4.65251597e-01 3.94186015e-01\n",
      "  3.24021361e-02 3.30196785e-01 3.01945404e-01 8.43143118e-01]\n",
      " [9.42258120e-01 4.22725995e-01 3.23558177e-01 9.51776250e-01\n",
      "  6.16251396e-01 8.41678447e-02 4.50782774e-01 8.54255796e-01\n",
      "  1.63633675e-01 8.31046781e-02 5.89659862e-01 7.21630703e-02\n",
      "  1.80788619e-01 7.12219334e-01 2.00926240e-01 5.23270720e-01\n",
      "  3.31050081e-02 9.35583871e-01 7.05940886e-01 2.21199541e-01\n",
      "  9.59513086e-02 8.16017595e-01 6.43906179e-01 9.18472161e-01\n",
      "  6.48652707e-01 8.82266399e-01 8.55619491e-01 5.99005286e-01]\n",
      " [1.77276815e-01 9.11077363e-01 7.66873491e-01 9.41849577e-01\n",
      "  2.50533067e-01 4.31365706e-02 6.28033089e-01 3.42390076e-01\n",
      "  2.44428632e-01 3.87419526e-02 9.84744418e-01 1.95215811e-02\n",
      "  4.10211020e-01 1.26322281e-01 9.33935457e-01 3.72227641e-01\n",
      "  7.92064254e-01 8.91832045e-01 1.54516789e-01 8.23066654e-01\n",
      "  7.90213078e-01 9.81575380e-01 3.20757294e-01 7.85056875e-01\n",
      "  2.92094667e-01 2.03464957e-01 8.42080082e-01 4.96769339e-01]\n",
      " [1.84499234e-01 1.39401306e-01 2.87270711e-01 8.10400305e-01\n",
      "  8.33800767e-01 7.35687660e-01 2.70831875e-01 3.31116532e-01\n",
      "  7.86996719e-01 1.98697628e-01 5.93515778e-01 3.86652797e-01\n",
      "  6.82219597e-01 8.90118749e-01 1.51921213e-01 4.22738999e-01\n",
      "  9.22710958e-01 8.86358930e-01 5.51024414e-02 3.90007644e-01\n",
      "  5.27261931e-01 7.23862496e-01 6.71040252e-01 3.30158080e-01\n",
      "  9.00394393e-01 7.35070409e-01 9.50725370e-01 4.09644909e-01]\n",
      " [3.65611620e-01 7.22709428e-01 3.78122341e-01 1.22777487e-01\n",
      "  6.73791156e-02 1.13046882e-01 1.52387355e-01 9.97033156e-01\n",
      "  9.66437103e-01 1.88598800e-01 3.52979037e-01 2.92680186e-01\n",
      "  8.63241378e-01 5.51968126e-01 9.49679472e-01 2.68153101e-01\n",
      "  4.26219177e-01 1.62998629e-01 9.82722235e-02 8.18060140e-01\n",
      "  7.72578667e-01 1.39731843e-01 3.82686760e-01 2.10494143e-01\n",
      "  7.48248890e-01 3.59199179e-01 1.79934299e-01 4.36893635e-01]\n",
      " [9.35426430e-01 1.71218563e-01 4.08348807e-01 1.53457977e-01\n",
      "  2.73497787e-01 7.62948965e-01 2.64653918e-01 4.44841032e-02\n",
      "  5.44738954e-01 8.13105164e-02 7.88603514e-01 4.57565635e-02\n",
      "  2.06490029e-02 4.99943222e-01 7.46470790e-01 7.54377418e-01\n",
      "  4.70068173e-01 3.67188774e-01 6.54931654e-01 2.15750851e-01\n",
      "  4.43389711e-01 6.97309278e-01 8.72178649e-01 1.76832559e-01\n",
      "  2.56331246e-01 4.80491140e-01 8.96940824e-01 8.36192057e-01]\n",
      " [4.40709324e-01 5.43737530e-01 7.80366851e-01 7.06476581e-01\n",
      "  9.62503053e-01 1.32791095e-01 6.34345708e-01 6.07058683e-01\n",
      "  8.03845145e-02 5.21746779e-01 6.45059716e-01 5.82738354e-01\n",
      "  8.61970159e-01 1.37996064e-01 8.06410714e-01 5.36947625e-01\n",
      "  6.10809624e-01 8.91560718e-01 5.75144892e-01 8.50476353e-01\n",
      "  5.10455843e-01 7.20168756e-01 4.02519462e-01 7.43075815e-02\n",
      "  7.60772393e-01 1.77025043e-01 5.17873094e-01 4.36717824e-01]\n",
      " [5.74445214e-02 7.26700136e-01 6.76514542e-01 3.94646680e-02\n",
      "  7.12431051e-01 2.49003831e-02 8.54620752e-01 8.39410884e-01\n",
      "  2.13756002e-01 4.72826175e-02 8.83024005e-01 8.46942662e-01\n",
      "  9.43497924e-02 3.01518208e-01 6.59509386e-01 6.27785726e-01\n",
      "  4.65704491e-02 5.09733627e-01 8.57769726e-01 6.30934090e-01\n",
      "  8.64051309e-01 5.08729397e-02 3.59336972e-01 2.67950884e-01\n",
      "  2.11740369e-01 4.87921264e-01 9.50220649e-01 7.93031009e-01]\n",
      " [2.40800293e-01 7.64147724e-01 5.79286685e-01 7.43927139e-01\n",
      "  1.02664969e-01 8.98757346e-01 4.95143335e-01 6.13559639e-01\n",
      "  2.72054937e-01 6.06486416e-01 8.07758002e-01 5.68072693e-01\n",
      "  6.35812236e-01 8.99826062e-01 9.99628012e-01 4.53251889e-01\n",
      "  9.32396617e-02 7.24685118e-01 8.08338961e-01 8.45515982e-01\n",
      "  1.64444559e-01 9.00882790e-01 3.38911280e-02 4.21112807e-01\n",
      "  9.38178508e-01 3.41780055e-01 2.49070695e-01 3.96164082e-01]\n",
      " [4.19836506e-01 2.62837935e-01 6.21845394e-01 4.06668196e-02\n",
      "  7.38074968e-01 8.05825255e-02 7.29466983e-01 1.40274088e-01\n",
      "  9.00371388e-01 8.54891862e-01 8.77846508e-01 1.09740878e-01\n",
      "  6.11596277e-01 5.62646191e-01 6.91522177e-01 7.06362813e-01\n",
      "  4.11085934e-02 2.44502377e-01 2.07077283e-01 6.54264238e-01\n",
      "  2.14096755e-01 6.77330710e-01 2.88301788e-01 2.56835840e-01\n",
      "  7.90309852e-01 7.65816936e-01 5.34876814e-01 4.40063693e-01]\n",
      " [7.98935196e-01 3.40591801e-01 9.03970334e-01 3.89995799e-01\n",
      "  3.61052750e-01 1.08257091e-02 5.62570772e-01 2.32869198e-03\n",
      "  3.31708560e-01 4.64611324e-02 3.06124324e-01 2.50969007e-01\n",
      "  4.03945325e-01 4.22915461e-01 8.34262481e-02 9.47557740e-01\n",
      "  8.24451351e-01 5.60857414e-01 5.90972842e-01 3.75452849e-01\n",
      "  2.02305074e-01 7.01200898e-01 1.51193161e-01 4.07313484e-01\n",
      "  8.43268374e-01 4.61897131e-01 2.12357559e-01 4.61200275e-01]\n",
      " [3.83570509e-01 8.05065178e-01 4.60453496e-01 2.12850289e-01\n",
      "  5.56921973e-01 9.27720743e-01 6.72597574e-02 6.32304776e-01\n",
      "  9.69367292e-01 6.76702091e-02 1.12333502e-01 3.70447196e-01\n",
      "  6.91948279e-02 3.71364558e-01 8.37011032e-01 4.13010076e-01\n",
      "  2.93211931e-02 7.67040027e-01 7.68063397e-01 1.57562227e-01\n",
      "  5.65609235e-01 7.59970970e-01 1.22636587e-01 6.68950791e-01\n",
      "  4.43592001e-01 4.48751365e-01 3.33254163e-02 4.32646712e-01]\n",
      " [7.29547333e-01 9.83131892e-01 6.41730158e-01 1.81040919e-01\n",
      "  8.73407081e-01 6.29652054e-01 5.74258190e-01 4.80383669e-01\n",
      "  8.91680566e-01 9.52919309e-01 7.18285811e-01 1.25141668e-01\n",
      "  3.73473284e-01 9.93524062e-01 2.88814201e-01 3.71157250e-01\n",
      "  5.49759211e-01 6.82335897e-01 3.35167996e-01 4.06871815e-01\n",
      "  8.52663806e-01 5.95138717e-01 2.67635304e-01 9.31275967e-01\n",
      "  6.48438198e-01 8.42841865e-01 6.81679092e-01 3.58646177e-01]\n",
      " [5.02228293e-01 5.24345169e-01 5.61287853e-01 9.70719111e-01\n",
      "  4.87196379e-01 9.79265507e-01 7.56287436e-01 8.23612121e-01\n",
      "  1.63665717e-01 9.95359126e-01 2.32847760e-01 7.44398718e-01\n",
      "  2.30088054e-01 8.35339228e-01 6.70150617e-01 6.45188789e-01\n",
      "  3.77373192e-01 9.75806487e-01 5.90223615e-01 8.04245980e-01\n",
      "  2.89983804e-01 7.90022365e-01 8.68441436e-01 1.56145933e-01\n",
      "  3.76379665e-01 5.14863360e-02 4.21760768e-01 5.49468485e-01]\n",
      " [9.39506150e-02 8.19068380e-01 9.53833235e-01 1.82371819e-01\n",
      "  3.32899436e-01 5.03655891e-02 2.84138475e-01 5.63225857e-01\n",
      "  8.96729341e-01 6.22620978e-01 7.67057578e-01 3.48586101e-01\n",
      "  6.71541791e-01 2.21639476e-01 2.52369415e-01 2.79201823e-01\n",
      "  1.27393527e-01 8.85842110e-01 1.87659202e-01 9.01052447e-01\n",
      "  7.44997344e-01 9.31602741e-01 1.41594665e-01 3.83608154e-01\n",
      "  8.08034651e-01 2.77757743e-01 4.94632198e-01 4.02348247e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(10, 1, 28, 28)  # 무작위로 데이터 생성\n",
    "print(x.shape)\n",
    "\n",
    "# 10개 중 1, 2번째 데이터 접근\n",
    "print(x[0].shape)\n",
    "print(x[1].shape)\n",
    "\n",
    "# 1번째 데이터의 첫 채널의 공간 데이터 접근\n",
    "print(x[0, 0])  # x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 im2col로 데이터 전개하기\n",
    "- 합성곱 연산에서 for문을 중첩해 사용하면 성능이 떨어진다는 단점 -> for문 대신 im2col 사용\n",
    "- **im2col**\n",
    "    - 입력 데이터를 필터링(가중치 계산) 하기 좋게 전개하는 함수\n",
    "    - 입력 데이터에서 필터를 적용하는 영역을 한 줄로 늘어놓는다. 이 전개를 모든 영역에서 수행\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/61455647/116519890-fa5c8080-a90c-11eb-9831-6b8531b59716.png)\n",
    "\n",
    "- 예시에서는 스트라이드를 크게 잡아 필터의 적용 영역이 겹치지 않았지만, 실제로는 겹치는 경우가 많다. 필터 적용 영역이 겹치면 im2col로 전개한 후 원소 수가 원래 블록의 원소 수보다 많아진다. -> 메모리를 더 많이 사용한다는 단점이 있지만, 컴퓨터는 큰 행렬을 묶어 계산하는 데 탁월하기 때문에 행렬 계산으로 만들면 선형 대수 라이브러리로 효율을 높일 수 있다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/61455647/116534150-241da380-a91d-11eb-8967-7eea526e1fb1.png)\n",
    "\n",
    "- 합성곱 연산의 필터 처리 과정: 필터를 세로로 1열로 전개하고, im2col이 전개한 데이터와 행렬 곱을 계산해 출력 데이터를 reshape\n",
    "\n",
    "### 7.4.3 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `im2col(input_data, filter_h, filter_w, stride=1, pad=0)`:\n",
    "    - `input_data`: (데이터 수, 채널 수, 높이, 너비)의 4차원 배열로 이루어진 입력 데이터\n",
    "    - `filter_h`: 필터의 높이\n",
    "    - `filter_w`: 필터의 너비\n",
    "    - `stride`: 스트라이드\n",
    "    - `pad`: 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7)  # (데이터 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7)  # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1번째 예시: 배치 크기가 1, 채널 3개, 높이/너비가 7*7인 데이터\n",
    "- 2번째 예시: 배치 크기가 10, 채널 3개, 높이/너비가 7*7인 데이터\n",
    "- im2col 함수를 적용했을 때 2번째 차원의 원소는 75개 = 필터의 원소 수(채널 3개, 5*5 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T  # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필터 `(FN, C, FH, FW)`: (필터 개수, 채널, 필터 높이, 필터 너비)\n",
    "- `col = im2col(x, FH, FW, self.stride, self.pad)`~`out = np.dot(col, col_W) + self.b`\n",
    "    - 입력 데이터를 `im2col`로 전개 -> 필터도 `reshape()`로 2차원 배열로 전개 -> 전개한 두 행렬의 곱\n",
    "    - `reshape( , -1)`: 다차원 배열의 원소 수가 변환 후에도 똑같이 유지되도록 적절히 묶음\n",
    "- `transpose()`: 다차원 배열의 축 순서를 바꿔주는 함수, 인덱스를 지정하여 축의 순서 변경\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/61455647/116537604-6a750180-a921-11eb-84b2-5fdd002b39f4.png)\n",
    "\n",
    "- 합성곱 계층의 역전파는 Affine 계층과 똑같지만, `im2col`을 역으로 처리해야 한다. -> `col2im` 함수 사용\n",
    "\n",
    "### 7.4.4 풀링 계층 구현하기\n",
    "- 풀링은 채널이 독립적이라는 점이 합성곱 계층 때와 다르다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/61455647/116538055-0141be00-a922-11eb-94b2-c9ad878fb4cb.png)\n",
    "\n",
    "- 입력 데이터의 풀링 적용 영역을 전개한 후 행렬에서 행별 최대값을 구하고, 적절한 형상으로 성형하면 된다.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/61455647/116538262-4239d280-a922-11eb-8b4d-8632af95ecb0.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 1. 전개\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "        \n",
    "        # 2. 최대값\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 3. 성형\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 풀링 계층 구현 단계\n",
    "    1. 입력 데이터를 전개한다.\n",
    "    2. 행별 최대값을 구한다.\n",
    "    3. 적절한 모양으로 성형한다.\n",
    "- `np.max(x, axis=1)`: 입력 x의 1번째 차원의 축마다 최대값\n",
    "\n",
    "## 7.5 CNN 구현하기\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/61455647/116541855-f178a880-a926-11eb-93e2-53c936024ba1.png)\n",
    "\n",
    "- Convolution-ReLU-Pooling-Affine-ReLU-Affine-Softmax 순의 CNN 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.layers import *\n",
    "from collections import OrderedDict\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28), conv_param={'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1}, hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        # 하이퍼파라미터를 딕셔너리에서 꺼내고 합성곱 계층의 출력 크기 계산\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2 * filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size / 2) * (conv_output_size / 2))\n",
    "        \n",
    "        # 가중치 매개변수 초기화\n",
    "        self.params = {}\n",
    "        # 1번째 계층: 합성곱 계층\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        # 2, 3번째 계층: 완전연결 계층\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'], conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    # 오차역전파법으로 기울기 구하기\n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "        \n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "        \n",
    "        return grads\n",
    "    \n",
    "    # 출처: https://github.com/oreilly-japan/deep-learning-from-scratch/blob/5aebd992ef70f8e0caa1036045eff53ce801e16b/ch07/simple_convnet.py\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 초기화 때 받는 인수\n",
    "    - `input_dim`: 입력 데이터(채널 수, 높이, 너비)의 차원\n",
    "    - `conv_param`: 합성곱 계층의 하이퍼파라미터(딕셔너리)\n",
    "        - `filter_num`: 필터 수\n",
    "        - `filter_size`: 필터 크기\n",
    "        - `stride`: 스트라이드\n",
    "        - `pad`: 패딩\n",
    "    - `hidden_size`: 은닉층(완전연결)의 뉴런 수\n",
    "    - `output_size`: 출력층(완전연결)의 뉴런 수\n",
    "    - `weight_init_std`: 초기화 때의 가중치 표준편차\n",
    "- `predict()`: 추론 수행, 초기화 때 `layers`에 추가한 계층을 맨 앞에서부터 차례로 `forward()`를 호출해 결과를 다음 계층에 전달\n",
    "- `loss()`\n",
    "    - 손실 함수\n",
    "    - `predict()`의 결과를 인수로 마지막 층의 `forward()` 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3001593827322955\n",
      "=== epoch:1, train acc:0.285, test acc:0.281 ===\n",
      "train loss:2.2979991193891145\n",
      "train loss:2.2924430551858803\n",
      "train loss:2.2866418021868675\n",
      "train loss:2.272355069154025\n",
      "train loss:2.258468138514817\n",
      "train loss:2.2518315732674274\n",
      "train loss:2.237582805636147\n",
      "train loss:2.2200888431724835\n",
      "train loss:2.1726844083606744\n",
      "train loss:2.1325225975488085\n",
      "train loss:2.115424308453094\n",
      "train loss:2.0273107230233887\n",
      "train loss:1.9407961304463308\n",
      "train loss:1.9761550038615954\n",
      "train loss:1.8523726594079257\n",
      "train loss:1.7164817842069817\n",
      "train loss:1.7214057722302811\n",
      "train loss:1.6965727668626167\n",
      "train loss:1.4335727056417829\n",
      "train loss:1.5669094123072689\n",
      "train loss:1.4489663279197647\n",
      "train loss:1.3099586352003703\n",
      "train loss:1.1415367056116978\n",
      "train loss:1.1368459309609336\n",
      "train loss:1.068221663050502\n",
      "train loss:1.130721353428072\n",
      "train loss:0.9160238691583515\n",
      "train loss:1.0744887308160374\n",
      "train loss:0.9028979186853111\n",
      "train loss:0.8561687144978875\n",
      "train loss:0.7602709477787275\n",
      "train loss:0.7998148232769906\n",
      "train loss:0.7299217181512947\n",
      "train loss:0.7905525352054006\n",
      "train loss:0.6191811938273074\n",
      "train loss:0.657352098394337\n",
      "train loss:0.9096859953675553\n",
      "train loss:0.6858851346723737\n",
      "train loss:0.5723807954891211\n",
      "train loss:0.9428924161699647\n",
      "train loss:0.683119739986949\n",
      "train loss:0.5908012084258243\n",
      "train loss:0.5595572135246885\n",
      "train loss:0.6319237211864401\n",
      "train loss:0.443698101944575\n",
      "train loss:0.511829146664868\n",
      "train loss:0.6352233547152494\n",
      "train loss:0.6192683761920412\n",
      "train loss:0.6753778742993495\n",
      "train loss:0.4861968014650228\n",
      "train loss:0.4849361691438624\n",
      "train loss:0.5761163712837138\n",
      "train loss:0.6621392785715432\n",
      "train loss:0.5424324354205579\n",
      "train loss:0.44330712726096044\n",
      "train loss:0.5812182291994432\n",
      "train loss:0.4763280809423053\n",
      "train loss:0.4504182764152671\n",
      "train loss:0.42610262854318165\n",
      "train loss:0.5136157010669973\n",
      "train loss:0.46999062244184364\n",
      "train loss:0.32575392550549614\n",
      "train loss:0.3394469449763846\n",
      "train loss:0.40967384074544044\n",
      "train loss:0.3505684424769286\n",
      "train loss:0.5563000977135812\n",
      "train loss:0.2872685516081459\n",
      "train loss:0.3739203599904532\n",
      "train loss:0.6267717541121857\n",
      "train loss:0.3715029265694367\n",
      "train loss:0.43213571977418425\n",
      "train loss:0.36370956033068497\n",
      "train loss:0.35168176288685193\n",
      "train loss:0.4148459806683221\n",
      "train loss:0.47260110797225957\n",
      "train loss:0.5389117523611189\n",
      "train loss:0.44557912022115803\n",
      "train loss:0.40373418877624706\n",
      "train loss:0.4636368095688999\n",
      "train loss:0.32011095613207646\n",
      "train loss:0.3448470364252985\n",
      "train loss:0.6030253495548881\n",
      "train loss:0.28726325504400874\n",
      "train loss:0.35530499263254056\n",
      "train loss:0.4637524618601095\n",
      "train loss:0.48412514889697994\n",
      "train loss:0.43517849651104357\n",
      "train loss:0.38076579879451505\n",
      "train loss:0.46910014832675223\n",
      "train loss:0.36247518080946634\n",
      "train loss:0.46549342563203133\n",
      "train loss:0.42680865908031285\n",
      "train loss:0.18654626350898673\n",
      "train loss:0.4707620372668104\n",
      "train loss:0.3701230602996695\n",
      "train loss:0.296107984965783\n",
      "train loss:0.33323912557592905\n",
      "train loss:0.3669877846610012\n",
      "train loss:0.4060547380830692\n",
      "train loss:0.2971405185134575\n",
      "train loss:0.2662025330692089\n",
      "train loss:0.31716751040041186\n",
      "train loss:0.3628350612853306\n",
      "train loss:0.20134633975867178\n",
      "train loss:0.3235983596774307\n",
      "train loss:0.38135382057562156\n",
      "train loss:0.30049941717545364\n",
      "train loss:0.3279596858540518\n",
      "train loss:0.3654494974272047\n",
      "train loss:0.29581812372296556\n",
      "train loss:0.2924792413266273\n",
      "train loss:0.46721046928368637\n",
      "train loss:0.3774171747430614\n",
      "train loss:0.3931016685679185\n",
      "train loss:0.2822175520058066\n",
      "train loss:0.2681490280569051\n",
      "train loss:0.29423470880362534\n",
      "train loss:0.4494128526256833\n",
      "train loss:0.308658536684232\n",
      "train loss:0.4420395443588039\n",
      "train loss:0.27131590551540213\n",
      "train loss:0.2620665343078121\n",
      "train loss:0.3843555217160881\n",
      "train loss:0.34324662430208647\n",
      "train loss:0.40992288487621376\n",
      "train loss:0.40240848273503105\n",
      "train loss:0.25572066651385567\n",
      "train loss:0.32309835857449626\n",
      "train loss:0.23902108818490525\n",
      "train loss:0.3227516816529316\n",
      "train loss:0.23716215280611738\n",
      "train loss:0.32661442597302537\n",
      "train loss:0.33932654317481586\n",
      "train loss:0.2962587179563794\n",
      "train loss:0.5079654687189911\n",
      "train loss:0.3090248042406335\n",
      "train loss:0.27468820825371615\n",
      "train loss:0.22794845931037588\n",
      "train loss:0.3245354650980339\n",
      "train loss:0.22318691807505042\n",
      "train loss:0.2614342303141547\n",
      "train loss:0.24538023958049798\n",
      "train loss:0.2277316796075669\n",
      "train loss:0.29769424798492106\n",
      "train loss:0.211609709814458\n",
      "train loss:0.17353321255329285\n",
      "train loss:0.28266643840054884\n",
      "train loss:0.1518501443322246\n",
      "train loss:0.3528567825363943\n",
      "train loss:0.2285864343119631\n",
      "train loss:0.2786954685579583\n",
      "train loss:0.2158321750116177\n",
      "train loss:0.37329521248063213\n",
      "train loss:0.3943197833367434\n",
      "train loss:0.21573144704723698\n",
      "train loss:0.35804072622813665\n",
      "train loss:0.39688174640258994\n",
      "train loss:0.25981289511363964\n",
      "train loss:0.4046332534234949\n",
      "train loss:0.441433207561302\n",
      "train loss:0.18018778456676848\n",
      "train loss:0.35195626663595897\n",
      "train loss:0.2710823137357546\n",
      "train loss:0.2565757761647113\n",
      "train loss:0.37972404328428927\n",
      "train loss:0.4195131509161345\n",
      "train loss:0.4179231332433983\n",
      "train loss:0.18376325961799922\n",
      "train loss:0.3049997504600149\n",
      "train loss:0.25411101528281077\n",
      "train loss:0.24585564211804642\n",
      "train loss:0.1933228091957766\n",
      "train loss:0.4786610551166598\n",
      "train loss:0.13952614600944988\n",
      "train loss:0.33881582642093155\n",
      "train loss:0.325164345033214\n",
      "train loss:0.22197304409523005\n",
      "train loss:0.2884743089021196\n",
      "train loss:0.37625789565436835\n",
      "train loss:0.19454344844012902\n",
      "train loss:0.3462588966142501\n",
      "train loss:0.33052295534143666\n",
      "train loss:0.3169177295884941\n",
      "train loss:0.31613491828153384\n",
      "train loss:0.22621785063548736\n",
      "train loss:0.2060839424798455\n",
      "train loss:0.20071930638001179\n",
      "train loss:0.1839624049385366\n",
      "train loss:0.2379036433105922\n",
      "train loss:0.24978397810267428\n",
      "train loss:0.23062002933964268\n",
      "train loss:0.32159966879730206\n",
      "train loss:0.2205192560812673\n",
      "train loss:0.2659059972330509\n",
      "train loss:0.27687827656544217\n",
      "train loss:0.29015454472695834\n",
      "train loss:0.2920393950719979\n",
      "train loss:0.2446526919392577\n",
      "train loss:0.26968620174032376\n",
      "train loss:0.13770677348100413\n",
      "train loss:0.18356119739044924\n",
      "train loss:0.14326716248965282\n",
      "train loss:0.3546533175090879\n",
      "train loss:0.24387449900355118\n",
      "train loss:0.1817177390210251\n",
      "train loss:0.4154161121435014\n",
      "train loss:0.2150816571657253\n",
      "train loss:0.406645778686954\n",
      "train loss:0.2470224358379555\n",
      "train loss:0.277992899301694\n",
      "train loss:0.2634316755907291\n",
      "train loss:0.292975722778808\n",
      "train loss:0.1536265882055043\n",
      "train loss:0.4388974059953906\n",
      "train loss:0.19656368476263755\n",
      "train loss:0.26972597509737356\n",
      "train loss:0.20241457158795848\n",
      "train loss:0.257217812089112\n",
      "train loss:0.23565788543660204\n",
      "train loss:0.47271249765112544\n",
      "train loss:0.2674574121944058\n",
      "train loss:0.23808764211733238\n",
      "train loss:0.27047382049074736\n",
      "train loss:0.3295362410604545\n",
      "train loss:0.16693092353293967\n",
      "train loss:0.14340857676844398\n",
      "train loss:0.18711979777892151\n",
      "train loss:0.4300380391839965\n",
      "train loss:0.23128767793769384\n",
      "train loss:0.19141461090905726\n",
      "train loss:0.24534277494182624\n",
      "train loss:0.2975904650169052\n",
      "train loss:0.15078154876823763\n",
      "train loss:0.18027064910348434\n",
      "train loss:0.26445256523396526\n",
      "train loss:0.2707472808364376\n",
      "train loss:0.2167573414568243\n",
      "train loss:0.2907743184764788\n",
      "train loss:0.2648222238910694\n",
      "train loss:0.32247152559527253\n",
      "train loss:0.2864075290540644\n",
      "train loss:0.22330123195327858\n",
      "train loss:0.1689363649289749\n",
      "train loss:0.22087145032135666\n",
      "train loss:0.16194698827468243\n",
      "train loss:0.20787871000813618\n",
      "train loss:0.24382952817757667\n",
      "train loss:0.2602871122124808\n",
      "train loss:0.25954776352855763\n",
      "train loss:0.17794210696574297\n",
      "train loss:0.1936606972097258\n",
      "train loss:0.12229665777695173\n",
      "train loss:0.2988081594164987\n",
      "train loss:0.15400492379571434\n",
      "train loss:0.22310966390539996\n",
      "train loss:0.2585830776165246\n",
      "train loss:0.27785444917529484\n",
      "train loss:0.3117598603800371\n",
      "train loss:0.16489565524092328\n",
      "train loss:0.3852456830418955\n",
      "train loss:0.17426318059112092\n",
      "train loss:0.2952126451366544\n",
      "train loss:0.18812435685741152\n",
      "train loss:0.21838871261873627\n",
      "train loss:0.1527315696468326\n",
      "train loss:0.24860976770327536\n",
      "train loss:0.25488702174581834\n",
      "train loss:0.24826960889615773\n",
      "train loss:0.1867415710292521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.21012679369256926\n",
      "train loss:0.285254175200184\n",
      "train loss:0.08985662886893943\n",
      "train loss:0.2514688781724496\n",
      "train loss:0.18164228389083148\n",
      "train loss:0.28909485291595477\n",
      "train loss:0.3470078426810035\n",
      "train loss:0.25508262779279905\n",
      "train loss:0.24373895596549794\n",
      "train loss:0.2244734632156435\n",
      "train loss:0.1806336267092618\n",
      "train loss:0.12666321364645294\n",
      "train loss:0.07066955790102683\n",
      "train loss:0.25582447785734513\n",
      "train loss:0.12248962976781617\n",
      "train loss:0.2556789521087834\n",
      "train loss:0.23995991154550073\n",
      "train loss:0.20988265304984238\n",
      "train loss:0.3230951203746133\n",
      "train loss:0.1561503253663963\n",
      "train loss:0.29685409498373133\n",
      "train loss:0.31536049072775096\n",
      "train loss:0.10803006790225192\n",
      "train loss:0.2247211533173582\n",
      "train loss:0.20672874235231403\n",
      "train loss:0.24696681067798262\n",
      "train loss:0.20947823964228857\n",
      "train loss:0.36025152672706007\n",
      "train loss:0.16940577199351017\n",
      "train loss:0.18381334967891338\n",
      "train loss:0.20400557309275397\n",
      "train loss:0.24267343314714399\n",
      "train loss:0.12724429422082384\n",
      "train loss:0.1366608785367824\n",
      "train loss:0.272571005202488\n",
      "train loss:0.1343127961321613\n",
      "train loss:0.1699332865601313\n",
      "train loss:0.21430012511612873\n",
      "train loss:0.14982234498423216\n",
      "train loss:0.1920458523291388\n",
      "train loss:0.19169405585091365\n",
      "train loss:0.1842504680683605\n",
      "train loss:0.13429778246248783\n",
      "train loss:0.19774428372491656\n",
      "train loss:0.21375259222662443\n",
      "train loss:0.2698543146077238\n",
      "train loss:0.10038743738296443\n",
      "train loss:0.20840543461914904\n",
      "train loss:0.15274255095790842\n",
      "train loss:0.14876780839200707\n",
      "train loss:0.2877347793348696\n",
      "train loss:0.24546907593100026\n",
      "train loss:0.23820617450147583\n",
      "train loss:0.19733463817678204\n",
      "train loss:0.3177779303824102\n",
      "train loss:0.26682158233636877\n",
      "train loss:0.1857647132446678\n",
      "train loss:0.2042724036268547\n",
      "train loss:0.25521563625903193\n",
      "train loss:0.1788938024791214\n",
      "train loss:0.12490094281121031\n",
      "train loss:0.22842057034346402\n",
      "train loss:0.09055533965390004\n",
      "train loss:0.1733547016318399\n",
      "train loss:0.24559533764021432\n",
      "train loss:0.21103916097393063\n",
      "train loss:0.1984235582331419\n",
      "train loss:0.1540678735227771\n",
      "train loss:0.09194606441091911\n",
      "train loss:0.3602238809085038\n",
      "train loss:0.23856026208986766\n",
      "train loss:0.2706160704489162\n",
      "train loss:0.2143242943038182\n",
      "train loss:0.20969667144254184\n",
      "train loss:0.14691904718298068\n",
      "train loss:0.21580802198718005\n",
      "train loss:0.20491564173302623\n",
      "train loss:0.3258310407650608\n",
      "train loss:0.13407267206226245\n",
      "train loss:0.13954364295921018\n",
      "train loss:0.21843758912571\n",
      "train loss:0.10326633611603178\n",
      "train loss:0.1260825218300619\n",
      "train loss:0.18742354674220615\n",
      "train loss:0.13067597037140474\n",
      "train loss:0.13010748033744235\n",
      "train loss:0.1639160272752644\n",
      "train loss:0.08734195963453556\n",
      "train loss:0.28258766438126515\n",
      "train loss:0.11050940610400853\n",
      "train loss:0.11646174539817816\n",
      "train loss:0.20173613541680552\n",
      "train loss:0.1330989420254854\n",
      "train loss:0.19826279927270832\n",
      "train loss:0.17479883845198882\n",
      "train loss:0.09091866087381931\n",
      "train loss:0.20596547327196874\n",
      "train loss:0.15784057077079758\n",
      "train loss:0.18341608479883395\n",
      "train loss:0.09624210935135387\n",
      "train loss:0.3018141002505424\n",
      "train loss:0.1867964172900874\n",
      "train loss:0.1331850515131698\n",
      "train loss:0.07657168171720369\n",
      "train loss:0.09548350821304745\n",
      "train loss:0.06768806403774755\n",
      "train loss:0.2400060360440639\n",
      "train loss:0.10083586110575879\n",
      "train loss:0.18361757142982632\n",
      "train loss:0.1409362441207124\n",
      "train loss:0.1625952323830238\n",
      "train loss:0.13454609064578277\n",
      "train loss:0.10721890332058569\n",
      "train loss:0.09690245450800199\n",
      "train loss:0.11418345920020409\n",
      "train loss:0.18256455527605964\n",
      "train loss:0.2778478834375197\n",
      "train loss:0.24823759623827685\n",
      "train loss:0.21409236528904427\n",
      "train loss:0.10340091444662294\n",
      "train loss:0.11958852624895626\n",
      "train loss:0.13381615731452412\n",
      "train loss:0.11783180555273988\n",
      "train loss:0.20126047106678996\n",
      "train loss:0.17879120709806448\n",
      "train loss:0.1898317296212626\n",
      "train loss:0.10266633568092053\n",
      "train loss:0.2538892700354434\n",
      "train loss:0.14693466861924986\n",
      "train loss:0.19104075205449145\n",
      "train loss:0.11340874287664522\n",
      "train loss:0.14341821028904764\n",
      "train loss:0.2059448749582937\n",
      "train loss:0.11088871470952885\n",
      "train loss:0.17630339779542495\n",
      "train loss:0.1275056350569621\n",
      "train loss:0.12441428984397779\n",
      "train loss:0.09691975971705823\n",
      "train loss:0.3129186530056483\n",
      "train loss:0.299861717538265\n",
      "train loss:0.1644919872154665\n",
      "train loss:0.12068776281942592\n",
      "train loss:0.07935417416401645\n",
      "train loss:0.14001361684028535\n",
      "train loss:0.23715441854383262\n",
      "train loss:0.1246776478372325\n",
      "train loss:0.1812639940941198\n",
      "train loss:0.09901918943029969\n",
      "train loss:0.23198970788701184\n",
      "train loss:0.19252553013861284\n",
      "train loss:0.2652878728761277\n",
      "train loss:0.10420614743800524\n",
      "train loss:0.2651809160933489\n",
      "train loss:0.18212506831154524\n",
      "train loss:0.09491364086639907\n",
      "train loss:0.2581567022674105\n",
      "train loss:0.193741373741205\n",
      "train loss:0.17721398397094076\n",
      "train loss:0.08525661196264359\n",
      "train loss:0.16628096805996617\n",
      "train loss:0.2773221984133454\n",
      "train loss:0.17793792106691214\n",
      "train loss:0.28054226210330574\n",
      "train loss:0.1416298114507237\n",
      "train loss:0.10878820113847384\n",
      "train loss:0.15500973374849067\n",
      "train loss:0.19317318067096917\n",
      "train loss:0.11833276291910078\n",
      "train loss:0.12264936504439079\n",
      "train loss:0.14380787796662442\n",
      "train loss:0.13535578572830134\n",
      "train loss:0.10396147926212405\n",
      "train loss:0.26769413485903204\n",
      "train loss:0.07906634708835135\n",
      "train loss:0.09883458056518331\n",
      "train loss:0.22935975938465572\n",
      "train loss:0.10956149975028523\n",
      "train loss:0.24112896727234723\n",
      "train loss:0.10310980945354783\n",
      "train loss:0.09509785969398822\n",
      "train loss:0.14932972648142814\n",
      "train loss:0.14611912901044635\n",
      "train loss:0.117499933798511\n",
      "train loss:0.156862816132137\n",
      "train loss:0.0712661642250751\n",
      "train loss:0.11519935762754122\n",
      "train loss:0.12301698706605374\n",
      "train loss:0.11387666452049489\n",
      "train loss:0.15496830458776936\n",
      "train loss:0.07593080828012021\n",
      "train loss:0.16980974642417745\n",
      "train loss:0.11343869774558434\n",
      "train loss:0.09780006641200294\n",
      "train loss:0.12623161428691515\n",
      "train loss:0.22179688877717876\n",
      "train loss:0.09620887907532674\n",
      "train loss:0.15442479012876925\n",
      "train loss:0.23844049357161834\n",
      "train loss:0.11539251434049685\n",
      "train loss:0.12729641486257\n",
      "train loss:0.1510840919749693\n",
      "train loss:0.1055692379114131\n",
      "train loss:0.1708278519574651\n",
      "train loss:0.13272991129925152\n",
      "train loss:0.17755473068643549\n",
      "train loss:0.13906717257334503\n",
      "train loss:0.11076810408015056\n",
      "train loss:0.1871917062588736\n",
      "train loss:0.11038812149494481\n",
      "train loss:0.14036121458538797\n",
      "train loss:0.09383725400481985\n",
      "train loss:0.18400441047884863\n",
      "train loss:0.1352275849047778\n",
      "train loss:0.10077185335352466\n",
      "train loss:0.09846454109349848\n",
      "train loss:0.05779300233529978\n",
      "train loss:0.10234429995454963\n",
      "train loss:0.1921468706341038\n",
      "train loss:0.17663524013647433\n",
      "train loss:0.07104345133096211\n",
      "train loss:0.23754448704186007\n",
      "train loss:0.047125549929055356\n",
      "train loss:0.17582938217413255\n",
      "train loss:0.1993794354625915\n",
      "train loss:0.1798464177111263\n",
      "train loss:0.15721067175710599\n",
      "train loss:0.24071082103791624\n",
      "train loss:0.18027645819311822\n",
      "train loss:0.07821378900416352\n",
      "train loss:0.13339012381648768\n",
      "train loss:0.15930865558459306\n",
      "train loss:0.09868639740676187\n",
      "train loss:0.05838986523529254\n",
      "train loss:0.06095919687236104\n",
      "train loss:0.09102304854200031\n",
      "train loss:0.15114223862685544\n",
      "train loss:0.12826203806350198\n",
      "train loss:0.09230712149571078\n",
      "train loss:0.18280698411652793\n",
      "train loss:0.12136139857489221\n",
      "train loss:0.13532575767219127\n",
      "train loss:0.09417605291110365\n",
      "train loss:0.13345193056052473\n",
      "train loss:0.14402900542446384\n",
      "train loss:0.17798847752131713\n",
      "train loss:0.1059660600375487\n",
      "train loss:0.12407354761797226\n",
      "train loss:0.15382325674661235\n",
      "train loss:0.16502218163388058\n",
      "train loss:0.03588998596696499\n",
      "train loss:0.1354906896653393\n",
      "train loss:0.11089882792608817\n",
      "train loss:0.1310790455435635\n",
      "train loss:0.03874834865071351\n",
      "train loss:0.1273997220433914\n",
      "train loss:0.07713316637466555\n",
      "train loss:0.1702327004865096\n",
      "train loss:0.06999961262222631\n",
      "train loss:0.04187448825386392\n",
      "train loss:0.10759701401673663\n",
      "train loss:0.10061024089911509\n",
      "train loss:0.08846800894889721\n",
      "train loss:0.0656193276135133\n",
      "train loss:0.08385440050003794\n",
      "train loss:0.16574799900107426\n",
      "train loss:0.09735854291671037\n",
      "train loss:0.19988892454284357\n",
      "train loss:0.123932173689156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.2511777372199403\n",
      "train loss:0.10026022350756429\n",
      "train loss:0.03890509036993649\n",
      "train loss:0.10227587877907254\n",
      "train loss:0.12865426263038937\n",
      "train loss:0.07094891085201854\n",
      "train loss:0.058176479168083634\n",
      "train loss:0.11920103988554445\n",
      "train loss:0.07936870315416354\n",
      "train loss:0.17487882165303617\n",
      "train loss:0.10782946912830967\n",
      "train loss:0.1845631282865813\n",
      "train loss:0.09707503905165471\n",
      "train loss:0.11233274715240679\n",
      "train loss:0.22903309367856392\n",
      "train loss:0.0968694600212004\n",
      "train loss:0.12161710409192895\n",
      "train loss:0.0865721810449487\n",
      "train loss:0.07314456540961957\n",
      "train loss:0.07263668157117419\n",
      "train loss:0.10360248912984968\n",
      "train loss:0.21679861250063617\n",
      "train loss:0.09785649339079945\n",
      "train loss:0.09017215935858833\n",
      "train loss:0.23003961145870944\n",
      "train loss:0.15017650957177925\n",
      "train loss:0.11925421958485583\n",
      "train loss:0.08164906600661237\n",
      "train loss:0.13100253457262906\n",
      "train loss:0.09507505972119773\n",
      "train loss:0.06737355743125187\n",
      "train loss:0.06532515864900498\n",
      "train loss:0.09227301789058656\n",
      "train loss:0.05914876108744564\n",
      "train loss:0.05995404200111664\n",
      "train loss:0.15419763120655022\n",
      "train loss:0.10159906845555713\n",
      "train loss:0.08771116094178234\n",
      "train loss:0.06393662643718953\n",
      "train loss:0.06359601179998982\n",
      "train loss:0.14233439636140044\n",
      "train loss:0.12008413938034429\n",
      "train loss:0.09957561960141006\n",
      "train loss:0.0691555932865298\n",
      "train loss:0.10435014633234156\n",
      "train loss:0.06578584513764177\n",
      "train loss:0.12048222187555574\n",
      "train loss:0.12845626066717064\n",
      "train loss:0.10590083853968334\n",
      "train loss:0.05403709051043926\n",
      "train loss:0.11234789215235359\n",
      "train loss:0.16446644593060394\n",
      "train loss:0.1030903368850435\n",
      "train loss:0.06530671706514096\n",
      "train loss:0.10375755320682392\n",
      "train loss:0.1438560604818229\n",
      "train loss:0.13679951222485032\n",
      "train loss:0.059374352366962896\n",
      "train loss:0.06838076677222665\n",
      "train loss:0.04614472379798907\n",
      "train loss:0.06180665771413164\n",
      "train loss:0.046864928869952076\n",
      "train loss:0.11130170139683837\n",
      "=== epoch:2, train acc:0.969, test acc:0.97 ===\n",
      "train loss:0.0737207762030541\n",
      "train loss:0.20439496712634703\n",
      "train loss:0.12717429641065028\n",
      "train loss:0.2287792403393202\n",
      "train loss:0.22683307506419223\n",
      "train loss:0.10439720486446767\n",
      "train loss:0.30452238659728204\n",
      "train loss:0.15068840995379518\n",
      "train loss:0.15716514634813056\n",
      "train loss:0.04421463927481399\n",
      "train loss:0.08396836739832786\n",
      "train loss:0.08662627721319632\n",
      "train loss:0.11930772449542415\n",
      "train loss:0.07071401270160775\n",
      "train loss:0.09140965707550124\n",
      "train loss:0.07131040377606261\n",
      "train loss:0.21868756126026792\n",
      "train loss:0.12156220045145803\n",
      "train loss:0.07951456776248135\n",
      "train loss:0.1360981376578733\n",
      "train loss:0.06808585378743773\n",
      "train loss:0.0810702532590418\n",
      "train loss:0.10560183315591437\n",
      "train loss:0.1563079415415593\n",
      "train loss:0.16645174848266198\n",
      "train loss:0.13400934536610834\n",
      "train loss:0.10992814684677726\n",
      "train loss:0.07804882285701897\n",
      "train loss:0.12715907274804356\n",
      "train loss:0.06702581568912212\n",
      "train loss:0.05605231053539827\n",
      "train loss:0.08607352516521055\n",
      "train loss:0.07114081788108054\n",
      "train loss:0.03715097046444924\n",
      "train loss:0.130861804604502\n",
      "train loss:0.1514502455724182\n",
      "train loss:0.1097423028495822\n",
      "train loss:0.04693587841629562\n",
      "train loss:0.23903946876591078\n",
      "train loss:0.058642407816149864\n",
      "train loss:0.08189719046159402\n",
      "train loss:0.09110069334864644\n",
      "train loss:0.11316552669340814\n",
      "train loss:0.06554199712092544\n",
      "train loss:0.04807997893437748\n",
      "train loss:0.14323938188765564\n",
      "train loss:0.05884612872814451\n",
      "train loss:0.1463339949326362\n",
      "train loss:0.04640163584521535\n",
      "train loss:0.09303337762195422\n",
      "train loss:0.1169984887446565\n",
      "train loss:0.0819436767460273\n",
      "train loss:0.058118551099768864\n",
      "train loss:0.029806797128291943\n",
      "train loss:0.20312944829775437\n",
      "train loss:0.07009802921310075\n",
      "train loss:0.06240596733376985\n",
      "train loss:0.08403746631693089\n",
      "train loss:0.13650718964847183\n",
      "train loss:0.0751719292460215\n",
      "train loss:0.10207994825396816\n",
      "train loss:0.0999229906662657\n",
      "train loss:0.1559072353204756\n",
      "train loss:0.10828493257436435\n",
      "train loss:0.080744736127139\n",
      "train loss:0.07884276062055565\n",
      "train loss:0.03668241570960928\n",
      "train loss:0.14451358261477046\n",
      "train loss:0.09598530879145663\n",
      "train loss:0.09041531794343494\n",
      "train loss:0.11053521076566508\n",
      "train loss:0.10497738429286853\n",
      "train loss:0.07150751241921395\n",
      "train loss:0.133636336454973\n",
      "train loss:0.08232490765994925\n",
      "train loss:0.07873241120033786\n",
      "train loss:0.06338195423121466\n",
      "train loss:0.06714845358224572\n",
      "train loss:0.15293328848283355\n",
      "train loss:0.06372810985913567\n",
      "train loss:0.09696799783755371\n",
      "train loss:0.055870078572767816\n",
      "train loss:0.09371042243844696\n",
      "train loss:0.05793789223816451\n",
      "train loss:0.0841554575894688\n",
      "train loss:0.10319522458011035\n",
      "train loss:0.07032052908361766\n",
      "train loss:0.1787086602473482\n",
      "train loss:0.03593073550638952\n",
      "train loss:0.08466318083173556\n",
      "train loss:0.06958485332412968\n",
      "train loss:0.04747042752573469\n",
      "train loss:0.08749888921569189\n",
      "train loss:0.03202933671900319\n",
      "train loss:0.06980828816218775\n",
      "train loss:0.06161203369393659\n",
      "train loss:0.13615433660787224\n",
      "train loss:0.11922535357418408\n",
      "train loss:0.0817493691415654\n",
      "train loss:0.12146331807541484\n",
      "train loss:0.07690836323162491\n",
      "train loss:0.030779416059629684\n",
      "train loss:0.1357084861931457\n",
      "train loss:0.03448787060018476\n",
      "train loss:0.08479277407903492\n",
      "train loss:0.044930264603934074\n",
      "train loss:0.134462647736921\n",
      "train loss:0.16033513158906704\n",
      "train loss:0.08157637063738138\n",
      "train loss:0.12893352469839164\n",
      "train loss:0.11957730769440564\n",
      "train loss:0.06916587545274874\n",
      "train loss:0.03423044586363579\n",
      "train loss:0.1094415909958894\n",
      "train loss:0.057884194290913\n",
      "train loss:0.07975982211255775\n",
      "train loss:0.06978230180015864\n",
      "train loss:0.08450635612221824\n",
      "train loss:0.11752500988148923\n",
      "train loss:0.06220681802967962\n",
      "train loss:0.08896060428923169\n",
      "train loss:0.07814959725541491\n",
      "train loss:0.05058474244751628\n",
      "train loss:0.06824765714428448\n",
      "train loss:0.1158458946383635\n",
      "train loss:0.08401388105745136\n",
      "train loss:0.15151426442339253\n",
      "train loss:0.07250143798759026\n",
      "train loss:0.0758948025490978\n",
      "train loss:0.07387466803030365\n",
      "train loss:0.038675403282756024\n",
      "train loss:0.1156630949718183\n",
      "train loss:0.056063202826754074\n",
      "train loss:0.03910501808142517\n",
      "train loss:0.10131128053539415\n",
      "train loss:0.06206495511411122\n",
      "train loss:0.10898113372204943\n",
      "train loss:0.04029474855973534\n",
      "train loss:0.03829455998541091\n",
      "train loss:0.0717752361546668\n",
      "train loss:0.02454137205378084\n",
      "train loss:0.03319097599285087\n",
      "train loss:0.07142090934092443\n",
      "train loss:0.1070351725606928\n",
      "train loss:0.05770531597323105\n",
      "train loss:0.08759271075001651\n",
      "train loss:0.0959239483253454\n",
      "train loss:0.038543851865425666\n",
      "train loss:0.11468633862394796\n",
      "train loss:0.07420529996275098\n",
      "train loss:0.0639464411410904\n",
      "train loss:0.06980000530890894\n",
      "train loss:0.13586824795745606\n",
      "train loss:0.06438722720821714\n",
      "train loss:0.09843353307099086\n",
      "train loss:0.10202977901683628\n",
      "train loss:0.05537312829557362\n",
      "train loss:0.05606544888848822\n",
      "train loss:0.06239617756526702\n",
      "train loss:0.08467683810203397\n",
      "train loss:0.11406711827704472\n",
      "train loss:0.06168470903909808\n",
      "train loss:0.057542613055228745\n",
      "train loss:0.04000020930351738\n",
      "train loss:0.07339902584202694\n",
      "train loss:0.09298997031141651\n",
      "train loss:0.10884284706316474\n",
      "train loss:0.10792157568774798\n",
      "train loss:0.055264024560503416\n",
      "train loss:0.09765574267392493\n",
      "train loss:0.09850180909146998\n",
      "train loss:0.05013478663877029\n",
      "train loss:0.05278761332628746\n",
      "train loss:0.06670429280212106\n",
      "train loss:0.1098030823265987\n",
      "train loss:0.08503379646284699\n",
      "train loss:0.1018945987526307\n",
      "train loss:0.09149294755862952\n",
      "train loss:0.07938459727909428\n",
      "train loss:0.14993131828456932\n",
      "train loss:0.07244569636361327\n",
      "train loss:0.1072657820079082\n",
      "train loss:0.10873088877224556\n",
      "train loss:0.07960038675412659\n",
      "train loss:0.07681108454515678\n",
      "train loss:0.03403382547194531\n",
      "train loss:0.07715213606893512\n",
      "train loss:0.03169919679110038\n",
      "train loss:0.0758251768251736\n",
      "train loss:0.05629653299879824\n",
      "train loss:0.06911317797090759\n",
      "train loss:0.09964496798464503\n",
      "train loss:0.08677108079217934\n",
      "train loss:0.08902967250402945\n",
      "train loss:0.06861042948144164\n",
      "train loss:0.05463333155762234\n",
      "train loss:0.09923043541413701\n",
      "train loss:0.07955942171582615\n",
      "train loss:0.102849862459012\n",
      "train loss:0.031170707929958193\n",
      "train loss:0.1431908508498506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.04996102903449907\n",
      "train loss:0.02304857257644712\n",
      "train loss:0.11260187358758277\n",
      "train loss:0.13539621345149136\n",
      "train loss:0.19877899669484797\n",
      "train loss:0.09868597823487985\n",
      "train loss:0.03845290995987422\n",
      "train loss:0.0453120879173101\n",
      "train loss:0.051250923587850696\n",
      "train loss:0.08116414324167519\n",
      "train loss:0.04234316332476881\n",
      "train loss:0.05159974558031056\n",
      "train loss:0.1728414884850514\n",
      "train loss:0.040690738389579914\n",
      "train loss:0.058419363209725565\n",
      "train loss:0.08075227768195722\n",
      "train loss:0.054521229714388816\n",
      "train loss:0.06527457370374452\n",
      "train loss:0.04231134303224964\n",
      "train loss:0.14163353028475184\n",
      "train loss:0.13983319835835073\n",
      "train loss:0.14668088521510295\n",
      "train loss:0.04116607871425449\n",
      "train loss:0.09749320072223294\n",
      "train loss:0.04065875257294028\n",
      "train loss:0.12242718875721614\n",
      "train loss:0.05816051846953792\n",
      "train loss:0.0998876415996124\n",
      "train loss:0.034917224393866665\n",
      "train loss:0.09504662554533348\n",
      "train loss:0.1168540889360073\n",
      "train loss:0.11196385701242109\n",
      "train loss:0.0570628774822777\n",
      "train loss:0.04954117623119252\n",
      "train loss:0.11217847609232821\n",
      "train loss:0.08952707626597292\n",
      "train loss:0.10178585662801991\n",
      "train loss:0.03943209754126087\n",
      "train loss:0.12220446273435166\n",
      "train loss:0.11011476456254245\n",
      "train loss:0.07557827818100271\n",
      "train loss:0.045246131852836796\n",
      "train loss:0.0584781145903439\n",
      "train loss:0.028957628965145664\n",
      "train loss:0.07275862718795083\n",
      "train loss:0.13589153168929496\n",
      "train loss:0.058931924635604954\n",
      "train loss:0.045145803554121594\n",
      "train loss:0.04244845518259292\n",
      "train loss:0.09289809033950538\n",
      "train loss:0.05463921641895366\n",
      "train loss:0.035977110893043514\n",
      "train loss:0.06784769222143189\n",
      "train loss:0.045624798638377186\n",
      "train loss:0.06850111011439754\n",
      "train loss:0.029079611219411935\n",
      "train loss:0.0681152424140878\n",
      "train loss:0.06368270113146608\n",
      "train loss:0.04121063009826551\n",
      "train loss:0.033535708573162896\n",
      "train loss:0.06416312535792869\n",
      "train loss:0.04635007358738068\n",
      "train loss:0.034071404227390356\n",
      "train loss:0.06972375835603581\n",
      "train loss:0.08609381983475821\n",
      "train loss:0.11122183761932822\n",
      "train loss:0.07423832740671861\n",
      "train loss:0.09366409447688351\n",
      "train loss:0.03166687656085327\n",
      "train loss:0.03430401266251553\n",
      "train loss:0.03187154255216283\n",
      "train loss:0.06510817267601202\n",
      "train loss:0.12189767964254754\n",
      "train loss:0.10334018665890418\n",
      "train loss:0.08572235102235032\n",
      "train loss:0.05231939668056698\n",
      "train loss:0.07650480649834411\n",
      "train loss:0.06031466545357149\n",
      "train loss:0.0453297971076285\n",
      "train loss:0.10867495193018291\n",
      "train loss:0.06490125046360255\n",
      "train loss:0.09311287528736373\n",
      "train loss:0.04720504514318168\n",
      "train loss:0.06181637158395507\n",
      "train loss:0.09972674285549683\n",
      "train loss:0.05149714397350022\n",
      "train loss:0.12063735920655887\n",
      "train loss:0.12785013161898595\n",
      "train loss:0.049423289166748076\n",
      "train loss:0.12848339967592076\n",
      "train loss:0.08077578572027325\n",
      "train loss:0.054896448941232585\n",
      "train loss:0.12400758287642827\n",
      "train loss:0.057804677240543986\n",
      "train loss:0.08694670945578947\n",
      "train loss:0.076165854700161\n",
      "train loss:0.07424055084386809\n",
      "train loss:0.14261677802007222\n",
      "train loss:0.09585439938424005\n",
      "train loss:0.049880933747462476\n",
      "train loss:0.06899393872022691\n",
      "train loss:0.02879770481862406\n",
      "train loss:0.19406837179951789\n",
      "train loss:0.06505574082904059\n",
      "train loss:0.04222354162405849\n",
      "train loss:0.035198973264085824\n",
      "train loss:0.04572418279734248\n",
      "train loss:0.182094522166704\n",
      "train loss:0.11826596445245383\n",
      "train loss:0.09687365198812073\n",
      "train loss:0.056518309398281674\n",
      "train loss:0.04458200602550981\n",
      "train loss:0.13494922347295965\n",
      "train loss:0.04290106848356752\n",
      "train loss:0.08141100556228455\n",
      "train loss:0.08383042183308131\n",
      "train loss:0.1144095074326565\n",
      "train loss:0.05226248122481813\n",
      "train loss:0.08869689932976658\n",
      "train loss:0.04191080222141551\n",
      "train loss:0.04706560947126687\n",
      "train loss:0.06054198285440369\n",
      "train loss:0.13742468656749335\n",
      "train loss:0.06945269680363281\n",
      "train loss:0.128458435977819\n",
      "train loss:0.07481822901531564\n",
      "train loss:0.03133920564705064\n",
      "train loss:0.10012635883081733\n",
      "train loss:0.07870537900309618\n",
      "train loss:0.03753120721500038\n",
      "train loss:0.04355861934842238\n",
      "train loss:0.043711036392060434\n",
      "train loss:0.03377130062754254\n",
      "train loss:0.05350256897877638\n",
      "train loss:0.04759124012240425\n",
      "train loss:0.07224383450185344\n",
      "train loss:0.21371771477014384\n",
      "train loss:0.02874860056123531\n",
      "train loss:0.03152301179884433\n",
      "train loss:0.023506586676336344\n",
      "train loss:0.053922430976656985\n",
      "train loss:0.022591261028745934\n",
      "train loss:0.05247152439857741\n",
      "train loss:0.0874925862198195\n",
      "train loss:0.052936253448288575\n",
      "train loss:0.04270106187539577\n",
      "train loss:0.027380218104632134\n",
      "train loss:0.09295727897786633\n",
      "train loss:0.034926004134368895\n",
      "train loss:0.09532126019417932\n",
      "train loss:0.023973580649028766\n",
      "train loss:0.02951766333983928\n",
      "train loss:0.10726305588866487\n",
      "train loss:0.05548813761242366\n",
      "train loss:0.02751081459016245\n",
      "train loss:0.03164057568228615\n",
      "train loss:0.18487719983935416\n",
      "train loss:0.024079875222740424\n",
      "train loss:0.023684941667786646\n",
      "train loss:0.026008306323649297\n",
      "train loss:0.12209428920870699\n",
      "train loss:0.039910798538337386\n",
      "train loss:0.15087247039250531\n",
      "train loss:0.059055873311773865\n",
      "train loss:0.050373931851530065\n",
      "train loss:0.025330042147614317\n",
      "train loss:0.042339750552683277\n",
      "train loss:0.09510693245411318\n",
      "train loss:0.06228177559817261\n",
      "train loss:0.06517047879534497\n",
      "train loss:0.06932479989440896\n",
      "train loss:0.0545546500908765\n",
      "train loss:0.03395064936052663\n",
      "train loss:0.02007346994741256\n",
      "train loss:0.023529455438104797\n",
      "train loss:0.10591987675548957\n",
      "train loss:0.02669977073404869\n",
      "train loss:0.07907614202239534\n",
      "train loss:0.04042145537974223\n",
      "train loss:0.06367563382792017\n",
      "train loss:0.015448669882292296\n",
      "train loss:0.12201822671214346\n",
      "train loss:0.04199555252689033\n",
      "train loss:0.05035453754512296\n",
      "train loss:0.0403118577234514\n",
      "train loss:0.04146750212297255\n",
      "train loss:0.028666001615661046\n",
      "train loss:0.05004203414094979\n",
      "train loss:0.0947227496043372\n",
      "train loss:0.0847039618161341\n",
      "train loss:0.09841771576885698\n",
      "train loss:0.033969414234034295\n",
      "train loss:0.06605928212144359\n",
      "train loss:0.05986654610485548\n",
      "train loss:0.10210757664250115\n",
      "train loss:0.10127684434010135\n",
      "train loss:0.21936748659170466\n",
      "train loss:0.01729492394921223\n",
      "train loss:0.04404713435213302\n",
      "train loss:0.0825927461737522\n",
      "train loss:0.07761524865536826\n",
      "train loss:0.06080030418614359\n",
      "train loss:0.06863464299593781\n",
      "train loss:0.01719984466219629\n",
      "train loss:0.1017542542703798\n",
      "train loss:0.08780327469317382\n",
      "train loss:0.04384345798301526\n",
      "train loss:0.0671294169448359\n",
      "train loss:0.04249239737575871\n",
      "train loss:0.12575786148245843\n",
      "train loss:0.05887565243803104\n",
      "train loss:0.04226843991230449\n",
      "train loss:0.06478647956740347\n",
      "train loss:0.0422710988140475\n",
      "train loss:0.10156780158205166\n",
      "train loss:0.05389376167844361\n",
      "train loss:0.09050943892560395\n",
      "train loss:0.047706558685248576\n",
      "train loss:0.07290995980166182\n",
      "train loss:0.1540818780473437\n",
      "train loss:0.18008637231322738\n",
      "train loss:0.035987636351104836\n",
      "train loss:0.10175111175421657\n",
      "train loss:0.07706776103943397\n",
      "train loss:0.07978390455460854\n",
      "train loss:0.1019844287558793\n",
      "train loss:0.07677942663020121\n",
      "train loss:0.08602925941888813\n",
      "train loss:0.07865680115463027\n",
      "train loss:0.03599239545155526\n",
      "train loss:0.14828964931566346\n",
      "train loss:0.06506962949540049\n",
      "train loss:0.024969618163966277\n",
      "train loss:0.05376083568321136\n",
      "train loss:0.060429632464413796\n",
      "train loss:0.06289063461490413\n",
      "train loss:0.08539808735683557\n",
      "train loss:0.03504313405938471\n",
      "train loss:0.027968680323530632\n",
      "train loss:0.056665644865103164\n",
      "train loss:0.04367243486927198\n",
      "train loss:0.014959765569635314\n",
      "train loss:0.026926799133823755\n",
      "train loss:0.028152722902195153\n",
      "train loss:0.037504117259925585\n",
      "train loss:0.07293938917944368\n",
      "train loss:0.03993326425593686\n",
      "train loss:0.041994360157761965\n",
      "train loss:0.033386144269754184\n",
      "train loss:0.0404417357541263\n",
      "train loss:0.07694696665009589\n",
      "train loss:0.054554921135834995\n",
      "train loss:0.06986833104930168\n",
      "train loss:0.11812190002505105\n",
      "train loss:0.028645520439696294\n",
      "train loss:0.016513533715232016\n",
      "train loss:0.04745761195555302\n",
      "train loss:0.05551380417934308\n",
      "train loss:0.011358231812752901\n",
      "train loss:0.03312189376624151\n",
      "train loss:0.020217631691565034\n",
      "train loss:0.05975493044314421\n",
      "train loss:0.05963259469210655\n",
      "train loss:0.16529276395882841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.055086405120240885\n",
      "train loss:0.09367995450799156\n",
      "train loss:0.11414758659375522\n",
      "train loss:0.07893256261947144\n",
      "train loss:0.06593087482001886\n",
      "train loss:0.02895128298834534\n",
      "train loss:0.02675541734517941\n",
      "train loss:0.041012545716175984\n",
      "train loss:0.14305420718231707\n",
      "train loss:0.07483680293579684\n",
      "train loss:0.047984495658938295\n",
      "train loss:0.013518727032164892\n",
      "train loss:0.05253461867845319\n",
      "train loss:0.03026024636903112\n",
      "train loss:0.038484488188602076\n",
      "train loss:0.1567308615701971\n",
      "train loss:0.05283403994214332\n",
      "train loss:0.1250644018892787\n",
      "train loss:0.05089605324925066\n",
      "train loss:0.04735725441921129\n",
      "train loss:0.04653096091442497\n",
      "train loss:0.0593079206830725\n",
      "train loss:0.042464537760389096\n",
      "train loss:0.06502758454246046\n",
      "train loss:0.024016989313284297\n",
      "train loss:0.18321093376976336\n",
      "train loss:0.05743064422333016\n",
      "train loss:0.01818611031276616\n",
      "train loss:0.06230872169262838\n",
      "train loss:0.03375214161730204\n",
      "train loss:0.070209877671235\n",
      "train loss:0.09975664147997908\n",
      "train loss:0.07588064708219405\n",
      "train loss:0.0762805844287536\n",
      "train loss:0.02857370061575677\n",
      "train loss:0.06284231123993876\n",
      "train loss:0.03048019613965298\n",
      "train loss:0.05552566566318693\n",
      "train loss:0.09119630411368602\n",
      "train loss:0.04207614411590679\n",
      "train loss:0.042202454036330515\n",
      "train loss:0.030267164070374525\n",
      "train loss:0.07806684368863935\n",
      "train loss:0.06775054958212008\n",
      "train loss:0.1050647090685154\n",
      "train loss:0.08173315712517198\n",
      "train loss:0.03078438438292782\n",
      "train loss:0.04474221001709841\n",
      "train loss:0.03846386521550235\n",
      "train loss:0.044875259412796666\n",
      "train loss:0.05330660236687702\n",
      "train loss:0.03672932458827209\n",
      "train loss:0.04269793531050075\n",
      "train loss:0.08094029370194136\n",
      "train loss:0.1314731515481452\n",
      "train loss:0.04004600810580425\n",
      "train loss:0.026509421023439565\n",
      "train loss:0.05581879187581877\n",
      "train loss:0.04771898297090837\n",
      "train loss:0.06117518722835235\n",
      "train loss:0.04554571474148227\n",
      "train loss:0.041450594085077556\n",
      "train loss:0.08048611751892545\n",
      "train loss:0.03406879731839231\n",
      "train loss:0.0776045918777714\n",
      "train loss:0.047573923997529306\n",
      "train loss:0.057093580384769735\n",
      "train loss:0.024959121175967942\n",
      "train loss:0.051385792786228734\n",
      "train loss:0.06761702145391299\n",
      "train loss:0.01435295446077214\n",
      "train loss:0.03647288672602455\n",
      "train loss:0.020481684587778576\n",
      "train loss:0.16080448407275155\n",
      "train loss:0.03972895764886511\n",
      "train loss:0.04057850236990793\n",
      "train loss:0.08837712320492626\n",
      "train loss:0.0656198374869583\n",
      "train loss:0.013744225786695397\n",
      "train loss:0.09023937667558588\n",
      "train loss:0.020513100748676075\n",
      "train loss:0.014830974531136888\n",
      "train loss:0.016390187940869275\n",
      "train loss:0.013690408193409095\n",
      "train loss:0.12047932373893853\n",
      "train loss:0.014301455697894263\n",
      "train loss:0.038444448873464154\n",
      "train loss:0.14109916475305048\n",
      "train loss:0.09303345631291314\n",
      "train loss:0.027010080170927417\n",
      "train loss:0.022468604026489633\n",
      "train loss:0.09510518431631151\n",
      "train loss:0.03915673563209098\n",
      "train loss:0.025399075546345306\n",
      "train loss:0.02435673453215389\n",
      "train loss:0.07056183326871177\n",
      "train loss:0.04141795859935263\n",
      "train loss:0.08991815833316842\n",
      "train loss:0.10670514280710286\n",
      "train loss:0.06689641972757443\n",
      "train loss:0.026805301040507823\n",
      "train loss:0.029640405799099313\n",
      "train loss:0.05017015874016827\n",
      "train loss:0.11587708213470246\n",
      "train loss:0.04969412760374563\n",
      "train loss:0.023088760847232336\n",
      "train loss:0.03232986943917897\n",
      "train loss:0.09562849819519753\n",
      "train loss:0.00880047246172221\n",
      "train loss:0.010616322031775571\n",
      "train loss:0.056269579621365196\n",
      "train loss:0.04168885038314465\n",
      "train loss:0.055454864237576826\n",
      "train loss:0.049902999023019985\n",
      "train loss:0.08979292901456999\n",
      "train loss:0.08926704871162498\n",
      "train loss:0.05930401097591156\n",
      "train loss:0.09012988129525351\n",
      "train loss:0.026610153747923762\n",
      "train loss:0.04288154317005941\n",
      "train loss:0.043437938692579225\n",
      "train loss:0.026205688186855695\n",
      "train loss:0.024236927760514004\n",
      "train loss:0.0735310638099114\n",
      "train loss:0.03110084195791688\n",
      "train loss:0.11433040995034605\n",
      "train loss:0.03502856324580241\n",
      "train loss:0.026723692636084283\n",
      "train loss:0.02600081169533641\n",
      "train loss:0.046381533638155635\n",
      "train loss:0.08741481110067652\n",
      "train loss:0.049411229719753605\n",
      "train loss:0.025264866213892342\n",
      "train loss:0.13642029821381937\n",
      "train loss:0.024035513592192363\n",
      "=== epoch:3, train acc:0.978, test acc:0.982 ===\n",
      "train loss:0.01688892610581002\n",
      "train loss:0.14468466902750074\n",
      "train loss:0.050796740097775066\n",
      "train loss:0.057710319620019934\n",
      "train loss:0.04233040226910338\n",
      "train loss:0.06241406932361221\n",
      "train loss:0.10602633771491007\n",
      "train loss:0.09416255457596011\n",
      "train loss:0.06261300424309733\n",
      "train loss:0.05356859167945658\n",
      "train loss:0.13214830808945055\n",
      "train loss:0.030928767399545164\n",
      "train loss:0.056542200994226376\n",
      "train loss:0.06195083202879071\n",
      "train loss:0.06523433756816041\n",
      "train loss:0.020645052138825247\n",
      "train loss:0.09116361027186758\n",
      "train loss:0.04708370176584129\n",
      "train loss:0.04531006732900262\n",
      "train loss:0.0830818280119625\n",
      "train loss:0.05957505684495781\n",
      "train loss:0.09675842550771512\n",
      "train loss:0.01815127376974306\n",
      "train loss:0.12802833430850435\n",
      "train loss:0.016336209634864585\n",
      "train loss:0.18479127750177476\n",
      "train loss:0.01347390379794031\n",
      "train loss:0.06506764031312834\n",
      "train loss:0.016444205079019437\n",
      "train loss:0.047010158700960286\n",
      "train loss:0.05936769665187148\n",
      "train loss:0.10540406573785242\n",
      "train loss:0.050783561482158034\n",
      "train loss:0.09183004516490537\n",
      "train loss:0.038429317285250356\n",
      "train loss:0.04882468281498936\n",
      "train loss:0.12596887196979098\n",
      "train loss:0.05138884557570175\n",
      "train loss:0.07134313868632292\n",
      "train loss:0.09730452379449593\n",
      "train loss:0.04708519661694484\n",
      "train loss:0.10296193877624639\n",
      "train loss:0.161924369003124\n",
      "train loss:0.04822187384504544\n",
      "train loss:0.04390351007252998\n",
      "train loss:0.11535751993281897\n",
      "train loss:0.07162014684203481\n",
      "train loss:0.03603980484188003\n",
      "train loss:0.055268550508312975\n",
      "train loss:0.03807524185051917\n",
      "train loss:0.029925043865255886\n",
      "train loss:0.03441303482167151\n",
      "train loss:0.06010487688229326\n",
      "train loss:0.2792557340695251\n",
      "train loss:0.12355033959361571\n",
      "train loss:0.05375135260209455\n",
      "train loss:0.050526734576095904\n",
      "train loss:0.05866258469715894\n",
      "train loss:0.06877777307578517\n",
      "train loss:0.04828554005104167\n",
      "train loss:0.03818783910908199\n",
      "train loss:0.034367593698849334\n",
      "train loss:0.023193790223338454\n",
      "train loss:0.03641862676299905\n",
      "train loss:0.0479281120463838\n",
      "train loss:0.09132050523765002\n",
      "train loss:0.08783690383502896\n",
      "train loss:0.06085346540258861\n",
      "train loss:0.08530538857157359\n",
      "train loss:0.0208814421726852\n",
      "train loss:0.11606564734753524\n",
      "train loss:0.10735902258354749\n",
      "train loss:0.07265966271128668\n",
      "train loss:0.04302367215620065\n",
      "train loss:0.023999540985524582\n",
      "train loss:0.08407637369705531\n",
      "train loss:0.00521739904593418\n",
      "train loss:0.03336770223633214\n",
      "train loss:0.012624620685008438\n",
      "train loss:0.03159835734891657\n",
      "train loss:0.0413816215661505\n",
      "train loss:0.025358171291990476\n",
      "train loss:0.0650814354064683\n",
      "train loss:0.0741486205374125\n",
      "train loss:0.013959216794759926\n",
      "train loss:0.025844149666214285\n",
      "train loss:0.06696213477603562\n",
      "train loss:0.045771614600822866\n",
      "train loss:0.015341922084215065\n",
      "train loss:0.06000469129692945\n",
      "train loss:0.08869454267951885\n",
      "train loss:0.02329486393192573\n",
      "train loss:0.040604807837496815\n",
      "train loss:0.01485180899943685\n",
      "train loss:0.019861777655776416\n",
      "train loss:0.016057608595707342\n",
      "train loss:0.05030714402315751\n",
      "train loss:0.025077119456496325\n",
      "train loss:0.0350816804880061\n",
      "train loss:0.10196975437267217\n",
      "train loss:0.03241071935133243\n",
      "train loss:0.06466518485155107\n",
      "train loss:0.04253598090505558\n",
      "train loss:0.05327944322613767\n",
      "train loss:0.03394767499683968\n",
      "train loss:0.029647272355566096\n",
      "train loss:0.07458714252649293\n",
      "train loss:0.03693775367778801\n",
      "train loss:0.13508248537039205\n",
      "train loss:0.03348895169120546\n",
      "train loss:0.02940111755084651\n",
      "train loss:0.04842143138466635\n",
      "train loss:0.03898409908887676\n",
      "train loss:0.03369339393256328\n",
      "train loss:0.06544132614759508\n",
      "train loss:0.013785210599054371\n",
      "train loss:0.0627711011257062\n",
      "train loss:0.020512663300517972\n",
      "train loss:0.045958702184798\n",
      "train loss:0.05913788486837191\n",
      "train loss:0.04664232829009728\n",
      "train loss:0.046422358567388224\n",
      "train loss:0.012163679417403109\n",
      "train loss:0.046890182418585565\n",
      "train loss:0.040187823061571946\n",
      "train loss:0.08180873543949639\n",
      "train loss:0.022219317938318616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03998919793162755\n",
      "train loss:0.057882670066843236\n",
      "train loss:0.03395352178457062\n",
      "train loss:0.0736680525221542\n",
      "train loss:0.019314406976235134\n",
      "train loss:0.05028488436129052\n",
      "train loss:0.04719401378688057\n",
      "train loss:0.02291506696714905\n",
      "train loss:0.011144965525251675\n",
      "train loss:0.02635778982804231\n",
      "train loss:0.04313643661078768\n",
      "train loss:0.03123081236278427\n",
      "train loss:0.023296711422843567\n",
      "train loss:0.021063175334459446\n",
      "train loss:0.06012994685771938\n",
      "train loss:0.08159560907944512\n",
      "train loss:0.015527620900035557\n",
      "train loss:0.04216700298115254\n",
      "train loss:0.060992161741164334\n",
      "train loss:0.03244432659248962\n",
      "train loss:0.041497979979893546\n",
      "train loss:0.04177688364496166\n",
      "train loss:0.06491890249935921\n",
      "train loss:0.02621957316702648\n",
      "train loss:0.037838247828807264\n",
      "train loss:0.022015948393789144\n",
      "train loss:0.07111292967947777\n",
      "train loss:0.028147485017983045\n",
      "train loss:0.04050382447517288\n",
      "train loss:0.1566252395554475\n",
      "train loss:0.034004404502884895\n",
      "train loss:0.050484044389565594\n",
      "train loss:0.1141887797753745\n",
      "train loss:0.01127911259190073\n",
      "train loss:0.0510744336169799\n",
      "train loss:0.09140858870388094\n",
      "train loss:0.013808760248196687\n",
      "train loss:0.01206243436555708\n",
      "train loss:0.05977908939343084\n",
      "train loss:0.0799888208668361\n",
      "train loss:0.030518037206230725\n",
      "train loss:0.08738643993884951\n",
      "train loss:0.09205400735813886\n",
      "train loss:0.05541110163850793\n",
      "train loss:0.05065748664626322\n",
      "train loss:0.06759455659187275\n",
      "train loss:0.09569853129872842\n",
      "train loss:0.05833606214834566\n",
      "train loss:0.07150740485334514\n",
      "train loss:0.041871082322890656\n",
      "train loss:0.09745432866014102\n",
      "train loss:0.012502958740969745\n",
      "train loss:0.04482997684627099\n",
      "train loss:0.031718304890976705\n",
      "train loss:0.055957527650983156\n",
      "train loss:0.023387454905503587\n",
      "train loss:0.06260159124450279\n",
      "train loss:0.025157451058554416\n",
      "train loss:0.04471904386860214\n",
      "train loss:0.030831699242605124\n",
      "train loss:0.041653478122360525\n",
      "train loss:0.07587177032035898\n",
      "train loss:0.02592068251796086\n",
      "train loss:0.023700098264227986\n",
      "train loss:0.06672355059794685\n",
      "train loss:0.1393957669412707\n",
      "train loss:0.12244619629954402\n",
      "train loss:0.05798317687926066\n",
      "train loss:0.03961434701556001\n",
      "train loss:0.016157417021557263\n",
      "train loss:0.011918286444971444\n",
      "train loss:0.06664213622714729\n",
      "train loss:0.02946179093949358\n",
      "train loss:0.14392945725025924\n",
      "train loss:0.08795160624019666\n",
      "train loss:0.04430268190433431\n",
      "train loss:0.07264754802173176\n",
      "train loss:0.04591175909258735\n",
      "train loss:0.050321854569292716\n",
      "train loss:0.05041474770508516\n",
      "train loss:0.028653587305584267\n",
      "train loss:0.0728123019211547\n",
      "train loss:0.06809660071115692\n",
      "train loss:0.00986843322098377\n",
      "train loss:0.03046423287994315\n",
      "train loss:0.01628916673582536\n",
      "train loss:0.0603135786367089\n",
      "train loss:0.033087082741084684\n",
      "train loss:0.03524522663424328\n",
      "train loss:0.01740822405439638\n",
      "train loss:0.07601631601959496\n",
      "train loss:0.0272913685892377\n",
      "train loss:0.018514934118064555\n",
      "train loss:0.020289877953446892\n",
      "train loss:0.019741088844450104\n",
      "train loss:0.08747903167223217\n",
      "train loss:0.01557385452454856\n",
      "train loss:0.06378592547962984\n",
      "train loss:0.02368727555132013\n",
      "train loss:0.015077966140676908\n",
      "train loss:0.05385922249445727\n",
      "train loss:0.061290689338075736\n",
      "train loss:0.01629385610017205\n",
      "train loss:0.03137007807189891\n",
      "train loss:0.03813183996922083\n",
      "train loss:0.01198111303826203\n",
      "train loss:0.02809079391173833\n",
      "train loss:0.026971242363013025\n",
      "train loss:0.01759020362032203\n",
      "train loss:0.02216174366363969\n",
      "train loss:0.03434862607163772\n",
      "train loss:0.01220840621785716\n",
      "train loss:0.04592960948963824\n",
      "train loss:0.041820679930225625\n",
      "train loss:0.05346885491681237\n",
      "train loss:0.04987578563621826\n",
      "train loss:0.12889684402424162\n",
      "train loss:0.03793265330768914\n",
      "train loss:0.012199860144487056\n",
      "train loss:0.02318746670151733\n",
      "train loss:0.04684932781691972\n",
      "train loss:0.012532696655256616\n",
      "train loss:0.0415304692747957\n",
      "train loss:0.01524687566681894\n",
      "train loss:0.042684664909401544\n",
      "train loss:0.03275174595209276\n",
      "train loss:0.02403760902684839\n",
      "train loss:0.02354016605563041\n",
      "train loss:0.021849550578344635\n",
      "train loss:0.020500390118433947\n",
      "train loss:0.01928830737964419\n",
      "train loss:0.022769525473053342\n",
      "train loss:0.004002348384837113\n",
      "train loss:0.08672833199631262\n",
      "train loss:0.009615820483020397\n",
      "train loss:0.01684706496731895\n",
      "train loss:0.05848527902434791\n",
      "train loss:0.011821099733703759\n",
      "train loss:0.03977265075841761\n",
      "train loss:0.06758712989468556\n",
      "train loss:0.036418927714464866\n",
      "train loss:0.07641059864375806\n",
      "train loss:0.03894962329447358\n",
      "train loss:0.019848803966301315\n",
      "train loss:0.05947426596392646\n",
      "train loss:0.047877942511981866\n",
      "train loss:0.06466541023314218\n",
      "train loss:0.02672593082040072\n",
      "train loss:0.04352309533420068\n",
      "train loss:0.02719987062572426\n",
      "train loss:0.04906527310265103\n",
      "train loss:0.03365515672647468\n",
      "train loss:0.059655106756462954\n",
      "train loss:0.022233102260912938\n",
      "train loss:0.01987779331846249\n",
      "train loss:0.047631378903840345\n",
      "train loss:0.018330875428771213\n",
      "train loss:0.022914446870285318\n",
      "train loss:0.010217715354272811\n",
      "train loss:0.08535249031608991\n",
      "train loss:0.008175493628865\n",
      "train loss:0.01754358291033388\n",
      "train loss:0.01230149618504909\n",
      "train loss:0.0065602416404569016\n",
      "train loss:0.020419631264415525\n",
      "train loss:0.032550571063944884\n",
      "train loss:0.007198120841029367\n",
      "train loss:0.03768312278169382\n",
      "train loss:0.025155669521503783\n",
      "train loss:0.05177049468001851\n",
      "train loss:0.21218538542777338\n",
      "train loss:0.01287779697319422\n",
      "train loss:0.023002637296601652\n",
      "train loss:0.04983659901268444\n",
      "train loss:0.02547014905852697\n",
      "train loss:0.058761570188341265\n",
      "train loss:0.03891549543252043\n",
      "train loss:0.006910709716034244\n",
      "train loss:0.037749540665818475\n",
      "train loss:0.021126109505274902\n",
      "train loss:0.019005955497556414\n",
      "train loss:0.08321165398488549\n",
      "train loss:0.0319720089085562\n",
      "train loss:0.03867919039172671\n",
      "train loss:0.03937121823551101\n",
      "train loss:0.045462851669271984\n",
      "train loss:0.01795882116533509\n",
      "train loss:0.012104416895065829\n",
      "train loss:0.02330607779481738\n",
      "train loss:0.030069793584940406\n",
      "train loss:0.03508233330667747\n",
      "train loss:0.0422883010030878\n",
      "train loss:0.027618225836084153\n",
      "train loss:0.0396612122038304\n",
      "train loss:0.02353769085517822\n",
      "train loss:0.016439481641907693\n",
      "train loss:0.03182806642298911\n",
      "train loss:0.02786373132183436\n",
      "train loss:0.08811543855157065\n",
      "train loss:0.0643720888945931\n",
      "train loss:0.0301514174961086\n",
      "train loss:0.09175229757463653\n",
      "train loss:0.02117888238732944\n",
      "train loss:0.02575225966413142\n",
      "train loss:0.01483612831038167\n",
      "train loss:0.06094226498270415\n",
      "train loss:0.03758893065393518\n",
      "train loss:0.016572866360034296\n",
      "train loss:0.028001028035399656\n",
      "train loss:0.029966615352857728\n",
      "train loss:0.020778465767958654\n",
      "train loss:0.04146662795644104\n",
      "train loss:0.027047111746533306\n",
      "train loss:0.06837222735078423\n",
      "train loss:0.05400251179839258\n",
      "train loss:0.017715546947096032\n",
      "train loss:0.030613764893146295\n",
      "train loss:0.013518933270569545\n",
      "train loss:0.058143223042339445\n",
      "train loss:0.01893833024836903\n",
      "train loss:0.09447599779474582\n",
      "train loss:0.05145591863254276\n",
      "train loss:0.08230446600725118\n",
      "train loss:0.040899383309394265\n",
      "train loss:0.06679808837518632\n",
      "train loss:0.034866591366386326\n",
      "train loss:0.04997560965516451\n",
      "train loss:0.0881502984472839\n",
      "train loss:0.0446601259069223\n",
      "train loss:0.07224493113448249\n",
      "train loss:0.012970491460487532\n",
      "train loss:0.014606017822195595\n",
      "train loss:0.04571857849281698\n",
      "train loss:0.042148361383996004\n",
      "train loss:0.019325488058530568\n",
      "train loss:0.016911995372615493\n",
      "train loss:0.06892566125685486\n",
      "train loss:0.062435392274601716\n",
      "train loss:0.01050285243221443\n",
      "train loss:0.06140368761112565\n",
      "train loss:0.0468171067664083\n",
      "train loss:0.036411363160957465\n",
      "train loss:0.022104938813650263\n",
      "train loss:0.027850767074833995\n",
      "train loss:0.026601989999410817\n",
      "train loss:0.024528827411392076\n",
      "train loss:0.05572055700409651\n",
      "train loss:0.034103096294778396\n",
      "train loss:0.05840706846172676\n",
      "train loss:0.027047968647942292\n",
      "train loss:0.025349014203604546\n",
      "train loss:0.08336149738758873\n",
      "train loss:0.20236333653707497\n",
      "train loss:0.0432814185657068\n",
      "train loss:0.021697602535473898\n",
      "train loss:0.0621312098831081\n",
      "train loss:0.02101804947349354\n",
      "train loss:0.06783129604399626\n",
      "train loss:0.04369587701120474\n",
      "train loss:0.01979580155460498\n",
      "train loss:0.0237024618900873\n",
      "train loss:0.034384515620685355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.024966645753078248\n",
      "train loss:0.03882441299863976\n",
      "train loss:0.1664149293169586\n",
      "train loss:0.02977366083169034\n",
      "train loss:0.03838704488114413\n",
      "train loss:0.06396289886597152\n",
      "train loss:0.008459639487881391\n",
      "train loss:0.018135366176833055\n",
      "train loss:0.007783868938446922\n",
      "train loss:0.043443815101438805\n",
      "train loss:0.04576124979320707\n",
      "train loss:0.06239691648391932\n",
      "train loss:0.033166844150321666\n",
      "train loss:0.00954811933694588\n",
      "train loss:0.034246745388102816\n",
      "train loss:0.06527255456664553\n",
      "train loss:0.033275496432284085\n",
      "train loss:0.03747566890984525\n",
      "train loss:0.010669903931040465\n",
      "train loss:0.03252110547146633\n",
      "train loss:0.06286859596695896\n",
      "train loss:0.025979694895848976\n",
      "train loss:0.024638335935615277\n",
      "train loss:0.05625529019898887\n",
      "train loss:0.08281117275628956\n",
      "train loss:0.09698312177887138\n",
      "train loss:0.013216690213860172\n",
      "train loss:0.0876570349474793\n",
      "train loss:0.05858757978566415\n",
      "train loss:0.027283489988825287\n",
      "train loss:0.06960032083096583\n",
      "train loss:0.041785428042972146\n",
      "train loss:0.14011656024570404\n",
      "train loss:0.028441997751263517\n",
      "train loss:0.056222005446671296\n",
      "train loss:0.04870012569369617\n",
      "train loss:0.04844677423871662\n",
      "train loss:0.06152098528489838\n",
      "train loss:0.024895579988442922\n",
      "train loss:0.014708769333282311\n",
      "train loss:0.03066984995869828\n",
      "train loss:0.051422063842809715\n",
      "train loss:0.024522525393126576\n",
      "train loss:0.014630984840466177\n",
      "train loss:0.019941505497348903\n",
      "train loss:0.028307812568068844\n",
      "train loss:0.055296482463396836\n",
      "train loss:0.09862091894259624\n",
      "train loss:0.013428943427592079\n",
      "train loss:0.02293538037100904\n",
      "train loss:0.02226044605830167\n",
      "train loss:0.018275533897084858\n",
      "train loss:0.020379621986472186\n",
      "train loss:0.032720917310139847\n",
      "train loss:0.06369605634269875\n",
      "train loss:0.01536212035026149\n",
      "train loss:0.03269246544872661\n",
      "train loss:0.027963791610853557\n",
      "train loss:0.04121762025653302\n",
      "train loss:0.04011226181589971\n",
      "train loss:0.035979809596048414\n",
      "train loss:0.03631130605764514\n",
      "train loss:0.03575428684263727\n",
      "train loss:0.05349165130045981\n",
      "train loss:0.0071356424447968254\n",
      "train loss:0.024766370452669658\n",
      "train loss:0.015785130911022474\n",
      "train loss:0.018750115345121953\n",
      "train loss:0.041910186569296445\n",
      "train loss:0.0900347505723174\n",
      "train loss:0.08712940307038171\n",
      "train loss:0.04113340738453328\n",
      "train loss:0.11935793057805083\n",
      "train loss:0.09005161754999279\n",
      "train loss:0.02970972304315902\n",
      "train loss:0.026053470772794973\n",
      "train loss:0.0305212986356603\n",
      "train loss:0.022617663707184356\n",
      "train loss:0.06557587981475135\n",
      "train loss:0.02379620575401328\n",
      "train loss:0.015067491569436367\n",
      "train loss:0.0413441294207154\n",
      "train loss:0.015124322988775384\n",
      "train loss:0.04256039703206265\n",
      "train loss:0.03861947366170736\n",
      "train loss:0.012671936960150449\n",
      "train loss:0.029751686687899646\n",
      "train loss:0.009425334514278379\n",
      "train loss:0.02761935496557887\n",
      "train loss:0.06348566794255818\n",
      "train loss:0.07681463322343372\n",
      "train loss:0.022015088894248937\n",
      "train loss:0.009411722740406466\n",
      "train loss:0.06725333966872435\n",
      "train loss:0.023706916292984433\n",
      "train loss:0.02415192573734637\n",
      "train loss:0.07045434660687026\n",
      "train loss:0.008292663393997333\n",
      "train loss:0.05153950608355137\n",
      "train loss:0.059395355918388605\n",
      "train loss:0.04700488034976582\n",
      "train loss:0.01600517667633778\n",
      "train loss:0.02205978056675713\n",
      "train loss:0.0063320516994361045\n",
      "train loss:0.03709499137343764\n",
      "train loss:0.014183263027926309\n",
      "train loss:0.01376740308336431\n",
      "train loss:0.03235731723151289\n",
      "train loss:0.02578948404722084\n",
      "train loss:0.06956776965482529\n",
      "train loss:0.008697427554045768\n",
      "train loss:0.010826297861103349\n",
      "train loss:0.09241868168505853\n",
      "train loss:0.0690204963282122\n",
      "train loss:0.010530139252345843\n",
      "train loss:0.06272538748726475\n",
      "train loss:0.01585588654648038\n",
      "train loss:0.010471153411522875\n",
      "train loss:0.014332690073108246\n",
      "train loss:0.047266328285396696\n",
      "train loss:0.05201018679148058\n",
      "train loss:0.02360360928048471\n",
      "train loss:0.05891967108042079\n",
      "train loss:0.01182289258101815\n",
      "train loss:0.08528172497870483\n",
      "train loss:0.009197163154848862\n",
      "train loss:0.04474348157398807\n",
      "train loss:0.07691719573094073\n",
      "train loss:0.02655245166462848\n",
      "train loss:0.038050724796361776\n",
      "train loss:0.012427092156720767\n",
      "train loss:0.06093890742251139\n",
      "train loss:0.029963310728871925\n",
      "train loss:0.018451278696686467\n",
      "train loss:0.023810745138193173\n",
      "train loss:0.014115442445045605\n",
      "train loss:0.06293071680012459\n",
      "train loss:0.017461785054086514\n",
      "train loss:0.04428778444433836\n",
      "train loss:0.02708198832087765\n",
      "train loss:0.014487516215579373\n",
      "train loss:0.018958112661639204\n",
      "train loss:0.04923968954604319\n",
      "train loss:0.008670147613615389\n",
      "train loss:0.005731302847103273\n",
      "train loss:0.013829509848597137\n",
      "train loss:0.04960218982760606\n",
      "train loss:0.0495889015853952\n",
      "train loss:0.016437007967199723\n",
      "train loss:0.051555767167346216\n",
      "train loss:0.018625919299785524\n",
      "train loss:0.03074527175477598\n",
      "train loss:0.1104743940339672\n",
      "train loss:0.01541695669491089\n",
      "train loss:0.025337292887636455\n",
      "train loss:0.01083257243037062\n",
      "train loss:0.07231729189442386\n",
      "train loss:0.023299342992374652\n",
      "train loss:0.05051312465184788\n",
      "train loss:0.01077226139421496\n",
      "train loss:0.024581894136747842\n",
      "train loss:0.033545662636984795\n",
      "train loss:0.032831313529084465\n",
      "train loss:0.03601083856071813\n",
      "train loss:0.006780272682631831\n",
      "train loss:0.043322679476209824\n",
      "train loss:0.007072024445406655\n",
      "train loss:0.008959432618630067\n",
      "train loss:0.050053550248126626\n",
      "train loss:0.012244767827175389\n",
      "train loss:0.024405415512657815\n",
      "train loss:0.07996479371358052\n",
      "train loss:0.01734267141756519\n",
      "train loss:0.004383126159867683\n",
      "train loss:0.1649270196700467\n",
      "train loss:0.041001735072027604\n",
      "train loss:0.025365433930883034\n",
      "train loss:0.03617366297000186\n",
      "train loss:0.03447776918036696\n",
      "train loss:0.033274794909465874\n",
      "train loss:0.041454759626562775\n",
      "train loss:0.07424460141480542\n",
      "train loss:0.027758702096251562\n",
      "train loss:0.011978352010813674\n",
      "train loss:0.03733894942866984\n",
      "train loss:0.010368632901838032\n",
      "train loss:0.022749632647870967\n",
      "train loss:0.01337926091207341\n",
      "train loss:0.016449989305025108\n",
      "train loss:0.05780478890545881\n",
      "train loss:0.03954377051776472\n",
      "train loss:0.02568818544351013\n",
      "train loss:0.04029123344540023\n",
      "train loss:0.05948309274356085\n",
      "train loss:0.012588453651441876\n",
      "train loss:0.03651118713842139\n",
      "train loss:0.00865599181327248\n",
      "train loss:0.03320036972266135\n",
      "train loss:0.03699196744499672\n",
      "train loss:0.020570677253962874\n",
      "train loss:0.017272890151642753\n",
      "train loss:0.04561930290085217\n",
      "train loss:0.06645362693854401\n",
      "train loss:0.020827300073132632\n",
      "train loss:0.017801906131491393\n",
      "train loss:0.043751292143499126\n",
      "train loss:0.01681827722620535\n",
      "train loss:0.025783316736349735\n",
      "train loss:0.04134683518158745\n",
      "train loss:0.015674012346904083\n",
      "train loss:0.049105644215177054\n",
      "=== epoch:4, train acc:0.984, test acc:0.981 ===\n",
      "train loss:0.01058001772150037\n",
      "train loss:0.03545553000141324\n",
      "train loss:0.012208487857024695\n",
      "train loss:0.031098138428634906\n",
      "train loss:0.007249713565456751\n",
      "train loss:0.046108658567558664\n",
      "train loss:0.031084135320096663\n",
      "train loss:0.006142952900582918\n",
      "train loss:0.07219895919408575\n",
      "train loss:0.02049901450980286\n",
      "train loss:0.022156767211183568\n",
      "train loss:0.05290685388307018\n",
      "train loss:0.009889101462850526\n",
      "train loss:0.019970040751418627\n",
      "train loss:0.061264818454955836\n",
      "train loss:0.031806712256200374\n",
      "train loss:0.05041771260586922\n",
      "train loss:0.04344609064168664\n",
      "train loss:0.036600482166024975\n",
      "train loss:0.10116587597687886\n",
      "train loss:0.04606397509824656\n",
      "train loss:0.021427573032060273\n",
      "train loss:0.06607744851287775\n",
      "train loss:0.04608624899732093\n",
      "train loss:0.06151892442414357\n",
      "train loss:0.007443711548163674\n",
      "train loss:0.04059724031155408\n",
      "train loss:0.015074908600132397\n",
      "train loss:0.08233869726648801\n",
      "train loss:0.07661329958857534\n",
      "train loss:0.012013475611377264\n",
      "train loss:0.017243794572084754\n",
      "train loss:0.01766451003864475\n",
      "train loss:0.022405811423398356\n",
      "train loss:0.06188244040424629\n",
      "train loss:0.14870229507504126\n",
      "train loss:0.12493995915444132\n",
      "train loss:0.01617278426855685\n",
      "train loss:0.009741256845900333\n",
      "train loss:0.024393953478967667\n",
      "train loss:0.014606123131553832\n",
      "train loss:0.05324303336280704\n",
      "train loss:0.029253799602987813\n",
      "train loss:0.021534612870583173\n",
      "train loss:0.0927107684990346\n",
      "train loss:0.015216199162743466\n",
      "train loss:0.014070685122810235\n",
      "train loss:0.06379394469537741\n",
      "train loss:0.014529603009868573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.014312112963376694\n",
      "train loss:0.013916588753247456\n",
      "train loss:0.04114959193930356\n",
      "train loss:0.018563179947164492\n",
      "train loss:0.03320038596716802\n",
      "train loss:0.048990772785480835\n",
      "train loss:0.08200496764306424\n",
      "train loss:0.049832281726933124\n",
      "train loss:0.06795214900455929\n",
      "train loss:0.01563037306840591\n",
      "train loss:0.04089530992506958\n",
      "train loss:0.008927559221355045\n",
      "train loss:0.03428931521851968\n",
      "train loss:0.027368495776879945\n",
      "train loss:0.029586519075442547\n",
      "train loss:0.024364845414624945\n",
      "train loss:0.19098491313394914\n",
      "train loss:0.020087413307364504\n",
      "train loss:0.018417325402833033\n",
      "train loss:0.008425596814447087\n",
      "train loss:0.01805480965903317\n",
      "train loss:0.027914436437216958\n",
      "train loss:0.06896277210697398\n",
      "train loss:0.029368332298407678\n",
      "train loss:0.05804053481068796\n",
      "train loss:0.03314733713553011\n",
      "train loss:0.04280349503975004\n",
      "train loss:0.03311109244013086\n",
      "train loss:0.029748541201128534\n",
      "train loss:0.053340862356354185\n",
      "train loss:0.010759379148503216\n",
      "train loss:0.015769598546858898\n",
      "train loss:0.08409201682249465\n",
      "train loss:0.01691077876523059\n",
      "train loss:0.04758152045084056\n",
      "train loss:0.007249691122578014\n",
      "train loss:0.023734022729646496\n",
      "train loss:0.02420821043189128\n",
      "train loss:0.012383355496863629\n",
      "train loss:0.02921672912403001\n",
      "train loss:0.06365280115615037\n",
      "train loss:0.018550943190192487\n",
      "train loss:0.021333760468308486\n",
      "train loss:0.009745494662830702\n",
      "train loss:0.059788123110786004\n",
      "train loss:0.02055138886085952\n",
      "train loss:0.03353384287598375\n",
      "train loss:0.061881261440079764\n",
      "train loss:0.03961715948329638\n",
      "train loss:0.04109057671658491\n",
      "train loss:0.04701039540617028\n",
      "train loss:0.07077431450970305\n",
      "train loss:0.026894112642959916\n",
      "train loss:0.028043235905440514\n",
      "train loss:0.021775239341081845\n",
      "train loss:0.023321302422728816\n",
      "train loss:0.01419731104588703\n",
      "train loss:0.028416050773271223\n",
      "train loss:0.009958214973809514\n",
      "train loss:0.03547705501183119\n",
      "train loss:0.016652756316635903\n",
      "train loss:0.05021400635323351\n",
      "train loss:0.019580169804870203\n",
      "train loss:0.03195633336265134\n",
      "train loss:0.006987674596859101\n",
      "train loss:0.04877213294675475\n",
      "train loss:0.017591466421723028\n",
      "train loss:0.07281147770666979\n",
      "train loss:0.01361761181353482\n",
      "train loss:0.07217215510997932\n",
      "train loss:0.021386754973221612\n",
      "train loss:0.0029834125736021484\n",
      "train loss:0.011086288873126357\n",
      "train loss:0.04127619773150254\n",
      "train loss:0.02647549572701101\n",
      "train loss:0.05343801902255434\n",
      "train loss:0.010424836786745263\n",
      "train loss:0.011836691050100765\n",
      "train loss:0.0682428033333236\n",
      "train loss:0.0198090023173043\n",
      "train loss:0.009790337281560105\n",
      "train loss:0.06885871584957798\n",
      "train loss:0.020478477121075745\n",
      "train loss:0.03843972588187849\n",
      "train loss:0.021257510962873497\n",
      "train loss:0.016482180807221476\n",
      "train loss:0.01730357757506822\n",
      "train loss:0.06527311066158362\n",
      "train loss:0.05379701451038967\n",
      "train loss:0.01415666298064614\n",
      "train loss:0.13111305001669696\n",
      "train loss:0.05739372291278299\n",
      "train loss:0.13727159201326275\n",
      "train loss:0.009406986111831665\n",
      "train loss:0.07200073170881614\n",
      "train loss:0.01887069697416019\n",
      "train loss:0.015732108573769957\n",
      "train loss:0.043314444659209056\n",
      "train loss:0.026510742378559708\n",
      "train loss:0.0648933354735234\n",
      "train loss:0.023128923246898338\n",
      "train loss:0.05463532892445286\n",
      "train loss:0.03750334111452775\n",
      "train loss:0.008628948064177055\n",
      "train loss:0.015790163302438032\n",
      "train loss:0.02550605900502659\n",
      "train loss:0.025370929201958648\n",
      "train loss:0.055705419945799244\n",
      "train loss:0.009662772773721358\n",
      "train loss:0.0322500555176614\n",
      "train loss:0.022094179096795924\n",
      "train loss:0.02262695391875131\n",
      "train loss:0.013381910911384059\n",
      "train loss:0.04429121542465958\n",
      "train loss:0.03566857768094493\n",
      "train loss:0.011572347226944694\n",
      "train loss:0.027855809468802378\n",
      "train loss:0.07115791901190872\n",
      "train loss:0.006259260532145797\n",
      "train loss:0.08328525902273709\n",
      "train loss:0.02379369100339691\n",
      "train loss:0.020328169155088137\n",
      "train loss:0.020423747660246353\n",
      "train loss:0.03314299991061509\n",
      "train loss:0.023398685176916727\n",
      "train loss:0.03212358148256109\n",
      "train loss:0.04077890921071603\n",
      "train loss:0.03694284308030017\n",
      "train loss:0.04038315416085629\n",
      "train loss:0.046070364853677714\n",
      "train loss:0.05247849027374129\n",
      "train loss:0.018762371341646423\n",
      "train loss:0.01927805108227857\n",
      "train loss:0.009958464759675465\n",
      "train loss:0.017079605450133782\n",
      "train loss:0.031914351570483245\n",
      "train loss:0.008970032349926736\n",
      "train loss:0.027676758043514226\n",
      "train loss:0.028965753475097788\n",
      "train loss:0.00924023890220103\n",
      "train loss:0.037863097196047565\n",
      "train loss:0.012081416826492122\n",
      "train loss:0.01539468894013261\n",
      "train loss:0.031645037413656284\n",
      "train loss:0.023178844023722597\n",
      "train loss:0.019924847403040798\n",
      "train loss:0.018863521610311473\n",
      "train loss:0.023360217109895106\n",
      "train loss:0.020918903415852803\n",
      "train loss:0.020684408133368044\n",
      "train loss:0.05470159920561911\n",
      "train loss:0.12152100017947493\n",
      "train loss:0.04978086413162842\n",
      "train loss:0.09291034600883875\n",
      "train loss:0.07717069057182685\n",
      "train loss:0.016933012899219137\n",
      "train loss:0.03320857737632291\n",
      "train loss:0.012590989848110752\n",
      "train loss:0.037309910339018336\n",
      "train loss:0.04221391839084927\n",
      "train loss:0.019025728471310475\n",
      "train loss:0.01364118580523346\n",
      "train loss:0.07493819379122328\n",
      "train loss:0.005866987040064141\n",
      "train loss:0.014505033957762259\n",
      "train loss:0.010600624428784748\n",
      "train loss:0.029248842670788276\n",
      "train loss:0.006287201479727065\n",
      "train loss:0.04723915909032875\n",
      "train loss:0.039110935064925134\n",
      "train loss:0.0087348527006345\n",
      "train loss:0.014299831838396513\n",
      "train loss:0.16880210492895467\n",
      "train loss:0.028758480047604992\n",
      "train loss:0.052191668510635614\n",
      "train loss:0.037362632501074876\n",
      "train loss:0.007653742445052334\n",
      "train loss:0.0840750133782912\n",
      "train loss:0.027618165952422394\n",
      "train loss:0.03485998078424696\n",
      "train loss:0.011405350630691313\n",
      "train loss:0.02110211698775739\n",
      "train loss:0.04027184931441454\n",
      "train loss:0.04919550440719153\n",
      "train loss:0.022826786042029347\n",
      "train loss:0.05525778245568598\n",
      "train loss:0.03553763404994901\n",
      "train loss:0.05197747108665762\n",
      "train loss:0.0163302489247407\n",
      "train loss:0.02732695858756257\n",
      "train loss:0.019940838306097167\n",
      "train loss:0.016622582678663705\n",
      "train loss:0.01961161985156168\n",
      "train loss:0.012715091933820475\n",
      "train loss:0.024808121921847445\n",
      "train loss:0.05512886201364865\n",
      "train loss:0.07746957353817999\n",
      "train loss:0.02170630627234448\n",
      "train loss:0.013319490373847885\n",
      "train loss:0.04262368826734374\n",
      "train loss:0.06556041420686597\n",
      "train loss:0.053769001302249576\n",
      "train loss:0.018627652010098937\n",
      "train loss:0.017100077460458666\n",
      "train loss:0.028620473632610714\n",
      "train loss:0.0864428012038837\n",
      "train loss:0.007492494665127356\n",
      "train loss:0.023562331169146015\n",
      "train loss:0.04271018505340126\n",
      "train loss:0.03290010833445976\n",
      "train loss:0.02342301976747821\n",
      "train loss:0.009260324993905982\n",
      "train loss:0.05152614411381782\n",
      "train loss:0.033214274785471135\n",
      "train loss:0.021619719931049518\n",
      "train loss:0.014227541900399411\n",
      "train loss:0.01297885425315917\n",
      "train loss:0.010381100352299761\n",
      "train loss:0.09439548554410802\n",
      "train loss:0.011414537140151025\n",
      "train loss:0.010240936141618218\n",
      "train loss:0.021901163647562113\n",
      "train loss:0.04106862516833157\n",
      "train loss:0.006464201410720971\n",
      "train loss:0.07934678463652355\n",
      "train loss:0.03657000166855406\n",
      "train loss:0.045514895594413074\n",
      "train loss:0.012040042085411524\n",
      "train loss:0.015340232535815488\n",
      "train loss:0.07166030003126506\n",
      "train loss:0.013368336674090462\n",
      "train loss:0.05886585673475611\n",
      "train loss:0.02265133101489345\n",
      "train loss:0.034468915109105075\n",
      "train loss:0.02745401539052932\n",
      "train loss:0.008969767505382696\n",
      "train loss:0.0258515651530507\n",
      "train loss:0.04424515661146499\n",
      "train loss:0.07454974365792875\n",
      "train loss:0.00933672146915222\n",
      "train loss:0.02102545923673754\n",
      "train loss:0.02578267044142492\n",
      "train loss:0.053859434450061555\n",
      "train loss:0.024561964037323046\n",
      "train loss:0.02288348529065027\n",
      "train loss:0.01865427081601198\n",
      "train loss:0.015696811236517925\n",
      "train loss:0.013468475585223585\n",
      "train loss:0.011524111529748497\n",
      "train loss:0.01095277112736054\n",
      "train loss:0.014817180960257257\n",
      "train loss:0.020731289410939966\n",
      "train loss:0.002478752896302283\n",
      "train loss:0.009210570506013272\n",
      "train loss:0.02024965775085149\n",
      "train loss:0.012601568308025604\n",
      "train loss:0.01047354594270563\n",
      "train loss:0.03601487260112761\n",
      "train loss:0.011842911034280573\n",
      "train loss:0.08111318884417709\n",
      "train loss:0.026524456974713756\n",
      "train loss:0.006153091320637196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015426263492655272\n",
      "train loss:0.042825941764285426\n",
      "train loss:0.01790017877556698\n",
      "train loss:0.02611524794925481\n",
      "train loss:0.034853915518617926\n",
      "train loss:0.04285004388503678\n",
      "train loss:0.012215710483490962\n",
      "train loss:0.01391955334986591\n",
      "train loss:0.011422133412271766\n",
      "train loss:0.010121075909794754\n",
      "train loss:0.026844079226568413\n",
      "train loss:0.01722788906503492\n",
      "train loss:0.08443896456353349\n",
      "train loss:0.0059799921739049945\n",
      "train loss:0.05767837618675856\n",
      "train loss:0.027049932859295897\n",
      "train loss:0.03427265949906211\n",
      "train loss:0.02785545495985616\n",
      "train loss:0.020390705782241475\n",
      "train loss:0.015173184429290594\n",
      "train loss:0.01525290253872388\n",
      "train loss:0.060748437841762384\n",
      "train loss:0.03308627214330856\n",
      "train loss:0.016529811306222653\n",
      "train loss:0.08034737866999342\n",
      "train loss:0.09337786496589065\n",
      "train loss:0.028150410022436935\n",
      "train loss:0.017614312260548593\n",
      "train loss:0.05082953477054025\n",
      "train loss:0.08591602018907826\n",
      "train loss:0.026808000758221286\n",
      "train loss:0.07393385956338222\n",
      "train loss:0.03017501414474087\n",
      "train loss:0.02187238002038137\n",
      "train loss:0.0444503467385371\n",
      "train loss:0.016166930356699125\n",
      "train loss:0.04054421655276471\n",
      "train loss:0.04577021971884685\n",
      "train loss:0.020028210276497312\n",
      "train loss:0.03366331375501166\n",
      "train loss:0.009459466557532251\n",
      "train loss:0.07070473611801485\n",
      "train loss:0.018944124406122823\n",
      "train loss:0.02415615543302918\n",
      "train loss:0.015988919279089745\n",
      "train loss:0.007486607363923191\n",
      "train loss:0.033668494152833996\n",
      "train loss:0.02093500371348232\n",
      "train loss:0.07905425140650876\n",
      "train loss:0.037642163881414926\n",
      "train loss:0.018085680680749776\n",
      "train loss:0.0035358868104650547\n",
      "train loss:0.06488356433922152\n",
      "train loss:0.0390431536393989\n",
      "train loss:0.01220938885820164\n",
      "train loss:0.014338857470809388\n",
      "train loss:0.055144309773772264\n",
      "train loss:0.004905353253079724\n",
      "train loss:0.005933268634959954\n",
      "train loss:0.05876176673704091\n",
      "train loss:0.017727938881068148\n",
      "train loss:0.046074868701822404\n",
      "train loss:0.034076355894422754\n",
      "train loss:0.012432278769112515\n",
      "train loss:0.04555368999909642\n",
      "train loss:0.08837665302291026\n",
      "train loss:0.05888162524980732\n",
      "train loss:0.01148228778551737\n",
      "train loss:0.07473210431897793\n",
      "train loss:0.029496214577680098\n",
      "train loss:0.010317931963606853\n",
      "train loss:0.06355091867880985\n",
      "train loss:0.027356951037338276\n",
      "train loss:0.058557043176326255\n",
      "train loss:0.005856652180014153\n",
      "train loss:0.021432587884497093\n",
      "train loss:0.0525357105844143\n",
      "train loss:0.013749219145055685\n",
      "train loss:0.03658555180915676\n",
      "train loss:0.03005685599964937\n",
      "train loss:0.07160362449790973\n",
      "train loss:0.01635085360672429\n",
      "train loss:0.01558105394418214\n",
      "train loss:0.02577999919741885\n",
      "train loss:0.11854896103481796\n",
      "train loss:0.0165740827602482\n",
      "train loss:0.12271893833780352\n",
      "train loss:0.02133446373657217\n",
      "train loss:0.04467843495999672\n",
      "train loss:0.02117901238828078\n",
      "train loss:0.04972402071971426\n",
      "train loss:0.01740136208163269\n",
      "train loss:0.08196471933532376\n",
      "train loss:0.008512716332418737\n",
      "train loss:0.0067472740513602825\n",
      "train loss:0.020323875388281308\n",
      "train loss:0.02936440008566021\n",
      "train loss:0.018420292794061256\n",
      "train loss:0.012381031464264346\n",
      "train loss:0.005264945527150908\n",
      "train loss:0.01143842309839015\n",
      "train loss:0.02467778607114089\n",
      "train loss:0.022234401552606725\n",
      "train loss:0.015220664772548284\n",
      "train loss:0.05781033150461066\n",
      "train loss:0.006350247753884665\n",
      "train loss:0.02139105132474947\n",
      "train loss:0.013168416064478536\n",
      "train loss:0.015442729998669368\n",
      "train loss:0.014566519274643322\n",
      "train loss:0.024480091984463197\n",
      "train loss:0.05457425338803354\n",
      "train loss:0.007489451042873539\n",
      "train loss:0.005010127747106175\n",
      "train loss:0.014457142568216137\n",
      "train loss:0.008892882952148734\n",
      "train loss:0.034854647944679636\n",
      "train loss:0.024232634532966917\n",
      "train loss:0.024853567849908078\n",
      "train loss:0.009489249612326243\n",
      "train loss:0.032918662691694384\n",
      "train loss:0.028614306536185213\n",
      "train loss:0.013256872270313282\n",
      "train loss:0.029494800672678834\n",
      "train loss:0.030990181584484647\n",
      "train loss:0.04616519809251271\n",
      "train loss:0.07782963970133282\n",
      "train loss:0.005945714348889301\n",
      "train loss:0.005487220473864902\n",
      "train loss:0.010221526395468321\n",
      "train loss:0.012835950601730534\n",
      "train loss:0.02325805078937775\n",
      "train loss:0.03350496879639409\n",
      "train loss:0.03239951456360539\n",
      "train loss:0.011352382522960437\n",
      "train loss:0.016772486437024867\n",
      "train loss:0.008085455989861219\n",
      "train loss:0.02269208740039559\n",
      "train loss:0.03260394662747878\n",
      "train loss:0.023571246503390854\n",
      "train loss:0.010907031234116899\n",
      "train loss:0.014743596363407734\n",
      "train loss:0.06442249482568982\n",
      "train loss:0.008457474858920679\n",
      "train loss:0.0023472863582984405\n",
      "train loss:0.0034221669913503693\n",
      "train loss:0.013316440364449124\n",
      "train loss:0.012939536328606142\n",
      "train loss:0.04525287383819525\n",
      "train loss:0.02321576354442079\n",
      "train loss:0.032806227848254904\n",
      "train loss:0.023547074831846825\n",
      "train loss:0.01572531527176695\n",
      "train loss:0.07979559196734227\n",
      "train loss:0.016368361632950575\n",
      "train loss:0.04823235271678932\n",
      "train loss:0.020337542322988456\n",
      "train loss:0.0049574751995327\n",
      "train loss:0.03818461099812101\n",
      "train loss:0.016887960954854703\n",
      "train loss:0.016122333275367842\n",
      "train loss:0.03179732626583901\n",
      "train loss:0.04310024070980498\n",
      "train loss:0.0475841528063472\n",
      "train loss:0.020257880240566156\n",
      "train loss:0.003905897466329376\n",
      "train loss:0.01703182869922965\n",
      "train loss:0.007223619491540595\n",
      "train loss:0.025364179972828502\n",
      "train loss:0.007272600150313804\n",
      "train loss:0.02313088180840921\n",
      "train loss:0.01795174369304423\n",
      "train loss:0.024384778913024253\n",
      "train loss:0.00747346463745835\n",
      "train loss:0.03614075188429863\n",
      "train loss:0.008106397971389121\n",
      "train loss:0.008848064328203708\n",
      "train loss:0.02308242165904194\n",
      "train loss:0.019229661052126725\n",
      "train loss:0.021249115796454842\n",
      "train loss:0.020823470239970346\n",
      "train loss:0.03604209615729337\n",
      "train loss:0.013134396235270917\n",
      "train loss:0.0056799238316894915\n",
      "train loss:0.010448905072211238\n",
      "train loss:0.0026403411761336034\n",
      "train loss:0.10559627956499211\n",
      "train loss:0.022639396175605318\n",
      "train loss:0.06811456094618354\n",
      "train loss:0.01546753706591004\n",
      "train loss:0.011659203382552098\n",
      "train loss:0.02535668632727195\n",
      "train loss:0.012554294132521798\n",
      "train loss:0.013543160823142686\n",
      "train loss:0.03994782894930284\n",
      "train loss:0.04300872851665958\n",
      "train loss:0.05476751092577075\n",
      "train loss:0.007505761438905841\n",
      "train loss:0.006228502194303175\n",
      "train loss:0.027238723380315143\n",
      "train loss:0.06296589372188692\n",
      "train loss:0.022715784787928826\n",
      "train loss:0.023425953656788526\n",
      "train loss:0.018139427994212386\n",
      "train loss:0.029875953703915423\n",
      "train loss:0.008705927921783915\n",
      "train loss:0.02186517140191277\n",
      "train loss:0.027669808556936126\n",
      "train loss:0.03200281128519385\n",
      "train loss:0.05124181167147127\n",
      "train loss:0.008602736260151757\n",
      "train loss:0.02641326362047189\n",
      "train loss:0.1055880704830969\n",
      "train loss:0.056253755705431764\n",
      "train loss:0.01163807676858689\n",
      "train loss:0.016393289298781505\n",
      "train loss:0.017784760822307493\n",
      "train loss:0.017507592306326134\n",
      "train loss:0.030799365890894895\n",
      "train loss:0.019779962982670474\n",
      "train loss:0.028171279693475295\n",
      "train loss:0.005509768809478862\n",
      "train loss:0.06965037375812476\n",
      "train loss:0.04891355685513186\n",
      "train loss:0.023550400532675056\n",
      "train loss:0.014430166653551997\n",
      "train loss:0.08354190771067645\n",
      "train loss:0.014041004589495603\n",
      "train loss:0.014326448195962526\n",
      "train loss:0.02069665470539022\n",
      "train loss:0.02006598890652292\n",
      "train loss:0.042247686589572495\n",
      "train loss:0.024131354621018623\n",
      "train loss:0.022929546293819856\n",
      "train loss:0.007014939649341545\n",
      "train loss:0.01851118104649014\n",
      "train loss:0.025879882537378232\n",
      "train loss:0.005870827250232294\n",
      "train loss:0.040539500220998885\n",
      "train loss:0.0200357408238452\n",
      "train loss:0.0482910052077979\n",
      "train loss:0.01517884835340287\n",
      "train loss:0.020172725796471697\n",
      "train loss:0.004305495884994917\n",
      "train loss:0.011873413558482005\n",
      "train loss:0.005401424433963949\n",
      "train loss:0.045011764529970286\n",
      "train loss:0.05477921125220257\n",
      "train loss:0.058733160073535115\n",
      "train loss:0.01872362162865546\n",
      "train loss:0.01980175245881174\n",
      "train loss:0.02283238304088832\n",
      "train loss:0.022214261660759956\n",
      "train loss:0.03041442087776157\n",
      "train loss:0.021659708612237795\n",
      "train loss:0.009449138122914383\n",
      "train loss:0.005429281675983047\n",
      "train loss:0.022665233387609743\n",
      "train loss:0.15684578179434833\n",
      "train loss:0.048021717375032115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.005220236402366751\n",
      "train loss:0.01461210245947747\n",
      "train loss:0.011628992526457313\n",
      "train loss:0.0476289750172054\n",
      "train loss:0.025692735903949583\n",
      "train loss:0.028239560496131334\n",
      "train loss:0.026127518522459616\n",
      "train loss:0.00836147938671319\n",
      "train loss:0.008217908794452562\n",
      "train loss:0.004369397434166865\n",
      "train loss:0.06049106778501806\n",
      "train loss:0.014759117164822427\n",
      "train loss:0.01794401801253088\n",
      "train loss:0.028186518004355593\n",
      "train loss:0.0266629899070679\n",
      "train loss:0.012886001108748999\n",
      "train loss:0.012926104582712896\n",
      "train loss:0.01667433680863336\n",
      "train loss:0.015074797692384755\n",
      "train loss:0.04497387016759305\n",
      "train loss:0.026142715663952872\n",
      "train loss:0.006145703848072511\n",
      "train loss:0.0098110099893905\n",
      "train loss:0.02240160296034183\n",
      "train loss:0.04194693182719044\n",
      "train loss:0.01938985910688863\n",
      "train loss:0.026703306483650636\n",
      "train loss:0.008566460027477525\n",
      "train loss:0.05198446529408693\n",
      "=== epoch:5, train acc:0.985, test acc:0.978 ===\n",
      "train loss:0.01630329020637853\n",
      "train loss:0.010370790135675007\n",
      "train loss:0.05359320205246545\n",
      "train loss:0.006218388363710406\n",
      "train loss:0.03422094259481383\n",
      "train loss:0.038634978243128094\n",
      "train loss:0.04343928566430298\n",
      "train loss:0.017010222880587636\n",
      "train loss:0.01277725361643412\n",
      "train loss:0.012570436715139393\n",
      "train loss:0.004566320877603087\n",
      "train loss:0.022906803460467855\n",
      "train loss:0.03535702649446967\n",
      "train loss:0.012106817483203927\n",
      "train loss:0.02733524216534344\n",
      "train loss:0.009076044001694272\n",
      "train loss:0.009192374784811906\n",
      "train loss:0.05551579251499411\n",
      "train loss:0.019717377850489895\n",
      "train loss:0.07937443086936095\n",
      "train loss:0.08243877845085061\n",
      "train loss:0.021657025231808392\n",
      "train loss:0.04520739632680284\n",
      "train loss:0.015254921170134019\n",
      "train loss:0.012935811156041352\n",
      "train loss:0.024253986862504243\n",
      "train loss:0.029016177964232188\n",
      "train loss:0.06812915949947626\n",
      "train loss:0.009782779966320328\n",
      "train loss:0.05525247468209635\n",
      "train loss:0.03324616983148292\n",
      "train loss:0.007462644548405669\n",
      "train loss:0.026364427681461303\n",
      "train loss:0.03865449340637027\n",
      "train loss:0.032652725991007034\n",
      "train loss:0.11535883863280326\n",
      "train loss:0.021500832192352468\n",
      "train loss:0.013007097810116107\n",
      "train loss:0.08092736484623099\n",
      "train loss:0.09785828839840507\n",
      "train loss:0.005591862102512175\n",
      "train loss:0.014724069510622263\n",
      "train loss:0.04151879637449547\n",
      "train loss:0.016749562717355296\n",
      "train loss:0.014580007405409719\n",
      "train loss:0.02208668883479327\n",
      "train loss:0.005919423525793904\n",
      "train loss:0.008837046552659577\n",
      "train loss:0.016505841950381298\n",
      "train loss:0.01306703607833069\n",
      "train loss:0.03957131583028472\n",
      "train loss:0.011637026519466308\n",
      "train loss:0.010331444761878633\n",
      "train loss:0.023454525650377697\n",
      "train loss:0.009008599129249612\n",
      "train loss:0.044259420396099855\n",
      "train loss:0.02706313497510503\n",
      "train loss:0.018088599064928004\n",
      "train loss:0.004605491670038777\n",
      "train loss:0.006071366140238117\n",
      "train loss:0.006575581012733849\n",
      "train loss:0.013617260006241316\n",
      "train loss:0.008124520540835947\n",
      "train loss:0.016008091900840057\n",
      "train loss:0.022509385144416055\n",
      "train loss:0.036216452774386336\n",
      "train loss:0.008103880293535159\n",
      "train loss:0.005641562553667902\n",
      "train loss:0.011553233719628747\n",
      "train loss:0.006770071071937771\n",
      "train loss:0.02852727901182523\n",
      "train loss:0.011475217041207282\n",
      "train loss:0.044582340229524696\n",
      "train loss:0.007098209201872469\n",
      "train loss:0.0157137445474595\n",
      "train loss:0.005388508306971043\n",
      "train loss:0.07355826774376578\n",
      "train loss:0.03733982857995852\n",
      "train loss:0.009943299164121414\n",
      "train loss:0.04675106166929346\n",
      "train loss:0.01765529232186317\n",
      "train loss:0.06641088908695914\n",
      "train loss:0.008633263796910835\n",
      "train loss:0.0220427922077357\n",
      "train loss:0.018670288216586343\n",
      "train loss:0.044520929787330354\n",
      "train loss:0.012057975484803508\n",
      "train loss:0.027295600601147902\n",
      "train loss:0.03477401988928449\n",
      "train loss:0.00927049025377902\n",
      "train loss:0.0030066388920139144\n",
      "train loss:0.021294040556637327\n",
      "train loss:0.013233567818614662\n",
      "train loss:0.06812559679493177\n",
      "train loss:0.008487783944403976\n",
      "train loss:0.012961165257584627\n",
      "train loss:0.009223312599145895\n",
      "train loss:0.009594668770884501\n",
      "train loss:0.05302569512332898\n",
      "train loss:0.016778016575939074\n",
      "train loss:0.04684670481002862\n",
      "train loss:0.0078073204973434385\n",
      "train loss:0.02574315654925108\n",
      "train loss:0.02074865713926996\n",
      "train loss:0.028493014556833243\n",
      "train loss:0.00556371496104295\n",
      "train loss:0.015464508640951651\n",
      "train loss:0.011750444813734558\n",
      "train loss:0.010700492621487073\n",
      "train loss:0.005929476862193468\n",
      "train loss:0.014447495179020253\n",
      "train loss:0.018774507347660736\n",
      "train loss:0.014917547855827766\n",
      "train loss:0.08846306190373618\n",
      "train loss:0.04252463119120184\n",
      "train loss:0.0449929748412683\n",
      "train loss:0.012218245639574764\n",
      "train loss:0.07335709242437022\n",
      "train loss:0.009087884483338905\n",
      "train loss:0.012761204924640685\n",
      "train loss:0.014487553756939948\n",
      "train loss:0.04069645648402521\n",
      "train loss:0.01761880044857099\n",
      "train loss:0.02417613365691034\n",
      "train loss:0.01679287013910294\n",
      "train loss:0.007516904471253807\n",
      "train loss:0.014352182160963966\n",
      "train loss:0.028739399107889335\n",
      "train loss:0.010673616150969702\n",
      "train loss:0.0034252185244104845\n",
      "train loss:0.04806386321949585\n",
      "train loss:0.045432528730039785\n",
      "train loss:0.018972974466276483\n",
      "train loss:0.008011766809364253\n",
      "train loss:0.007411199584340078\n",
      "train loss:0.02198588552946682\n",
      "train loss:0.010341842312340777\n",
      "train loss:0.012922500832053345\n",
      "train loss:0.016865489181928962\n",
      "train loss:0.008603968633320802\n",
      "train loss:0.01359660518652527\n",
      "train loss:0.05032983358470951\n",
      "train loss:0.010547384310324757\n",
      "train loss:0.035553379723297994\n",
      "train loss:0.027007828938879704\n",
      "train loss:0.11871281561209691\n",
      "train loss:0.010630172901981776\n",
      "train loss:0.0359714225978276\n",
      "train loss:0.05430370830263307\n",
      "train loss:0.012786368300931779\n",
      "train loss:0.04598110846949086\n",
      "train loss:0.010055470845554956\n",
      "train loss:0.005448044262501058\n",
      "train loss:0.08889457776433327\n",
      "train loss:0.06462780125739478\n",
      "train loss:0.020395507021835377\n",
      "train loss:0.047687623097226156\n",
      "train loss:0.016609000083559273\n",
      "train loss:0.005989898279421018\n",
      "train loss:0.014171074591527581\n",
      "train loss:0.002973680430381406\n",
      "train loss:0.07534351145739841\n",
      "train loss:0.05351074834792497\n",
      "train loss:0.03304974125947221\n",
      "train loss:0.02064302756059516\n",
      "train loss:0.011029799935587573\n",
      "train loss:0.016103608299626523\n",
      "train loss:0.0998053510087779\n",
      "train loss:0.007458049314540056\n",
      "train loss:0.17156571442874344\n",
      "train loss:0.022597191985433543\n",
      "train loss:0.05190837930352346\n",
      "train loss:0.0749848550387666\n",
      "train loss:0.02931039150959659\n",
      "train loss:0.024038230120602796\n",
      "train loss:0.048035349775726335\n",
      "train loss:0.040307654895418855\n",
      "train loss:0.009209785654998269\n",
      "train loss:0.03139053967135596\n",
      "train loss:0.006036627137096058\n",
      "train loss:0.01601921852526005\n",
      "train loss:0.019021484128461493\n",
      "train loss:0.011479542238586517\n",
      "train loss:0.014987214236611106\n",
      "train loss:0.03171537306235058\n",
      "train loss:0.009801387182168666\n",
      "train loss:0.008274536793183134\n",
      "train loss:0.017420529765637766\n",
      "train loss:0.071723944974746\n",
      "train loss:0.007559853052486248\n",
      "train loss:0.019693831033293356\n",
      "train loss:0.025312567258563817\n",
      "train loss:0.017030289965882416\n",
      "train loss:0.10019592951241256\n",
      "train loss:0.029045488514676487\n",
      "train loss:0.032150482668015005\n",
      "train loss:0.027923583701086153\n",
      "train loss:0.0383578902158278\n",
      "train loss:0.014159648403900658\n",
      "train loss:0.006670428206554368\n",
      "train loss:0.08222727423143088\n",
      "train loss:0.024147698090439457\n",
      "train loss:0.008629485272075795\n",
      "train loss:0.03290115941022669\n",
      "train loss:0.004294335884168243\n",
      "train loss:0.003464177589468367\n",
      "train loss:0.00801183820688715\n",
      "train loss:0.015337034163601297\n",
      "train loss:0.014363057525444938\n",
      "train loss:0.025245354655204114\n",
      "train loss:0.11350187524478905\n",
      "train loss:0.029972315952244557\n",
      "train loss:0.027392978685285084\n",
      "train loss:0.0371245484785462\n",
      "train loss:0.05396428228800893\n",
      "train loss:0.014686572349712273\n",
      "train loss:0.02161518791579797\n",
      "train loss:0.018378572841098905\n",
      "train loss:0.008566124963639813\n",
      "train loss:0.011880403359742027\n",
      "train loss:0.015413432208118765\n",
      "train loss:0.007281888247211328\n",
      "train loss:0.025804540173936248\n",
      "train loss:0.010378118113874997\n",
      "train loss:0.026790336928588742\n",
      "train loss:0.02522198915441779\n",
      "train loss:0.04605440486830489\n",
      "train loss:0.02670406909434572\n",
      "train loss:0.007244820006845296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.21320855677997025\n",
      "train loss:0.014031870164142743\n",
      "train loss:0.028174647450113496\n",
      "train loss:0.05258976532182851\n",
      "train loss:0.019075688384846943\n",
      "train loss:0.007186956537734947\n",
      "train loss:0.017592699823997776\n",
      "train loss:0.017351536099047295\n",
      "train loss:0.03061236074904643\n",
      "train loss:0.028497607929377847\n",
      "train loss:0.011707646584413067\n",
      "train loss:0.044726124112629814\n",
      "train loss:0.012137247834673933\n",
      "train loss:0.003533536680684506\n",
      "train loss:0.004813092782845251\n",
      "train loss:0.01878980257135193\n",
      "train loss:0.035228520245718487\n",
      "train loss:0.010077349669799356\n",
      "train loss:0.008431374312492353\n",
      "train loss:0.009181411247804298\n",
      "train loss:0.039933938177407875\n",
      "train loss:0.06480563953964136\n",
      "train loss:0.014293910381205099\n",
      "train loss:0.012942559232261659\n",
      "train loss:0.08183237989751058\n",
      "train loss:0.07205892302309919\n",
      "train loss:0.04403580925080997\n",
      "train loss:0.042863904555062005\n",
      "train loss:0.007360042505480108\n",
      "train loss:0.025362965286237917\n",
      "train loss:0.08281354619891157\n",
      "train loss:0.0055856120849343575\n",
      "train loss:0.048070879347050954\n",
      "train loss:0.029616275185946773\n",
      "train loss:0.03469156995479284\n",
      "train loss:0.02009587801135946\n",
      "train loss:0.013267219237602587\n",
      "train loss:0.008034953276665327\n",
      "train loss:0.007108549990402575\n",
      "train loss:0.030954084949341\n",
      "train loss:0.09102162897528218\n",
      "train loss:0.033563400557737794\n",
      "train loss:0.016502274589494787\n",
      "train loss:0.010201536077661085\n",
      "train loss:0.021449521471685176\n",
      "train loss:0.02476610513480876\n",
      "train loss:0.004679210457783244\n",
      "train loss:0.029415690186343615\n",
      "train loss:0.020973860960551805\n",
      "train loss:0.0080237024338163\n",
      "train loss:0.00919076603488841\n",
      "train loss:0.06595942655088158\n",
      "train loss:0.028950114479280073\n",
      "train loss:0.034463847597731856\n",
      "train loss:0.11585800668100571\n",
      "train loss:0.012054294230860095\n",
      "train loss:0.006660645358404502\n",
      "train loss:0.019946910889575484\n",
      "train loss:0.027831347772896115\n",
      "train loss:0.012477415660752961\n",
      "train loss:0.027120713361429957\n",
      "train loss:0.05624990802615249\n",
      "train loss:0.07543907142241257\n",
      "train loss:0.011533230467557285\n",
      "train loss:0.03551860316031799\n",
      "train loss:0.03609840949667335\n",
      "train loss:0.006362954600197756\n",
      "train loss:0.019628217326977445\n",
      "train loss:0.037315736805118606\n",
      "train loss:0.0062718299550942125\n",
      "train loss:0.014052059705675593\n",
      "train loss:0.01747547414956173\n",
      "train loss:0.01820034231062184\n",
      "train loss:0.011641100094788978\n",
      "train loss:0.016008755415235137\n",
      "train loss:0.016999869065261672\n",
      "train loss:0.0204282976935247\n",
      "train loss:0.01815146050006114\n",
      "train loss:0.022834456087923304\n",
      "train loss:0.02440428930891596\n",
      "train loss:0.015934732057419604\n",
      "train loss:0.00967330979135813\n",
      "train loss:0.009871306707913644\n",
      "train loss:0.016314153910590403\n",
      "train loss:0.003596594474697669\n",
      "train loss:0.008654102488104954\n",
      "train loss:0.05427945955029742\n",
      "train loss:0.018535761578037338\n",
      "train loss:0.012093474149553198\n",
      "train loss:0.008115452780968847\n",
      "train loss:0.01071696325218996\n",
      "train loss:0.018750820921105932\n",
      "train loss:0.00519341548287347\n",
      "train loss:0.02108802704830486\n",
      "train loss:0.011165794013342905\n",
      "train loss:0.002389019957404802\n",
      "train loss:0.006047815573986845\n",
      "train loss:0.027184505733760692\n",
      "train loss:0.009122271719493818\n",
      "train loss:0.036227638507163526\n",
      "train loss:0.0056873210559491615\n",
      "train loss:0.023133023224300484\n",
      "train loss:0.03636608741397389\n",
      "train loss:0.017176976821312966\n",
      "train loss:0.017991160706375995\n",
      "train loss:0.023894200359217542\n",
      "train loss:0.06477694993062942\n",
      "train loss:0.015819895637067\n",
      "train loss:0.02155164298700732\n",
      "train loss:0.023601045503218954\n",
      "train loss:0.0413265273088984\n",
      "train loss:0.014927016654264956\n",
      "train loss:0.02456216101778059\n",
      "train loss:0.04663572818706866\n",
      "train loss:0.018073414220088842\n",
      "train loss:0.02601005382589028\n",
      "train loss:0.021861877865689897\n",
      "train loss:0.004164699307497235\n",
      "train loss:0.007309455325896456\n",
      "train loss:0.010804313338742336\n",
      "train loss:0.049490197502004604\n",
      "train loss:0.014820026585328883\n",
      "train loss:0.023411632304089252\n",
      "train loss:0.007076727785805462\n",
      "train loss:0.014956852378806857\n",
      "train loss:0.018485637041897117\n",
      "train loss:0.014483225684211763\n",
      "train loss:0.019163150542971918\n",
      "train loss:0.015737359351993982\n",
      "train loss:0.003980756648734027\n",
      "train loss:0.012203595784387322\n",
      "train loss:0.024709990260818916\n",
      "train loss:0.02560058228766395\n",
      "train loss:0.019946402795350066\n",
      "train loss:0.005756009940772847\n",
      "train loss:0.07259517632378229\n",
      "train loss:0.034012482148510624\n",
      "train loss:0.016914058500992722\n",
      "train loss:0.010558365254376735\n",
      "train loss:0.003084673812921206\n",
      "train loss:0.02050738116700966\n",
      "train loss:0.03705003887254529\n",
      "train loss:0.010296053296688857\n",
      "train loss:0.007898673453268891\n",
      "train loss:0.037370172854745934\n",
      "train loss:0.016736462882315235\n",
      "train loss:0.009133154372851273\n",
      "train loss:0.036255184817709236\n",
      "train loss:0.022959347065435565\n",
      "train loss:0.13272546037339028\n",
      "train loss:0.06887435738808775\n",
      "train loss:0.008264715067233579\n",
      "train loss:0.046098550362641974\n",
      "train loss:0.012039001194273495\n",
      "train loss:0.005106590219732004\n",
      "train loss:0.07992291759005314\n",
      "train loss:0.00485051041366181\n",
      "train loss:0.03793307957675961\n",
      "train loss:0.008283034774054402\n",
      "train loss:0.024255087624882953\n",
      "train loss:0.06700862151649463\n",
      "train loss:0.020830317992679336\n",
      "train loss:0.024018969205672102\n",
      "train loss:0.030341834441745964\n",
      "train loss:0.03607275813557726\n",
      "train loss:0.01900844363625412\n",
      "train loss:0.0538596835779825\n",
      "train loss:0.012816993927002456\n",
      "train loss:0.01988482840432543\n",
      "train loss:0.07807278780999993\n",
      "train loss:0.008012621392758322\n",
      "train loss:0.0168255483493036\n",
      "train loss:0.014807010782269169\n",
      "train loss:0.003374068600261822\n",
      "train loss:0.010626310541030715\n",
      "train loss:0.04402209052784811\n",
      "train loss:0.02076767762890951\n",
      "train loss:0.02274384652896276\n",
      "train loss:0.00773183875511978\n",
      "train loss:0.006748810625099268\n",
      "train loss:0.033752778952176175\n",
      "train loss:0.034133970188132606\n",
      "train loss:0.0056684986809473455\n",
      "train loss:0.02421702629394416\n",
      "train loss:0.07718810123245434\n",
      "train loss:0.0284832155672108\n",
      "train loss:0.009760101910390758\n",
      "train loss:0.009338455237935894\n",
      "train loss:0.009224844578251793\n",
      "train loss:0.012459098697309599\n",
      "train loss:0.04285480217809818\n",
      "train loss:0.015761671570743693\n",
      "train loss:0.017397472041164912\n",
      "train loss:0.018104170044347626\n",
      "train loss:0.027799697097845456\n",
      "train loss:0.020263374648864158\n",
      "train loss:0.023850975973352014\n",
      "train loss:0.0620789790498094\n",
      "train loss:0.03204060027905848\n",
      "train loss:0.022945331431024348\n",
      "train loss:0.0576717867477359\n",
      "train loss:0.011574899501549014\n",
      "train loss:0.015379158197942442\n",
      "train loss:0.003448550849892588\n",
      "train loss:0.022938913241036255\n",
      "train loss:0.003764539105213724\n",
      "train loss:0.038395227254102736\n",
      "train loss:0.007808726293591465\n",
      "train loss:0.01285440416745731\n",
      "train loss:0.06799366001898807\n",
      "train loss:0.006923945287785\n",
      "train loss:0.030173539772761063\n",
      "train loss:0.014914572211271555\n",
      "train loss:0.01672371996065385\n",
      "train loss:0.015785767913498516\n",
      "train loss:0.007774138925328185\n",
      "train loss:0.06823036284854304\n",
      "train loss:0.010994366849555905\n",
      "train loss:0.02070678932812921\n",
      "train loss:0.0019069623025159354\n",
      "train loss:0.0050295356362397795\n",
      "train loss:0.014060722013917854\n",
      "train loss:0.00564936157887547\n",
      "train loss:0.010201464171008832\n",
      "train loss:0.01588651984042649\n",
      "train loss:0.007924982197809589\n",
      "train loss:0.0074139628927604425\n",
      "train loss:0.03435382300896703\n",
      "train loss:0.0020641046108679324\n",
      "train loss:0.0416204844642783\n",
      "train loss:0.00525627427626127\n",
      "train loss:0.009733610090708304\n",
      "train loss:0.005278311678933484\n",
      "train loss:0.0032772224718405885\n",
      "train loss:0.009947893009451418\n",
      "train loss:0.006559697378022463\n",
      "train loss:0.006310047861140786\n",
      "train loss:0.009585970570336834\n",
      "train loss:0.015724813890322167\n",
      "train loss:0.007032162432493019\n",
      "train loss:0.022775668354155187\n",
      "train loss:0.005362034057841827\n",
      "train loss:0.03435177680344477\n",
      "train loss:0.038953988959129895\n",
      "train loss:0.055426748450552864\n",
      "train loss:0.003953400471173136\n",
      "train loss:0.04603362986684372\n",
      "train loss:0.02570070463264698\n",
      "train loss:0.05000474217378832\n",
      "train loss:0.017697597255901847\n",
      "train loss:0.02485505322511794\n",
      "train loss:0.026381375651063018\n",
      "train loss:0.04850075357056356\n",
      "train loss:0.033054836462045614\n",
      "train loss:0.007305306749545948\n",
      "train loss:0.017971602561978658\n",
      "train loss:0.05504227861501374\n",
      "train loss:0.012954279934431316\n",
      "train loss:0.0047139487364374726\n",
      "train loss:0.010275864504201388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009409392725419597\n",
      "train loss:0.010404641508471178\n",
      "train loss:0.006420527653659038\n",
      "train loss:0.0723452474397678\n",
      "train loss:0.006027956789264154\n",
      "train loss:0.027376935950739797\n",
      "train loss:0.0016184328926041713\n",
      "train loss:0.007079871925075978\n",
      "train loss:0.00884236144032319\n",
      "train loss:0.05261696528488122\n",
      "train loss:0.026456338977058437\n",
      "train loss:0.009191122777951638\n",
      "train loss:0.10343768716689511\n",
      "train loss:0.005764245285961773\n",
      "train loss:0.012522331739816275\n",
      "train loss:0.007535574881243408\n",
      "train loss:0.010677876045675983\n",
      "train loss:0.00965262976004616\n",
      "train loss:0.034704548027388024\n",
      "train loss:0.01195024549858595\n",
      "train loss:0.02519999977584353\n",
      "train loss:0.008769180908339686\n",
      "train loss:0.011036863296875357\n",
      "train loss:0.009476670326494017\n",
      "train loss:0.01270946651713253\n",
      "train loss:0.06277683812423066\n",
      "train loss:0.003374514841861105\n",
      "train loss:0.03155585530984487\n",
      "train loss:0.009308463072320382\n",
      "train loss:0.02014188986397403\n",
      "train loss:0.024640636130562887\n",
      "train loss:0.0015128150437230608\n",
      "train loss:0.022106260786190116\n",
      "train loss:0.005127064687808597\n",
      "train loss:0.045742996309626145\n",
      "train loss:0.005985760046642241\n",
      "train loss:0.02145551785076684\n",
      "train loss:0.014983895445709319\n",
      "train loss:0.014305430696252919\n",
      "train loss:0.019029467434359994\n",
      "train loss:0.015853925825522423\n",
      "train loss:0.0035696738792499742\n",
      "train loss:0.02443695211188891\n",
      "train loss:0.057494328433684204\n",
      "train loss:0.004569616746423233\n",
      "train loss:0.013744433254535051\n",
      "train loss:0.013542628406679105\n",
      "train loss:0.019507196409351113\n",
      "train loss:0.01533110261521575\n",
      "train loss:0.007012089192089066\n",
      "train loss:0.002883592679607877\n",
      "train loss:0.0049361046894631925\n",
      "train loss:0.010762417180352033\n",
      "train loss:0.02286524007583728\n",
      "train loss:0.01959424519149225\n",
      "train loss:0.07007283190631088\n",
      "train loss:0.029158754783244572\n",
      "train loss:0.008260657953702179\n",
      "train loss:0.026868002264683968\n",
      "train loss:0.006747294851637776\n",
      "train loss:0.0075391026458897625\n",
      "train loss:0.0008684202517716128\n",
      "train loss:0.1483429086055392\n",
      "train loss:0.0013464756925955928\n",
      "train loss:0.008947017239481256\n",
      "train loss:0.02213375930065065\n",
      "train loss:0.008347473282754054\n",
      "train loss:0.007121900207736627\n",
      "train loss:0.004150085277884355\n",
      "train loss:0.01422310329088931\n",
      "train loss:0.0073131373457217715\n",
      "train loss:0.02083995290019896\n",
      "train loss:0.01473807853127221\n",
      "train loss:0.012767969574994533\n",
      "train loss:0.11816652047848734\n",
      "train loss:0.03896452731106482\n",
      "train loss:0.014134544976014947\n",
      "train loss:0.022377901308537323\n",
      "train loss:0.010020481490427417\n",
      "train loss:0.026258135298105695\n",
      "train loss:0.012833335345871902\n",
      "train loss:0.00923092509211076\n",
      "train loss:0.014680839490029424\n",
      "train loss:0.028389226459969167\n",
      "train loss:0.014823987244802477\n",
      "train loss:0.005276720984225591\n",
      "train loss:0.02974841912950935\n",
      "train loss:0.01725797485545276\n",
      "train loss:0.008160967657660253\n",
      "train loss:0.07370387747336948\n",
      "train loss:0.003987194958984055\n",
      "train loss:0.003090774227525743\n",
      "train loss:0.01194016249867794\n",
      "train loss:0.02013305254717368\n",
      "train loss:0.014176105703522308\n",
      "train loss:0.011973366265128592\n",
      "train loss:0.006377525034882165\n",
      "train loss:0.029449121358782974\n",
      "train loss:0.008676058546655098\n",
      "train loss:0.011863402716516853\n",
      "train loss:0.016226846777008662\n",
      "train loss:0.012661978876954806\n",
      "train loss:0.007113392799468122\n",
      "train loss:0.007526530798976308\n",
      "train loss:0.012443402814593572\n",
      "train loss:0.017139977216784473\n",
      "train loss:0.0032455656657574255\n",
      "train loss:0.008342259867167034\n",
      "train loss:0.025860210698744113\n",
      "train loss:0.01147116339748671\n",
      "train loss:0.031341394427562966\n",
      "=== epoch:6, train acc:0.99, test acc:0.983 ===\n",
      "train loss:0.007008371517598508\n",
      "train loss:0.01342404680624002\n",
      "train loss:0.023674144483582578\n",
      "train loss:0.009344729068478904\n",
      "train loss:0.01072622547324446\n",
      "train loss:0.021518428528500933\n",
      "train loss:0.0020046220575384473\n",
      "train loss:0.005250858053063231\n",
      "train loss:0.0027441134976489874\n",
      "train loss:0.015604904515237016\n",
      "train loss:0.0052495643531164414\n",
      "train loss:0.014818399252251717\n",
      "train loss:0.03497550397278737\n",
      "train loss:0.019549293418098725\n",
      "train loss:0.015012450053938973\n",
      "train loss:0.01878809030271238\n",
      "train loss:0.011893283798013974\n",
      "train loss:0.026305925342206195\n",
      "train loss:0.012955429074781399\n",
      "train loss:0.03147742122121255\n",
      "train loss:0.04791680437018246\n",
      "train loss:0.01626074131392882\n",
      "train loss:0.018245503864359386\n",
      "train loss:0.011761231556159104\n",
      "train loss:0.025465507734846078\n",
      "train loss:0.016024529151934565\n",
      "train loss:0.08364179234841763\n",
      "train loss:0.015746732725705637\n",
      "train loss:0.011781509419473282\n",
      "train loss:0.032775333028432024\n",
      "train loss:0.04011001828398877\n",
      "train loss:0.005646731786386921\n",
      "train loss:0.033810248240301516\n",
      "train loss:0.023318381537538634\n",
      "train loss:0.023715494960804877\n",
      "train loss:0.01997772084396348\n",
      "train loss:0.08039573202274228\n",
      "train loss:0.025703486837839212\n",
      "train loss:0.009613709988485902\n",
      "train loss:0.006944223685143513\n",
      "train loss:0.015271999074108986\n",
      "train loss:0.00693720013598152\n",
      "train loss:0.012055878682982395\n",
      "train loss:0.08495840924181486\n",
      "train loss:0.008925043608010514\n",
      "train loss:0.019437557028053838\n",
      "train loss:0.00570923043520569\n",
      "train loss:0.01150082564000938\n",
      "train loss:0.011611092776603904\n",
      "train loss:0.007815299866404692\n",
      "train loss:0.008245200039714306\n",
      "train loss:0.015241175200483957\n",
      "train loss:0.006791661059627988\n",
      "train loss:0.06715566162588578\n",
      "train loss:0.029841452397623223\n",
      "train loss:0.013171357575510816\n",
      "train loss:0.006803888742459676\n",
      "train loss:0.010367025827680409\n",
      "train loss:0.07566847677455994\n",
      "train loss:0.01846825796386536\n",
      "train loss:0.005757051889825544\n",
      "train loss:0.012402158425093205\n",
      "train loss:0.03039643948531171\n",
      "train loss:0.016115039371572368\n",
      "train loss:0.02010198967167255\n",
      "train loss:0.011181092053622886\n",
      "train loss:0.004729511566933669\n",
      "train loss:0.018304210024393544\n",
      "train loss:0.0048023438366495905\n",
      "train loss:0.01845023632217753\n",
      "train loss:0.0045427691715663335\n",
      "train loss:0.00521524619912985\n",
      "train loss:0.022862181613994243\n",
      "train loss:0.005215609247418439\n",
      "train loss:0.006678850613012556\n",
      "train loss:0.0063504086292642615\n",
      "train loss:0.02695047228529065\n",
      "train loss:0.021983409235725847\n",
      "train loss:0.017310080516162292\n",
      "train loss:0.0056327405304322144\n",
      "train loss:0.006084814246557747\n",
      "train loss:0.014644909725628779\n",
      "train loss:0.04274325652023747\n",
      "train loss:0.020040465448926757\n",
      "train loss:0.037377280888145334\n",
      "train loss:0.005322728744205971\n",
      "train loss:0.022032392131506602\n",
      "train loss:0.00302150279568099\n",
      "train loss:0.007628150273663839\n",
      "train loss:0.025021073345289135\n",
      "train loss:0.015440977353839955\n",
      "train loss:0.022569448281638992\n",
      "train loss:0.0205438937285584\n",
      "train loss:0.026331595880684625\n",
      "train loss:0.023423599784002058\n",
      "train loss:0.018003208677214513\n",
      "train loss:0.07007787989417574\n",
      "train loss:0.02944188182622937\n",
      "train loss:0.03508812105166302\n",
      "train loss:0.026430908205273843\n",
      "train loss:0.02994625992996054\n",
      "train loss:0.0059946374323076\n",
      "train loss:0.020750402707848833\n",
      "train loss:0.004711050261634934\n",
      "train loss:0.024412926056452476\n",
      "train loss:0.001818110490292673\n",
      "train loss:0.014403480297868426\n",
      "train loss:0.03407668870017402\n",
      "train loss:0.05242409410312849\n",
      "train loss:0.00888924053917562\n",
      "train loss:0.01186384361903683\n",
      "train loss:0.04540306830985871\n",
      "train loss:0.0063299213892100996\n",
      "train loss:0.002832573473008616\n",
      "train loss:0.022611917659283897\n",
      "train loss:0.010557830083888302\n",
      "train loss:0.006916278820134632\n",
      "train loss:0.013677331635109051\n",
      "train loss:0.08265239265543702\n",
      "train loss:0.05179467041661475\n",
      "train loss:0.016744416728439605\n",
      "train loss:0.01118683848209303\n",
      "train loss:0.048601031778794684\n",
      "train loss:0.023959206141496162\n",
      "train loss:0.028115480166349304\n",
      "train loss:0.019670802252203384\n",
      "train loss:0.005731202190592842\n",
      "train loss:0.02161151561623105\n",
      "train loss:0.032446872666018756\n",
      "train loss:0.02740158936545595\n",
      "train loss:0.01850605719897615\n",
      "train loss:0.013067089530012859\n",
      "train loss:0.03561668326756742\n",
      "train loss:0.013826020481335933\n",
      "train loss:0.009974660515791467\n",
      "train loss:0.004942824054223027\n",
      "train loss:0.009617813344358243\n",
      "train loss:0.006656717580318296\n",
      "train loss:0.06233293934736855\n",
      "train loss:0.003538703312942214\n",
      "train loss:0.01699064245713004\n",
      "train loss:0.01547432664801266\n",
      "train loss:0.004199979596021558\n",
      "train loss:0.005412260503708017\n",
      "train loss:0.005549369714963285\n",
      "train loss:0.006173640963614747\n",
      "train loss:0.04474424405125773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00447760689904772\n",
      "train loss:0.01536540079727158\n",
      "train loss:0.022721614127185166\n",
      "train loss:0.01548361113182716\n",
      "train loss:0.008805529322376245\n",
      "train loss:0.011058199159421822\n",
      "train loss:0.00942628318197754\n",
      "train loss:0.01589349494197642\n",
      "train loss:0.023333405506672063\n",
      "train loss:0.007444335832008664\n",
      "train loss:0.013609225824215594\n",
      "train loss:0.013236634856470853\n",
      "train loss:0.03738847528484127\n",
      "train loss:0.0034354604963974748\n",
      "train loss:0.012598604072010966\n",
      "train loss:0.01586084415736284\n",
      "train loss:0.010422168167731092\n",
      "train loss:0.0345526575429307\n",
      "train loss:0.006766410404314459\n",
      "train loss:0.016978898811756956\n",
      "train loss:0.017742453871371022\n",
      "train loss:0.007520644297280855\n",
      "train loss:0.007535622720660685\n",
      "train loss:0.023528527868462698\n",
      "train loss:0.005808806121694776\n",
      "train loss:0.03350981472285594\n",
      "train loss:0.009100966098887945\n",
      "train loss:0.028163016784165974\n",
      "train loss:0.01368533731860793\n",
      "train loss:0.016699128120554595\n",
      "train loss:0.00844031919843803\n",
      "train loss:0.0306947739704907\n",
      "train loss:0.006433081088600112\n",
      "train loss:0.021677574896704507\n",
      "train loss:0.028657891658561332\n",
      "train loss:0.029530037520263352\n",
      "train loss:0.00900904365051214\n",
      "train loss:0.007743220128052575\n",
      "train loss:0.017547040152987338\n",
      "train loss:0.01915637783238477\n",
      "train loss:0.006646897602169173\n",
      "train loss:0.0083284271095873\n",
      "train loss:0.013408633153937002\n",
      "train loss:0.012609053546897375\n",
      "train loss:0.002458781035955458\n",
      "train loss:0.02423696010634744\n",
      "train loss:0.005979001240929458\n",
      "train loss:0.0043399443127532964\n",
      "train loss:0.005309581392727096\n",
      "train loss:0.030807754571226753\n",
      "train loss:0.012639264727903117\n",
      "train loss:0.009438453088208237\n",
      "train loss:0.021935975773384544\n",
      "train loss:0.003266080081412977\n",
      "train loss:0.011957714829102815\n",
      "train loss:0.02379715153370338\n",
      "train loss:0.007322140901815882\n",
      "train loss:0.02662878112318896\n",
      "train loss:0.0021059794959221007\n",
      "train loss:0.04780577094966542\n",
      "train loss:0.02418043134225746\n",
      "train loss:0.00790187122739886\n",
      "train loss:0.008991129171483097\n",
      "train loss:0.014851425861393559\n",
      "train loss:0.006655388400666057\n",
      "train loss:0.007115029358437054\n",
      "train loss:0.0030095672715433446\n",
      "train loss:0.13632289156830646\n",
      "train loss:0.042236937371426\n",
      "train loss:0.012343137730375238\n",
      "train loss:0.007003155277812831\n",
      "train loss:0.0374437339144671\n",
      "train loss:0.01181261490684064\n",
      "train loss:0.016655338105853967\n",
      "train loss:0.001348113249911307\n",
      "train loss:0.11462907235427103\n",
      "train loss:0.017087021489565687\n",
      "train loss:0.0059835778121714155\n",
      "train loss:0.013195787942331555\n",
      "train loss:0.0120844265094073\n",
      "train loss:0.0041670722991874855\n",
      "train loss:0.0019235228084230277\n",
      "train loss:0.008668591952694003\n",
      "train loss:0.00470298386941252\n",
      "train loss:0.009205374168837693\n",
      "train loss:0.003482732291352222\n",
      "train loss:0.029935778889294728\n",
      "train loss:0.022098348705552294\n",
      "train loss:0.021558946740136472\n",
      "train loss:0.006153467051204557\n",
      "train loss:0.01566704166053098\n",
      "train loss:0.0074179887674556575\n",
      "train loss:0.019567146058666676\n",
      "train loss:0.00935896470683551\n",
      "train loss:0.00989805124362308\n",
      "train loss:0.016542037738094074\n",
      "train loss:0.014167589145929782\n",
      "train loss:0.011105593565755073\n",
      "train loss:0.0202296779909479\n",
      "train loss:0.012911446686254421\n",
      "train loss:0.0016361745123307943\n",
      "train loss:0.013485863421584721\n",
      "train loss:0.007472413173058871\n",
      "train loss:0.045610957715618676\n",
      "train loss:0.03036373486032126\n",
      "train loss:0.0010807361262301675\n",
      "train loss:0.011637843011422247\n",
      "train loss:0.0007424072555808528\n",
      "train loss:0.012217828567040685\n",
      "train loss:0.03207859575368256\n",
      "train loss:0.021658241050770764\n",
      "train loss:0.05495415053454847\n",
      "train loss:0.03266758563570228\n",
      "train loss:0.005469657510527241\n",
      "train loss:0.011829535637797692\n",
      "train loss:0.008325897490583501\n",
      "train loss:0.005212584286385582\n",
      "train loss:0.031269337048735184\n",
      "train loss:0.057993318752930255\n",
      "train loss:0.012587156809111901\n",
      "train loss:0.01158278347749475\n",
      "train loss:0.001674040574436979\n",
      "train loss:0.006419622486587328\n",
      "train loss:0.028377194382413425\n",
      "train loss:0.006180176651463678\n",
      "train loss:0.011016985655649202\n",
      "train loss:0.021567871284905508\n",
      "train loss:0.003287314044818069\n",
      "train loss:0.04706672855161166\n",
      "train loss:0.019428209436271122\n",
      "train loss:0.009549937909261733\n",
      "train loss:0.007406348968452023\n",
      "train loss:0.014517387552635564\n",
      "train loss:0.004507411367761635\n",
      "train loss:0.005383879240215577\n",
      "train loss:0.09490340120059897\n",
      "train loss:0.03951749072519571\n",
      "train loss:0.006987183962685434\n",
      "train loss:0.0028958139809946654\n",
      "train loss:0.01619085037596873\n",
      "train loss:0.002402057915913031\n",
      "train loss:0.007480458644013674\n",
      "train loss:0.006259911080354686\n",
      "train loss:0.008621758565753222\n",
      "train loss:0.0037604217320101906\n",
      "train loss:0.015080031002738706\n",
      "train loss:0.05434038481611119\n",
      "train loss:0.006100467971907424\n",
      "train loss:0.007554974671719342\n",
      "train loss:0.014486119237736506\n",
      "train loss:0.006356656163016796\n",
      "train loss:0.0012682862610350187\n",
      "train loss:0.013415345332459687\n",
      "train loss:0.01803002393627183\n",
      "train loss:0.020217752580716886\n",
      "train loss:0.02863251902825061\n",
      "train loss:0.012310289740011122\n",
      "train loss:0.005696843350166978\n",
      "train loss:0.020117377164518578\n",
      "train loss:0.010141473852420804\n",
      "train loss:0.032208249467533694\n",
      "train loss:0.0031720432043779462\n",
      "train loss:0.008943162328076716\n",
      "train loss:0.0154658976319323\n",
      "train loss:0.006134597854510653\n",
      "train loss:0.0040700992243563215\n",
      "train loss:0.014677893807207052\n",
      "train loss:0.09201574063564603\n",
      "train loss:0.013059168576002797\n",
      "train loss:0.009945261693416333\n",
      "train loss:0.004387619494333266\n",
      "train loss:0.015622700304549646\n",
      "train loss:0.03674744810167004\n",
      "train loss:0.002003876232433092\n",
      "train loss:0.01736098068321204\n",
      "train loss:0.004399814293460774\n",
      "train loss:0.01920749572245412\n",
      "train loss:0.013616986184522728\n",
      "train loss:0.04227519994384281\n",
      "train loss:0.043967537770796324\n",
      "train loss:0.06865777800075729\n",
      "train loss:0.008025648523201\n",
      "train loss:0.006636106622404698\n",
      "train loss:0.0039603962622513774\n",
      "train loss:0.059006371796671335\n",
      "train loss:0.03236456046945088\n",
      "train loss:0.0019934344905227206\n",
      "train loss:0.0506162094704157\n",
      "train loss:0.07746769792803594\n",
      "train loss:0.006993812367236686\n",
      "train loss:0.018666129187551794\n",
      "train loss:0.01580415057488577\n",
      "train loss:0.00926572756866014\n",
      "train loss:0.014946846451845195\n",
      "train loss:0.004080701855349166\n",
      "train loss:0.010583726135643264\n",
      "train loss:0.007671245077127104\n",
      "train loss:0.007244301683973282\n",
      "train loss:0.010792098289446432\n",
      "train loss:0.034879189245824685\n",
      "train loss:0.02168920106901513\n",
      "train loss:0.006093826023905447\n",
      "train loss:0.014540451417833016\n",
      "train loss:0.0037056791495902004\n",
      "train loss:0.004543929081844863\n",
      "train loss:0.015841220899330797\n",
      "train loss:0.021682940212706843\n",
      "train loss:0.010489098792547679\n",
      "train loss:0.006710539027050656\n",
      "train loss:0.05419801348029993\n",
      "train loss:0.003100718252252222\n",
      "train loss:0.006582538966853723\n",
      "train loss:0.018740998907138203\n",
      "train loss:0.020177965065890507\n",
      "train loss:0.04838531871309334\n",
      "train loss:0.06587706577256953\n",
      "train loss:0.02413915060318523\n",
      "train loss:0.004841449915772738\n",
      "train loss:0.017320350437533175\n",
      "train loss:0.005078421112614987\n",
      "train loss:0.04989183467489437\n",
      "train loss:0.018344198545552783\n",
      "train loss:0.025879222777360763\n",
      "train loss:0.024368092607838246\n",
      "train loss:0.01791519633642382\n",
      "train loss:0.012264942958184297\n",
      "train loss:0.007765334616529189\n",
      "train loss:0.10453966389055493\n",
      "train loss:0.00828933709143472\n",
      "train loss:0.0076873441477594605\n",
      "train loss:0.014656890662634571\n",
      "train loss:0.00477091093568455\n",
      "train loss:0.0063878983708074676\n",
      "train loss:0.016484076770363253\n",
      "train loss:0.00690881418271818\n",
      "train loss:0.004821893347880608\n",
      "train loss:0.013154105128638384\n",
      "train loss:0.015341568308775849\n",
      "train loss:0.008756629671198318\n",
      "train loss:0.009492347185728233\n",
      "train loss:0.011407891450391547\n",
      "train loss:0.00888619151115817\n",
      "train loss:0.012606732319207965\n",
      "train loss:0.004672494899555558\n",
      "train loss:0.0036889443860483595\n",
      "train loss:0.01035934051935772\n",
      "train loss:0.012203197131862652\n",
      "train loss:0.024416206312367184\n",
      "train loss:0.08192425889271346\n",
      "train loss:0.0557930897347684\n",
      "train loss:0.007470941344337646\n",
      "train loss:0.0024371978747828203\n",
      "train loss:0.014619720044052422\n",
      "train loss:0.011339233385393903\n",
      "train loss:0.012533023970023614\n",
      "train loss:0.00975058383942303\n",
      "train loss:0.009313286968947924\n",
      "train loss:0.011003977811007362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.008140546227591498\n",
      "train loss:0.003247739287642786\n",
      "train loss:0.011492300375375228\n",
      "train loss:0.01581344035249521\n",
      "train loss:0.02527432090504934\n",
      "train loss:0.01716968968782561\n",
      "train loss:0.008951650369297393\n",
      "train loss:0.002730972134967765\n",
      "train loss:0.16915083254845456\n",
      "train loss:0.010553459646063395\n",
      "train loss:0.012317528213506623\n",
      "train loss:0.006192877893317322\n",
      "train loss:0.0053951702231384655\n",
      "train loss:0.02274530074369566\n",
      "train loss:0.030365104477118425\n",
      "train loss:0.04424123636082034\n",
      "train loss:0.01042356659819645\n",
      "train loss:0.012787671355388355\n",
      "train loss:0.02373543200342164\n",
      "train loss:0.02078312328026143\n",
      "train loss:0.003204327802114274\n",
      "train loss:0.016008683737043113\n",
      "train loss:0.0018812637965842536\n",
      "train loss:0.016415781762466334\n",
      "train loss:0.01165857569728744\n",
      "train loss:0.021371044353764638\n",
      "train loss:0.01793926293496174\n",
      "train loss:0.004605327686424518\n",
      "train loss:0.018549571657121355\n",
      "train loss:0.012240775623220299\n",
      "train loss:0.06255527610604589\n",
      "train loss:0.03166295446744955\n",
      "train loss:0.0059195213411066296\n",
      "train loss:0.0578742568309658\n",
      "train loss:0.023072764066338524\n",
      "train loss:0.05343878754137988\n",
      "train loss:0.013117124017979199\n",
      "train loss:0.021226461177131565\n",
      "train loss:0.014187818832706051\n",
      "train loss:0.00992130644411425\n",
      "train loss:0.008210766746858998\n",
      "train loss:0.01681108708121606\n",
      "train loss:0.006406833961229261\n",
      "train loss:0.003816295877559068\n",
      "train loss:0.03753749910460322\n",
      "train loss:0.03588049475979818\n",
      "train loss:0.011919199233573683\n",
      "train loss:0.009993870074716927\n",
      "train loss:0.003650300860835476\n",
      "train loss:0.010323698762258953\n",
      "train loss:0.014076200362388318\n",
      "train loss:0.0658659901095786\n",
      "train loss:0.009383826204735485\n",
      "train loss:0.05327196436910389\n",
      "train loss:0.005715264389769905\n",
      "train loss:0.04925431550705268\n",
      "train loss:0.016646831307141487\n",
      "train loss:0.018258700619880257\n",
      "train loss:0.02080322147762327\n",
      "train loss:0.005699741053950885\n",
      "train loss:0.006440762198128624\n",
      "train loss:0.003420801699100423\n",
      "train loss:0.012462306233487921\n",
      "train loss:0.005627138750656874\n",
      "train loss:0.04018834332603584\n",
      "train loss:0.00652295519945021\n",
      "train loss:0.008421844978082894\n",
      "train loss:0.006894800397659984\n",
      "train loss:0.015949608126353668\n",
      "train loss:0.028369643917201995\n",
      "train loss:0.07032537439754936\n",
      "train loss:0.0926197299809572\n",
      "train loss:0.0026053773292184705\n",
      "train loss:0.006052478179663475\n",
      "train loss:0.032449891209059105\n",
      "train loss:0.009754707799237278\n",
      "train loss:0.0020252320271574404\n",
      "train loss:0.0326593029143123\n",
      "train loss:0.021753559104420228\n",
      "train loss:0.013970267399485682\n",
      "train loss:0.0023503208777790278\n",
      "train loss:0.03497799963720069\n",
      "train loss:0.07155212516783814\n",
      "train loss:0.02266891425800502\n",
      "train loss:0.011185984711310468\n",
      "train loss:0.007366006624072372\n",
      "train loss:0.009732429904302124\n",
      "train loss:0.012194919090110706\n",
      "train loss:0.011235465386136855\n",
      "train loss:0.03490113136285625\n",
      "train loss:0.018007544083705116\n",
      "train loss:0.022647491962698697\n",
      "train loss:0.025579455431607213\n",
      "train loss:0.05089001308188746\n",
      "train loss:0.022706853078089406\n",
      "train loss:0.006067157515827017\n",
      "train loss:0.01333944386835411\n",
      "train loss:0.02129356629553985\n",
      "train loss:0.01233862004257193\n",
      "train loss:0.006565911262519925\n",
      "train loss:0.003911485319227324\n",
      "train loss:0.012416960143830272\n",
      "train loss:0.009057148048483883\n",
      "train loss:0.02179645830629546\n",
      "train loss:0.018622276837638632\n",
      "train loss:0.03269716118427568\n",
      "train loss:0.00605288005667442\n",
      "train loss:0.008519111770192999\n",
      "train loss:0.007004283572805747\n",
      "train loss:0.06932490736031853\n",
      "train loss:0.005097160004934681\n",
      "train loss:0.008747329727650464\n",
      "train loss:0.006363145203319831\n",
      "train loss:0.0065104379567790215\n",
      "train loss:0.004147819690543193\n",
      "train loss:0.01679767422239503\n",
      "train loss:0.016610326296553082\n",
      "train loss:0.009068848630906904\n",
      "train loss:0.005734758384853838\n",
      "train loss:0.003142651503619135\n",
      "train loss:0.00597830926230074\n",
      "train loss:0.015603718659649008\n",
      "train loss:0.011043753204688913\n",
      "train loss:0.01320846149900527\n",
      "train loss:0.002633100459087318\n",
      "train loss:0.03787303579160446\n",
      "train loss:0.04956943341410565\n",
      "train loss:0.0083468573470435\n",
      "train loss:0.010500908677960235\n",
      "train loss:0.0027085447806523906\n",
      "train loss:0.0046251727967099995\n",
      "train loss:0.014396208884934692\n",
      "train loss:0.010263158748218973\n",
      "train loss:0.010990418465213028\n",
      "train loss:0.015769762782623844\n",
      "train loss:0.00547980228454401\n",
      "train loss:0.008287237430350328\n",
      "train loss:0.005760460622655281\n",
      "train loss:0.02303106722275695\n",
      "train loss:0.05009799484666314\n",
      "train loss:0.002641401017229798\n",
      "train loss:0.009452093289949764\n",
      "train loss:0.0782960288814862\n",
      "train loss:0.005807591021669777\n",
      "train loss:0.004695358883769241\n",
      "train loss:0.007795907667727524\n",
      "train loss:0.0029128540281885777\n",
      "train loss:0.005074605661556072\n",
      "train loss:0.0028217838136587415\n",
      "train loss:0.01698158228353739\n",
      "train loss:0.010638413935628215\n",
      "train loss:0.015161780550973619\n",
      "train loss:0.00142201441491427\n",
      "train loss:0.005040842766229196\n",
      "train loss:0.017780197806895902\n",
      "train loss:0.007961828649689978\n",
      "train loss:0.00953393279297216\n",
      "train loss:0.021067070554585014\n",
      "train loss:0.0868909125741557\n",
      "train loss:0.07509353316663839\n",
      "train loss:0.005581077754334235\n",
      "train loss:0.0009445636355384719\n",
      "train loss:0.060548753411891566\n",
      "train loss:0.012422186887890999\n",
      "train loss:0.010168311604805016\n",
      "train loss:0.03133767802543025\n",
      "train loss:0.03528585289778997\n",
      "train loss:0.008319183757236314\n",
      "train loss:0.011549944026557752\n",
      "train loss:0.016017928538812575\n",
      "train loss:0.013111736413129411\n",
      "train loss:0.014661307799899794\n",
      "train loss:0.0028488334594895036\n",
      "train loss:0.007836843890798221\n",
      "train loss:0.008142970884277727\n",
      "train loss:0.00484000617644898\n",
      "train loss:0.012127461104963646\n",
      "train loss:0.002097033713112403\n",
      "train loss:0.010458310815016915\n",
      "train loss:0.0044206945634694475\n",
      "train loss:0.009816231904475427\n",
      "train loss:0.003727099938523054\n",
      "train loss:0.011675770541591152\n",
      "train loss:0.007232475093621857\n",
      "train loss:0.0034179311727604127\n",
      "train loss:0.005774808122118838\n",
      "train loss:0.011373414670774322\n",
      "train loss:0.008526142486711876\n",
      "train loss:0.016453036831155572\n",
      "train loss:0.02417651786384431\n",
      "train loss:0.005172990143637716\n",
      "train loss:0.03575634876563245\n",
      "train loss:0.015900607467773647\n",
      "train loss:0.005684173024960199\n",
      "train loss:0.011821294100058267\n",
      "=== epoch:7, train acc:0.991, test acc:0.986 ===\n",
      "train loss:0.0063347269511077635\n",
      "train loss:0.005075457814944927\n",
      "train loss:0.008142852986901455\n",
      "train loss:0.009044642464886144\n",
      "train loss:0.02945878948755022\n",
      "train loss:0.00048237480592726084\n",
      "train loss:0.04075814911440181\n",
      "train loss:0.02621213167677675\n",
      "train loss:0.003200651796472799\n",
      "train loss:0.006090616513613146\n",
      "train loss:0.025149742040097598\n",
      "train loss:0.018464473414338357\n",
      "train loss:0.010788866124950294\n",
      "train loss:0.01263687423107115\n",
      "train loss:0.006039902865813051\n",
      "train loss:0.010523422229208663\n",
      "train loss:0.020553482203795607\n",
      "train loss:0.0022426852885791292\n",
      "train loss:0.0890286756582921\n",
      "train loss:0.004151088970545755\n",
      "train loss:0.010146826652191372\n",
      "train loss:0.0027823466042246944\n",
      "train loss:0.03274141109969187\n",
      "train loss:0.033309472639007166\n",
      "train loss:0.024084052041747187\n",
      "train loss:0.033583324205510426\n",
      "train loss:0.02917697049853532\n",
      "train loss:0.00596798932036159\n",
      "train loss:0.01736445110797017\n",
      "train loss:0.010393696495966045\n",
      "train loss:0.02267516061624518\n",
      "train loss:0.09987999987086102\n",
      "train loss:0.0032627185158946694\n",
      "train loss:0.0170698387847225\n",
      "train loss:0.008252007758968675\n",
      "train loss:0.01598621062244514\n",
      "train loss:0.009874578932981094\n",
      "train loss:0.02496896678734703\n",
      "train loss:0.01777376856251806\n",
      "train loss:0.009879205221773034\n",
      "train loss:0.01835841617145251\n",
      "train loss:0.013809498233633947\n",
      "train loss:0.126108046433402\n",
      "train loss:0.006425127071748751\n",
      "train loss:0.048842136798938\n",
      "train loss:0.013805718442388284\n",
      "train loss:0.007753146248762381\n",
      "train loss:0.009203477048972866\n",
      "train loss:0.008806403910181034\n",
      "train loss:0.0026564775762442537\n",
      "train loss:0.007542154420089705\n",
      "train loss:0.028349493825914004\n",
      "train loss:0.009258538326438366\n",
      "train loss:0.004618666927548188\n",
      "train loss:0.01236231802792872\n",
      "train loss:0.009110043261681798\n",
      "train loss:0.001587368535473945\n",
      "train loss:0.013617785691320404\n",
      "train loss:0.0359717520462356\n",
      "train loss:0.012080728431963759\n",
      "train loss:0.021980237039035014\n",
      "train loss:0.0074642244822718225\n",
      "train loss:0.02237370003797854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1118585655014753\n",
      "train loss:0.007471895875868055\n",
      "train loss:0.028870598356676925\n",
      "train loss:0.02039284929364923\n",
      "train loss:0.004648941150097144\n",
      "train loss:0.014903244295961314\n",
      "train loss:0.024778307567156467\n",
      "train loss:0.014827131435234705\n",
      "train loss:0.005568386621798037\n",
      "train loss:0.028019431364198426\n",
      "train loss:0.0683348762754939\n",
      "train loss:0.008817598710263903\n",
      "train loss:0.004119549202770195\n",
      "train loss:0.021752681080718997\n",
      "train loss:0.001960557679041751\n",
      "train loss:0.036980478475906915\n",
      "train loss:0.00918503473864644\n",
      "train loss:0.009001788579743117\n",
      "train loss:0.06743632669787378\n",
      "train loss:0.11288263159031993\n",
      "train loss:0.025613577137981864\n",
      "train loss:0.07613230664319136\n",
      "train loss:0.007368257827577743\n",
      "train loss:0.015100681677469044\n",
      "train loss:0.03946952608522951\n",
      "train loss:0.02896975823625863\n",
      "train loss:0.08100608689123376\n",
      "train loss:0.0365706114346058\n",
      "train loss:0.0073560351653603724\n",
      "train loss:0.005537372853700463\n",
      "train loss:0.005044176347126145\n",
      "train loss:0.008292590514814296\n",
      "train loss:0.01510309324054005\n",
      "train loss:0.04271940738578362\n",
      "train loss:0.016753009471390738\n",
      "train loss:0.008961135183101782\n",
      "train loss:0.009590471752084676\n",
      "train loss:0.008761112550847723\n",
      "train loss:0.012718050584714086\n",
      "train loss:0.01747904022250702\n",
      "train loss:0.02069625833374578\n",
      "train loss:0.00269712876017514\n",
      "train loss:0.006505780671478859\n",
      "train loss:0.008936050924204355\n",
      "train loss:0.006539585661155962\n",
      "train loss:0.01654997650666568\n",
      "train loss:0.007488897263723719\n",
      "train loss:0.039925705089991506\n",
      "train loss:0.0028338799742560978\n",
      "train loss:0.01989565185555721\n",
      "train loss:0.011879702922212867\n",
      "train loss:0.031514793050985083\n",
      "train loss:0.07401103052911652\n",
      "train loss:0.005907593120765836\n",
      "train loss:0.009630138053087847\n",
      "train loss:0.003131058496777591\n",
      "train loss:0.01236757162022272\n",
      "train loss:0.028766116601610593\n",
      "train loss:0.03186286084151571\n",
      "train loss:0.00419388298929683\n",
      "train loss:0.00410858122213465\n",
      "train loss:0.032490148811159573\n",
      "train loss:0.0027983353449146046\n",
      "train loss:0.009468012597380832\n",
      "train loss:0.0051359037906984735\n",
      "train loss:0.016567856137160768\n",
      "train loss:0.03320889312187838\n",
      "train loss:0.002000667662632821\n",
      "train loss:0.004654016907925146\n",
      "train loss:0.012394994446481154\n",
      "train loss:0.05075462253674967\n",
      "train loss:0.01105118817513484\n",
      "train loss:0.001847000308110913\n",
      "train loss:0.008515308772864286\n",
      "train loss:0.013548206427587677\n",
      "train loss:0.004286393013012856\n",
      "train loss:0.012396481743823214\n",
      "train loss:0.00322165661534512\n",
      "train loss:0.01580768926108674\n",
      "train loss:0.005277124307823506\n",
      "train loss:0.0030794492682696827\n",
      "train loss:0.0037406817645738418\n",
      "train loss:0.009814500684548245\n",
      "train loss:0.009895403200044091\n",
      "train loss:0.008529865494746885\n",
      "train loss:0.020417696246670045\n",
      "train loss:0.004398563563794338\n",
      "train loss:0.008540782092449855\n",
      "train loss:0.03379109948188119\n",
      "train loss:0.038842588343218146\n",
      "train loss:0.021576444536960452\n",
      "train loss:0.02454028811513287\n",
      "train loss:0.015760029007430926\n",
      "train loss:0.001933624297242405\n",
      "train loss:0.015978079341016284\n",
      "train loss:0.0028532880924928726\n",
      "train loss:0.0045830516863710055\n",
      "train loss:0.02386093368027667\n",
      "train loss:0.012299789044426261\n",
      "train loss:0.004054185097932572\n",
      "train loss:0.002882942797673876\n",
      "train loss:0.008117528942255026\n",
      "train loss:0.0025019138896393584\n",
      "train loss:0.016013879423268994\n",
      "train loss:0.0103315672504466\n",
      "train loss:0.02328379739927704\n",
      "train loss:0.004281188398325799\n",
      "train loss:0.001710690010185259\n",
      "train loss:0.0020958593827554313\n",
      "train loss:0.007548970095346533\n",
      "train loss:0.06123313544478152\n",
      "train loss:0.004930947060821308\n",
      "train loss:0.008087335851784653\n",
      "train loss:0.03852761174514925\n",
      "train loss:0.005960135628168944\n",
      "train loss:0.005944184903221444\n",
      "train loss:0.027720068545093103\n",
      "train loss:0.023469528830625933\n",
      "train loss:0.006079434980550496\n",
      "train loss:0.0025688447102346556\n",
      "train loss:0.007873542119099018\n",
      "train loss:0.021341183387089954\n",
      "train loss:0.0022265268513669183\n",
      "train loss:0.004432474654938308\n",
      "train loss:0.018060379648733745\n",
      "train loss:0.026135890243303\n",
      "train loss:0.004233069316309543\n",
      "train loss:0.005074055118871412\n",
      "train loss:0.011364749815591785\n",
      "train loss:0.009425709838852003\n",
      "train loss:0.009787333679331376\n",
      "train loss:0.00463006414938699\n",
      "train loss:0.0121759363070727\n",
      "train loss:0.0025108628829700556\n",
      "train loss:0.05665494000267036\n",
      "train loss:0.01594471306380623\n",
      "train loss:0.0022253446747298707\n",
      "train loss:0.01601103891015397\n",
      "train loss:0.004320148848301343\n",
      "train loss:0.009411386640700667\n",
      "train loss:0.00995452362755367\n",
      "train loss:0.002096098031454331\n",
      "train loss:0.016806659620818856\n",
      "train loss:0.008707402064961064\n",
      "train loss:0.0012696765889684495\n",
      "train loss:0.0058528565923359355\n",
      "train loss:0.007559752608485031\n",
      "train loss:0.003549078596264806\n",
      "train loss:0.005449905542312125\n",
      "train loss:0.011095088840744395\n",
      "train loss:0.003100711879567794\n",
      "train loss:0.004509674602400435\n",
      "train loss:0.010685787390799992\n",
      "train loss:0.020779507424179458\n",
      "train loss:0.0026601695688051037\n",
      "train loss:0.026985744713169998\n",
      "train loss:0.0022165474602364784\n",
      "train loss:0.017119400595611546\n",
      "train loss:0.009039438735093844\n",
      "train loss:0.00417862116764882\n",
      "train loss:0.010394702279697252\n",
      "train loss:0.010696180246791798\n",
      "train loss:0.029948634407217973\n",
      "train loss:0.008266103389502876\n",
      "train loss:0.0017050043884543045\n",
      "train loss:0.0029284773063419263\n",
      "train loss:0.005229958521822367\n",
      "train loss:0.007341448604464812\n",
      "train loss:0.0021627332545124\n",
      "train loss:0.008500269057725038\n",
      "train loss:0.05618874750313208\n",
      "train loss:0.026022674383328247\n",
      "train loss:0.02289004826668116\n",
      "train loss:0.0033659856025665563\n",
      "train loss:0.0020063546986462183\n",
      "train loss:0.0022730086143587748\n",
      "train loss:0.007397600541976685\n",
      "train loss:0.01051147808106276\n",
      "train loss:0.011739072360904388\n",
      "train loss:0.007579065981457202\n",
      "train loss:0.0091752677829966\n",
      "train loss:0.022034594332945964\n",
      "train loss:0.023828105413642532\n",
      "train loss:0.005908542312153955\n",
      "train loss:0.01122692718926608\n",
      "train loss:0.004287683965067767\n",
      "train loss:0.009764579269721917\n",
      "train loss:0.028106373283868686\n",
      "train loss:0.04076460258573702\n",
      "train loss:0.005234302070860283\n",
      "train loss:0.015978291866521357\n",
      "train loss:0.013234227531702366\n",
      "train loss:0.0075663924900089465\n",
      "train loss:0.027891420750388102\n",
      "train loss:0.0011154900132391752\n",
      "train loss:0.008279874658056964\n",
      "train loss:0.005935079367670154\n",
      "train loss:0.03179410353621498\n",
      "train loss:0.01195497384705741\n",
      "train loss:0.002472138435145785\n",
      "train loss:0.0013367029978047648\n",
      "train loss:0.07290979633829692\n",
      "train loss:0.007724109934594469\n",
      "train loss:0.007755867347503162\n",
      "train loss:0.04238928510134577\n",
      "train loss:0.007657968487652617\n",
      "train loss:0.005277240695495238\n",
      "train loss:0.0452209994719944\n",
      "train loss:0.007781912917682592\n",
      "train loss:0.0023570012622249562\n",
      "train loss:0.03186913417757996\n",
      "train loss:0.022816062308863697\n",
      "train loss:0.0044943463332621\n",
      "train loss:0.03515123493138627\n",
      "train loss:0.03794039973897797\n",
      "train loss:0.006628538582395039\n",
      "train loss:0.003344614557340602\n",
      "train loss:0.006120478299450765\n",
      "train loss:0.008371903963511012\n",
      "train loss:0.03086302766761914\n",
      "train loss:0.021027412166517795\n",
      "train loss:0.013416754383715679\n",
      "train loss:0.017213894657312708\n",
      "train loss:0.00843872877972612\n",
      "train loss:0.01348124767942795\n",
      "train loss:0.007280142728385088\n",
      "train loss:0.03306672940661977\n",
      "train loss:0.07710778281760133\n",
      "train loss:0.009633223521773813\n",
      "train loss:0.0009940513848331898\n",
      "train loss:0.007429050350371178\n",
      "train loss:0.003269190440634054\n",
      "train loss:0.0028256167341696916\n",
      "train loss:0.0013804298213847383\n",
      "train loss:0.0017638230850893172\n",
      "train loss:0.006539289362186692\n",
      "train loss:0.0038895709987652877\n",
      "train loss:0.022758182285966252\n",
      "train loss:0.022614602403610604\n",
      "train loss:0.010053363558756074\n",
      "train loss:0.005316574687370171\n",
      "train loss:0.05090449298431767\n",
      "train loss:0.004267320965206175\n",
      "train loss:0.0399113043896788\n",
      "train loss:0.01216893248724637\n",
      "train loss:0.011193238605962877\n",
      "train loss:0.03063906647723141\n",
      "train loss:0.0034675397663966813\n",
      "train loss:0.006258078328754832\n",
      "train loss:0.0024020183865100177\n",
      "train loss:0.006765506662633196\n",
      "train loss:0.010609636085490528\n",
      "train loss:0.004071159857107225\n",
      "train loss:0.0163800809054966\n",
      "train loss:0.008059275186806485\n",
      "train loss:0.027885690545576283\n",
      "train loss:0.07338534309744954\n",
      "train loss:0.007258218827230203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015683391304601325\n",
      "train loss:0.004219118843186862\n",
      "train loss:0.024234325601452684\n",
      "train loss:0.04899046352219918\n",
      "train loss:0.006360115309668543\n",
      "train loss:0.040687912245359045\n",
      "train loss:0.0069072842919974805\n",
      "train loss:0.005150533231249485\n",
      "train loss:0.0011508131706483458\n",
      "train loss:0.022621917958586812\n",
      "train loss:0.004478069594810752\n",
      "train loss:0.015331620504092229\n",
      "train loss:0.019662005748361435\n",
      "train loss:0.010467433013509064\n",
      "train loss:0.01318781037434509\n",
      "train loss:0.003662016937654534\n",
      "train loss:0.009345586581676859\n",
      "train loss:0.010413583233048211\n",
      "train loss:0.008780694646846438\n",
      "train loss:0.013712759402879466\n",
      "train loss:0.01689175424824753\n",
      "train loss:0.012033101639250391\n",
      "train loss:0.008562970179088783\n",
      "train loss:0.009971700558774084\n",
      "train loss:0.008761529508478028\n",
      "train loss:0.013472844836436617\n",
      "train loss:0.012422481414400135\n",
      "train loss:0.018068256272144728\n",
      "train loss:0.005297835708504778\n",
      "train loss:0.00893223214424161\n",
      "train loss:0.005081750739437655\n",
      "train loss:0.06737745595321387\n",
      "train loss:0.0035083408064781846\n",
      "train loss:0.01960039766216641\n",
      "train loss:0.009450763648734394\n",
      "train loss:0.009594769086011212\n",
      "train loss:0.01544536539857786\n",
      "train loss:0.025177672995404524\n",
      "train loss:0.0060148607352252\n",
      "train loss:0.005258121935220347\n",
      "train loss:0.004877360822526377\n",
      "train loss:0.0038900632267262645\n",
      "train loss:0.014052025645425802\n",
      "train loss:0.05349848217484074\n",
      "train loss:0.020842612148653\n",
      "train loss:0.0038562749492186054\n",
      "train loss:0.0029196143458129764\n",
      "train loss:0.009938882332876578\n",
      "train loss:0.008849855477537126\n",
      "train loss:0.008819921121881947\n",
      "train loss:0.0067585100596078175\n",
      "train loss:0.005439315984951683\n",
      "train loss:0.011612808071390906\n",
      "train loss:0.002795221906534352\n",
      "train loss:0.0019657623079135404\n",
      "train loss:0.0034080660441045507\n",
      "train loss:0.007842243057659628\n",
      "train loss:0.0061493151867951235\n",
      "train loss:0.002705824447921339\n",
      "train loss:0.008898224934933056\n",
      "train loss:0.007916566917123523\n",
      "train loss:0.054572454512996096\n",
      "train loss:0.02525489656986955\n",
      "train loss:0.033478440013447505\n",
      "train loss:0.023553560917376582\n",
      "train loss:0.034635070903205833\n",
      "train loss:0.015192312785711305\n",
      "train loss:0.02749309541776845\n",
      "train loss:0.00802438980169229\n",
      "train loss:0.03180512346367824\n",
      "train loss:0.00771643109061815\n",
      "train loss:0.013203810160616194\n",
      "train loss:0.005293473090004734\n",
      "train loss:0.017561210600327934\n",
      "train loss:0.001299267222634375\n",
      "train loss:0.003976222307384178\n",
      "train loss:0.003900803103861001\n",
      "train loss:0.02049430690014467\n",
      "train loss:0.018250380138776265\n",
      "train loss:0.004451954742345208\n",
      "train loss:0.023594638423154398\n",
      "train loss:0.0040522862016048496\n",
      "train loss:0.056639582696776374\n",
      "train loss:0.0066709910208153835\n",
      "train loss:0.05938350283039084\n",
      "train loss:0.008125354743110172\n",
      "train loss:0.0015357314354679608\n",
      "train loss:0.006316797164478423\n",
      "train loss:0.0028563935505489736\n",
      "train loss:0.006369423213839879\n",
      "train loss:0.012544640693697824\n",
      "train loss:0.011433610710346487\n",
      "train loss:0.007651491685874854\n",
      "train loss:0.0018789066518169432\n",
      "train loss:0.006312466753207849\n",
      "train loss:0.007502158907450571\n",
      "train loss:0.0018940385445913796\n",
      "train loss:0.007076979288578359\n",
      "train loss:0.013302704886787826\n",
      "train loss:0.011601476122359098\n",
      "train loss:0.016195381729960125\n",
      "train loss:0.034389970474415346\n",
      "train loss:0.00511244361854095\n",
      "train loss:0.00896533668322874\n",
      "train loss:0.012618549404166417\n",
      "train loss:0.00754376048151638\n",
      "train loss:0.007596586761681838\n",
      "train loss:0.002287001659509563\n",
      "train loss:0.01154756242125299\n",
      "train loss:0.008912348424835926\n",
      "train loss:0.0032788490484879675\n",
      "train loss:0.016563774798825648\n",
      "train loss:0.011470041712696917\n",
      "train loss:0.003660495899263743\n",
      "train loss:0.014264391021160465\n",
      "train loss:0.01175532979395625\n",
      "train loss:0.011721945863145853\n",
      "train loss:0.04653363980736698\n",
      "train loss:0.010148459131096124\n",
      "train loss:0.005047684201352868\n",
      "train loss:0.00679175745904179\n",
      "train loss:0.014590995282959304\n",
      "train loss:0.010652005962998883\n",
      "train loss:0.03914834339296134\n",
      "train loss:0.05246409891244594\n",
      "train loss:0.0158543859545801\n",
      "train loss:0.006792828859740875\n",
      "train loss:0.020376702699675984\n",
      "train loss:0.11459308551236191\n",
      "train loss:0.029655598036333684\n",
      "train loss:0.014014786871362945\n",
      "train loss:0.004982291594980197\n",
      "train loss:0.005049417260764483\n",
      "train loss:0.007444100577703031\n",
      "train loss:0.005432349896119952\n",
      "train loss:0.009197970821909358\n",
      "train loss:0.0020599194934028285\n",
      "train loss:0.023503871078734927\n",
      "train loss:0.053901752572223564\n",
      "train loss:0.022715821614290435\n",
      "train loss:0.01825297368375822\n",
      "train loss:0.007190431380877688\n",
      "train loss:0.011308853567791863\n",
      "train loss:0.003926259644837512\n",
      "train loss:0.0274774019120886\n",
      "train loss:0.011858079914098865\n",
      "train loss:0.008090898001733952\n",
      "train loss:0.005023012145205896\n",
      "train loss:0.0028486818062963613\n",
      "train loss:0.006202013697890375\n",
      "train loss:0.0038027680196534384\n",
      "train loss:0.005965421683383408\n",
      "train loss:0.007233119984118868\n",
      "train loss:0.011668655221392371\n",
      "train loss:0.006570648939824503\n",
      "train loss:0.008880104800408156\n",
      "train loss:0.0028689429906407567\n",
      "train loss:0.00885042132763103\n",
      "train loss:0.0037132797948722434\n",
      "train loss:0.0016306598301108696\n",
      "train loss:0.001783942302390685\n",
      "train loss:0.04705629981728408\n",
      "train loss:0.004902223388085267\n",
      "train loss:0.0053254316850414\n",
      "train loss:0.013356154685816954\n",
      "train loss:0.003706068636165998\n",
      "train loss:0.004084412733207713\n",
      "train loss:0.024150273123840157\n",
      "train loss:0.01988654567628245\n",
      "train loss:0.005326925173783508\n",
      "train loss:0.01414764397895821\n",
      "train loss:0.010340760793828752\n",
      "train loss:0.014983747958851157\n",
      "train loss:0.005649250384292948\n",
      "train loss:0.02422762371077236\n",
      "train loss:0.021722262848679487\n",
      "train loss:0.004364485955686556\n",
      "train loss:0.0013014520755880296\n",
      "train loss:0.011206127994078698\n",
      "train loss:0.04210332589803758\n",
      "train loss:0.02682253074690185\n",
      "train loss:0.0031716967453513044\n",
      "train loss:0.0060631717370320075\n",
      "train loss:0.003700333714291717\n",
      "train loss:0.037378510429666306\n",
      "train loss:0.02563216455014309\n",
      "train loss:0.015121185182661968\n",
      "train loss:0.026696178262626002\n",
      "train loss:0.017511266510738702\n",
      "train loss:0.027605298764781492\n",
      "train loss:0.005310446210836174\n",
      "train loss:0.010664931228674594\n",
      "train loss:0.01018616610949656\n",
      "train loss:0.0035542054491107585\n",
      "train loss:0.022707063417412104\n",
      "train loss:0.005091158996645869\n",
      "train loss:0.002539724899096823\n",
      "train loss:0.0032444272425603054\n",
      "train loss:0.004141735389547385\n",
      "train loss:0.005866437255414853\n",
      "train loss:0.0022201069621120696\n",
      "train loss:0.00787386495857556\n",
      "train loss:0.0015857534315157635\n",
      "train loss:0.008308098165883689\n",
      "train loss:0.004882146587487266\n",
      "train loss:0.0066074788022651276\n",
      "train loss:0.0023432821165936977\n",
      "train loss:0.021703756543180523\n",
      "train loss:0.005960406830200185\n",
      "train loss:0.0064915853847669494\n",
      "train loss:0.0029769625979131765\n",
      "train loss:0.01182254437759408\n",
      "train loss:0.009630174642753614\n",
      "train loss:0.01903561891103763\n",
      "train loss:0.0017832599036110939\n",
      "train loss:0.01793830966717953\n",
      "train loss:0.022911638412389062\n",
      "train loss:0.003012003916348113\n",
      "train loss:0.029409041749523787\n",
      "train loss:0.01052629110741655\n",
      "train loss:0.005167037765358217\n",
      "train loss:0.0652740652181718\n",
      "train loss:0.024155711446797564\n",
      "train loss:0.05237068458217637\n",
      "train loss:0.0069341721433197785\n",
      "train loss:0.012773515315697464\n",
      "train loss:0.003922969837858635\n",
      "train loss:0.015476472199262776\n",
      "train loss:0.018143231978658945\n",
      "train loss:0.008018466391814227\n",
      "train loss:0.011590128419595532\n",
      "train loss:0.004765860449835028\n",
      "train loss:0.012102531128978194\n",
      "train loss:0.005980531725667787\n",
      "train loss:0.023096983181089277\n",
      "train loss:0.003401617988130851\n",
      "train loss:0.0460228665164801\n",
      "train loss:0.0011095285795230557\n",
      "train loss:0.044589027199120564\n",
      "train loss:0.005505684980510286\n",
      "train loss:0.01891079256726617\n",
      "train loss:0.009085361601178388\n",
      "train loss:0.012519957473074833\n",
      "train loss:0.004414841040226271\n",
      "train loss:0.0065034035806439275\n",
      "train loss:0.009672684452952813\n",
      "train loss:0.010543272890735651\n",
      "train loss:0.011806674276800369\n",
      "train loss:0.04857527993779939\n",
      "train loss:0.022885333348993755\n",
      "train loss:0.0026240060526183883\n",
      "train loss:0.024166178346645473\n",
      "train loss:0.008919291260470094\n",
      "train loss:0.005289407769768722\n",
      "train loss:0.010271374329415849\n",
      "train loss:0.007621094521508213\n",
      "train loss:0.0142903636114905\n",
      "train loss:0.020945560099559824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0315211219783167\n",
      "train loss:0.008591950858447637\n",
      "train loss:0.0048310771267119695\n",
      "train loss:0.004036882370393204\n",
      "train loss:0.05943479797617547\n",
      "train loss:0.04247005444051087\n",
      "train loss:0.0013310951326617612\n",
      "train loss:0.005659487098995566\n",
      "train loss:0.009571880965178258\n",
      "train loss:0.0010062303454342711\n",
      "train loss:0.012495384144284971\n",
      "train loss:0.004698237894832174\n",
      "train loss:0.018149950926649262\n",
      "train loss:0.005640492946591119\n",
      "train loss:0.006231353040902773\n",
      "train loss:0.008504175315904012\n",
      "train loss:0.004896460944936364\n",
      "train loss:0.0023668264315854\n",
      "train loss:0.0024394019277095363\n",
      "train loss:0.021051799136422505\n",
      "train loss:0.01321991352640362\n",
      "=== epoch:8, train acc:0.99, test acc:0.982 ===\n",
      "train loss:0.011248444181196153\n",
      "train loss:0.013368379877407965\n",
      "train loss:0.02717340059015545\n",
      "train loss:0.018503302332889538\n",
      "train loss:0.003118339893988972\n",
      "train loss:0.0046300476164636865\n",
      "train loss:0.013518374862574132\n",
      "train loss:0.032900081677818854\n",
      "train loss:0.0190685714435975\n",
      "train loss:0.009287898877462498\n",
      "train loss:0.04658329221658474\n",
      "train loss:0.011279404762275165\n",
      "train loss:0.003658599502075985\n",
      "train loss:0.039536046373773864\n",
      "train loss:0.005674993931603358\n",
      "train loss:0.010411655828137651\n",
      "train loss:0.017788129859326186\n",
      "train loss:0.009178654249678562\n",
      "train loss:0.008835371669206275\n",
      "train loss:0.004064669869271268\n",
      "train loss:0.0037341987505711068\n",
      "train loss:0.0013772202247556388\n",
      "train loss:0.019026102829579637\n",
      "train loss:0.013372963351660994\n",
      "train loss:0.026327563849242043\n",
      "train loss:0.0037125826707536604\n",
      "train loss:0.018474689478865266\n",
      "train loss:0.014042632954730865\n",
      "train loss:0.007216883866778588\n",
      "train loss:0.008802172926639396\n",
      "train loss:0.007971239855310673\n",
      "train loss:0.016162872377816998\n",
      "train loss:0.007134361519353558\n",
      "train loss:0.004929097660175518\n",
      "train loss:0.027754259849374116\n",
      "train loss:0.004363987341912689\n",
      "train loss:0.0011593120162577016\n",
      "train loss:0.019128630068229034\n",
      "train loss:0.03636041276358645\n",
      "train loss:0.008259321058293185\n",
      "train loss:0.0017356095019157047\n",
      "train loss:0.016973687485658733\n",
      "train loss:0.013167992445416346\n",
      "train loss:0.003113625296188669\n",
      "train loss:0.007825524393493292\n",
      "train loss:0.011757374426903309\n",
      "train loss:0.033519675696761536\n",
      "train loss:0.0074280264847992675\n",
      "train loss:0.008174487321559471\n",
      "train loss:0.015135077591044295\n",
      "train loss:0.004142706514100442\n",
      "train loss:0.010572910725001829\n",
      "train loss:0.003065928585958228\n",
      "train loss:0.01210259552021695\n",
      "train loss:0.0022198207279307547\n",
      "train loss:0.0004864611792661195\n",
      "train loss:0.0018226079054999517\n",
      "train loss:0.027106823510094233\n",
      "train loss:0.015223647567956862\n",
      "train loss:0.0030240701879671954\n",
      "train loss:0.006640890761814209\n",
      "train loss:0.0009515876856355053\n",
      "train loss:0.002889118364305751\n",
      "train loss:0.004957837850517916\n",
      "train loss:0.002739726991727472\n",
      "train loss:0.00579718254536224\n",
      "train loss:0.00015637869899061294\n",
      "train loss:0.0023603083024659275\n",
      "train loss:0.012600931015278826\n",
      "train loss:0.023786946724156283\n",
      "train loss:0.0025882759820101977\n",
      "train loss:0.004663581530366306\n",
      "train loss:0.010957571685003643\n",
      "train loss:0.0096174331956497\n",
      "train loss:0.007921172184355651\n",
      "train loss:0.0017540159883259949\n",
      "train loss:0.021736377954472016\n",
      "train loss:0.000868644857627106\n",
      "train loss:0.010712955221020082\n",
      "train loss:0.0038741582289937055\n",
      "train loss:0.00393822771094485\n",
      "train loss:0.0004495906450857086\n",
      "train loss:0.003920514093659946\n",
      "train loss:0.001981864334606377\n",
      "train loss:0.0014524912244846288\n",
      "train loss:0.0051833878240346645\n",
      "train loss:0.005636538865054366\n",
      "train loss:0.003137613386574032\n",
      "train loss:0.013524301480458833\n",
      "train loss:0.007377988575227635\n",
      "train loss:0.001047304533016589\n",
      "train loss:0.007948153927521257\n",
      "train loss:0.0034747097435490117\n",
      "train loss:0.021733030292238675\n",
      "train loss:0.004890924175846528\n",
      "train loss:0.005474788295410042\n",
      "train loss:0.04980477957061342\n",
      "train loss:0.012392162681621912\n",
      "train loss:0.006477922257976351\n",
      "train loss:0.001922975477377571\n",
      "train loss:0.007960756576338707\n",
      "train loss:0.0019061361457684636\n",
      "train loss:0.014916834446016363\n",
      "train loss:0.0015443496464248132\n",
      "train loss:0.006412406049230003\n",
      "train loss:0.006683183817975513\n",
      "train loss:0.0015149622025205564\n",
      "train loss:0.004049995184839375\n",
      "train loss:0.009433459548644269\n",
      "train loss:0.001085454920517328\n",
      "train loss:0.003847897146241932\n",
      "train loss:0.013546757344813073\n",
      "train loss:0.017501997622458368\n",
      "train loss:0.003459286164163816\n",
      "train loss:0.007336598390737576\n",
      "train loss:0.01359939801823619\n",
      "train loss:0.0005283786453253657\n",
      "train loss:0.003799349757871531\n",
      "train loss:0.009030586962015618\n",
      "train loss:0.011949914659005079\n",
      "train loss:0.006680439226671925\n",
      "train loss:0.01044161558264989\n",
      "train loss:0.012786407586398058\n",
      "train loss:0.001242688427104962\n",
      "train loss:0.010638721311471422\n",
      "train loss:0.013924584025285031\n",
      "train loss:0.001714191156860389\n",
      "train loss:0.0572728026651001\n",
      "train loss:0.009775070709385048\n",
      "train loss:0.043520981517748254\n",
      "train loss:0.001821804574395148\n",
      "train loss:0.04080977677537192\n",
      "train loss:0.0030731737200384163\n",
      "train loss:0.003514127880663405\n",
      "train loss:0.02536446978241428\n",
      "train loss:0.0017078052628572964\n",
      "train loss:0.025599987877017356\n",
      "train loss:0.02192326074150543\n",
      "train loss:0.007015609061650977\n",
      "train loss:0.0018662236460156357\n",
      "train loss:0.0010518304103280059\n",
      "train loss:0.01370193319027973\n",
      "train loss:0.008005252643960965\n",
      "train loss:0.0070328418376013665\n",
      "train loss:0.006802352781078801\n",
      "train loss:0.0030051106430657136\n",
      "train loss:0.000527878206378988\n",
      "train loss:0.01180435478044962\n",
      "train loss:0.029663775226148572\n",
      "train loss:0.004086426543351807\n",
      "train loss:0.0044879275147643605\n",
      "train loss:0.0021339862359276234\n",
      "train loss:0.00643636403164495\n",
      "train loss:0.03343121650787481\n",
      "train loss:0.0032012052282144425\n",
      "train loss:0.005073139622294397\n",
      "train loss:0.004373585725759496\n",
      "train loss:0.00684182057389408\n",
      "train loss:0.015623427806246655\n",
      "train loss:0.0032744117172224664\n",
      "train loss:0.07027476921190445\n",
      "train loss:0.00263192756172095\n",
      "train loss:0.0014602945477555527\n",
      "train loss:0.01237356249433553\n",
      "train loss:0.013887357850524543\n",
      "train loss:0.020360272907686022\n",
      "train loss:0.006759482589651526\n",
      "train loss:0.011297747089849805\n",
      "train loss:0.004398549732584514\n",
      "train loss:0.01721031474162317\n",
      "train loss:0.004994229848390109\n",
      "train loss:0.02829519687708015\n",
      "train loss:0.0009944308904838372\n",
      "train loss:0.00735197708522913\n",
      "train loss:0.0014814179307130768\n",
      "train loss:0.002391068820023589\n",
      "train loss:0.00747208380050647\n",
      "train loss:0.06209879345930633\n",
      "train loss:0.009965155746276282\n",
      "train loss:0.0048767499229750814\n",
      "train loss:0.0029254177398134206\n",
      "train loss:0.007023979932700045\n",
      "train loss:0.0041365278265681855\n",
      "train loss:0.006838365344225855\n",
      "train loss:0.00489955312975162\n",
      "train loss:0.030910675538508108\n",
      "train loss:0.027255125273516253\n",
      "train loss:0.009816508595265366\n",
      "train loss:0.029501929051528465\n",
      "train loss:0.011134890900280955\n",
      "train loss:0.004519015136029308\n",
      "train loss:0.005716158969021302\n",
      "train loss:0.008420652497497488\n",
      "train loss:0.0025330703531882028\n",
      "train loss:0.03954902374489361\n",
      "train loss:0.005273573472529395\n",
      "train loss:0.0210698226477304\n",
      "train loss:0.002496827476824069\n",
      "train loss:0.0697929972592732\n",
      "train loss:0.035178731159074064\n",
      "train loss:0.005765030122674578\n",
      "train loss:0.0026959446914903724\n",
      "train loss:0.004827510762908177\n",
      "train loss:0.005436293002877548\n",
      "train loss:0.02401798023850653\n",
      "train loss:0.01050929527800637\n",
      "train loss:0.026358592450351895\n",
      "train loss:0.009383300030505451\n",
      "train loss:0.033143719493206276\n",
      "train loss:0.0033209553761335913\n",
      "train loss:0.0020882812568202304\n",
      "train loss:0.0008575814807620133\n",
      "train loss:0.016226009405208245\n",
      "train loss:0.003275770931925477\n",
      "train loss:0.002734551536011323\n",
      "train loss:0.009842704227445466\n",
      "train loss:0.0045459943187515514\n",
      "train loss:0.005401376007532475\n",
      "train loss:0.005229006561551738\n",
      "train loss:0.0333343822486484\n",
      "train loss:0.016700113485593228\n",
      "train loss:0.01156141798807805\n",
      "train loss:0.016278250290594418\n",
      "train loss:0.012537501867242491\n",
      "train loss:0.011380985788992826\n",
      "train loss:0.0010466296267223243\n",
      "train loss:0.0035576115152192943\n",
      "train loss:0.0032784359375201606\n",
      "train loss:0.006767407556647389\n",
      "train loss:0.004166363542208914\n",
      "train loss:0.03585642420779704\n",
      "train loss:0.06061673830587857\n",
      "train loss:0.010033312517801369\n",
      "train loss:0.001842816410051618\n",
      "train loss:0.004871529168115247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.006396599117870866\n",
      "train loss:0.007944426884043043\n",
      "train loss:0.005417746481128028\n",
      "train loss:0.008023162725918812\n",
      "train loss:0.01022831464282273\n",
      "train loss:0.007404590300950075\n",
      "train loss:0.006971141487968031\n",
      "train loss:0.0025977640969017095\n",
      "train loss:0.0025211192603299365\n",
      "train loss:0.07407421241894763\n",
      "train loss:0.006572016644369031\n",
      "train loss:0.0010236545450719677\n",
      "train loss:0.016049014500910855\n",
      "train loss:0.0034654015533284355\n",
      "train loss:0.004104996547532834\n",
      "train loss:0.00954565757426323\n",
      "train loss:0.004881967609584113\n",
      "train loss:0.011009611188741894\n",
      "train loss:0.0021668735186970286\n",
      "train loss:0.008297169854538653\n",
      "train loss:0.005378648031640277\n",
      "train loss:0.008938300832018268\n",
      "train loss:0.005409227160920591\n",
      "train loss:0.0007037530952752772\n",
      "train loss:0.006888523111307994\n",
      "train loss:0.0077415490021914505\n",
      "train loss:0.0006633859732341143\n",
      "train loss:0.005311505159897888\n",
      "train loss:0.0030238122778117353\n",
      "train loss:0.0079478455994541\n",
      "train loss:0.00479631459525979\n",
      "train loss:0.0012577153383786165\n",
      "train loss:0.0017969368002768618\n",
      "train loss:0.003202116117870327\n",
      "train loss:0.03790766605445969\n",
      "train loss:0.021033846658329317\n",
      "train loss:0.0014717575742437378\n",
      "train loss:0.01857021241647213\n",
      "train loss:0.0041682058256160125\n",
      "train loss:0.012212578131990443\n",
      "train loss:0.002696526758079487\n",
      "train loss:0.0016162017723318947\n",
      "train loss:0.03366885822264026\n",
      "train loss:0.006799209699833883\n",
      "train loss:0.0005561863570282533\n",
      "train loss:0.013247427793669886\n",
      "train loss:0.009193105432224685\n",
      "train loss:0.006726842047459602\n",
      "train loss:0.01082938518690064\n",
      "train loss:0.002285480622229409\n",
      "train loss:0.02287207848251421\n",
      "train loss:0.013135588887558726\n",
      "train loss:0.01034287830425995\n",
      "train loss:0.018404659495218266\n",
      "train loss:0.0031868519032251475\n",
      "train loss:0.0022382173489133273\n",
      "train loss:0.003775758803281214\n",
      "train loss:0.015459497763800442\n",
      "train loss:0.005689721037929311\n",
      "train loss:0.0019069129302110089\n",
      "train loss:0.007835640939932836\n",
      "train loss:0.002009977808449923\n",
      "train loss:0.00710115941015819\n",
      "train loss:0.020445193633378298\n",
      "train loss:0.012956382469008439\n",
      "train loss:0.007912417243714822\n",
      "train loss:0.002489505638107898\n",
      "train loss:0.02525798286165597\n",
      "train loss:0.0076014480074113565\n",
      "train loss:0.020331365272371286\n",
      "train loss:0.00540542224272741\n",
      "train loss:0.012280444611306604\n",
      "train loss:0.011479356998745171\n",
      "train loss:0.005102028678773348\n",
      "train loss:0.003388605870759011\n",
      "train loss:0.006937603851694691\n",
      "train loss:0.0491385636825644\n",
      "train loss:0.007591517300122327\n",
      "train loss:0.0067995019856772025\n",
      "train loss:0.06389412009101891\n",
      "train loss:0.001250626569113876\n",
      "train loss:0.006776667285819314\n",
      "train loss:0.003771156602070034\n",
      "train loss:0.0019545218194830043\n",
      "train loss:0.003797798314562873\n",
      "train loss:0.027883058985539853\n",
      "train loss:0.009104299919987522\n",
      "train loss:0.0018554750442743681\n",
      "train loss:0.007985749889768549\n",
      "train loss:0.01939130671935968\n",
      "train loss:0.0027265945793621587\n",
      "train loss:0.006922876994499596\n",
      "train loss:0.0018329550408976577\n",
      "train loss:0.018063234198726526\n",
      "train loss:0.013626090816041561\n",
      "train loss:0.031445449491055835\n",
      "train loss:0.004850070300994625\n",
      "train loss:0.013538853809637407\n",
      "train loss:0.0038770015424919673\n",
      "train loss:0.003266203981481538\n",
      "train loss:0.0057177213987502215\n",
      "train loss:0.013579239761283475\n",
      "train loss:0.0021121381216746894\n",
      "train loss:0.024356407294449527\n",
      "train loss:0.011188393375719244\n",
      "train loss:0.02081954716098141\n",
      "train loss:0.021161253987365472\n",
      "train loss:0.006256724169625667\n",
      "train loss:0.006586130472294188\n",
      "train loss:0.00598448276204004\n",
      "train loss:0.013575938232438687\n",
      "train loss:0.0146542699069018\n",
      "train loss:0.010546434090349674\n",
      "train loss:0.002427444371400969\n",
      "train loss:0.03354807458229601\n",
      "train loss:0.030324052765857\n",
      "train loss:0.03700427228153208\n",
      "train loss:0.010415078569574627\n",
      "train loss:0.0008161959276358825\n",
      "train loss:0.00785803562774237\n",
      "train loss:0.0007079024163517887\n",
      "train loss:0.011744939351315209\n",
      "train loss:0.003373625164614619\n",
      "train loss:0.01794119532872305\n",
      "train loss:0.015695866654826605\n",
      "train loss:0.014153535018914252\n",
      "train loss:0.004227722529475094\n",
      "train loss:0.005726814526797034\n",
      "train loss:0.026296730856407383\n",
      "train loss:0.005955070996511809\n",
      "train loss:0.010280201689411033\n",
      "train loss:0.002046700426501039\n",
      "train loss:0.004767324914106535\n",
      "train loss:0.002056207595179751\n",
      "train loss:0.010080503364584228\n",
      "train loss:0.004651351949060887\n",
      "train loss:0.01142182299798516\n",
      "train loss:0.0028946550797450867\n",
      "train loss:0.03711365167110787\n",
      "train loss:0.03395182791722786\n",
      "train loss:0.009285273173512828\n",
      "train loss:0.004199753432206864\n",
      "train loss:0.007745502785221497\n",
      "train loss:0.010748635419839902\n",
      "train loss:0.005341709317399976\n",
      "train loss:0.0031629552672845685\n",
      "train loss:0.0076721045540552365\n",
      "train loss:0.01150066218519214\n",
      "train loss:0.00167600051177128\n",
      "train loss:0.004712014895595301\n",
      "train loss:0.01961398081002739\n",
      "train loss:0.002667545411376034\n",
      "train loss:0.0021197602156333177\n",
      "train loss:0.024853207356601605\n",
      "train loss:0.0019006763369758448\n",
      "train loss:0.009943976725584523\n",
      "train loss:0.0052283334335316844\n",
      "train loss:0.005248815920898669\n",
      "train loss:0.008304165373628391\n",
      "train loss:0.012702955343357147\n",
      "train loss:0.007127017226758704\n",
      "train loss:0.0021256336806032656\n",
      "train loss:0.003369662722467479\n",
      "train loss:0.0030085537492376196\n",
      "train loss:0.029950580531055582\n",
      "train loss:0.002845899432755781\n",
      "train loss:0.032013735295777127\n",
      "train loss:0.00414644230109141\n",
      "train loss:0.015925941863393297\n",
      "train loss:0.005175480787164496\n",
      "train loss:0.007431108958905472\n",
      "train loss:0.002272464958660485\n",
      "train loss:0.01840353015518814\n",
      "train loss:0.0025965494854574456\n",
      "train loss:0.00214740808610376\n",
      "train loss:0.022111793614153358\n",
      "train loss:0.005339845939584292\n",
      "train loss:0.029679478662293195\n",
      "train loss:0.0030440380307131514\n",
      "train loss:0.002983299628301902\n",
      "train loss:0.002616926022832739\n",
      "train loss:0.009897653063164718\n",
      "train loss:0.007440366165159835\n",
      "train loss:0.009102641789697443\n",
      "train loss:0.011088231104751186\n",
      "train loss:0.015293659530493815\n",
      "train loss:0.003953575166597828\n",
      "train loss:0.02258455563371958\n",
      "train loss:0.0027276929943138312\n",
      "train loss:0.0070390203345231765\n",
      "train loss:0.015195040502315222\n",
      "train loss:0.0019714623743373534\n",
      "train loss:0.006754942824579666\n",
      "train loss:0.006689310735586567\n",
      "train loss:0.006374500530658173\n",
      "train loss:0.005256516821602145\n",
      "train loss:0.0035885444662513543\n",
      "train loss:0.009538283159957129\n",
      "train loss:0.005881561683829818\n",
      "train loss:0.0024614089746239913\n",
      "train loss:0.011958539689752232\n",
      "train loss:0.006176923816816886\n",
      "train loss:0.0035595690205066765\n",
      "train loss:0.016783631328036477\n",
      "train loss:0.0022482567949947134\n",
      "train loss:0.00972272898368381\n",
      "train loss:0.009029697539315498\n",
      "train loss:0.008001516769302252\n",
      "train loss:0.00278405608848915\n",
      "train loss:0.014316005391333018\n",
      "train loss:0.0016966477603202123\n",
      "train loss:0.007508563958082554\n",
      "train loss:0.007163084314455979\n",
      "train loss:0.005635958205570815\n",
      "train loss:0.0026803193527978365\n",
      "train loss:0.0032495546788076563\n",
      "train loss:0.012818925991289015\n",
      "train loss:0.0060524368861884755\n",
      "train loss:0.023178625967913334\n",
      "train loss:0.0014647776992354098\n",
      "train loss:0.0027519139250527314\n",
      "train loss:0.0029369650421488523\n",
      "train loss:0.005410157856793826\n",
      "train loss:0.000612059969788807\n",
      "train loss:0.025042776518896588\n",
      "train loss:0.005439714463123957\n",
      "train loss:0.0017179985260870009\n",
      "train loss:0.011960326987645516\n",
      "train loss:0.004219596624130916\n",
      "train loss:0.013118996844522647\n",
      "train loss:0.013885016132949946\n",
      "train loss:0.0014242489515791654\n",
      "train loss:0.00202910391862012\n",
      "train loss:0.007938021577598322\n",
      "train loss:0.002400357295389054\n",
      "train loss:0.0008104757560875765\n",
      "train loss:0.0033062286075743103\n",
      "train loss:0.007168811696231501\n",
      "train loss:0.0660228410428533\n",
      "train loss:0.004001366816973018\n",
      "train loss:0.006445639299916322\n",
      "train loss:0.0036995055033927715\n",
      "train loss:0.018324891902075115\n",
      "train loss:0.003732603906149194\n",
      "train loss:0.004018192617204081\n",
      "train loss:0.044741443027564456\n",
      "train loss:0.01997060335170882\n",
      "train loss:0.009325154706728156\n",
      "train loss:0.015913199503735435\n",
      "train loss:0.004296022388177406\n",
      "train loss:0.007799891487250085\n",
      "train loss:0.012678083843681966\n",
      "train loss:0.006193093481898342\n",
      "train loss:0.002689077930655292\n",
      "train loss:0.0011290999968999872\n",
      "train loss:0.006522518792420601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.06628571970084259\n",
      "train loss:0.003006598432676523\n",
      "train loss:0.005606431288693834\n",
      "train loss:0.022117525320132433\n",
      "train loss:0.00870474035741955\n",
      "train loss:0.0013959332872677227\n",
      "train loss:0.008087398474933373\n",
      "train loss:0.014632125172780026\n",
      "train loss:0.010632370954560502\n",
      "train loss:0.006199804101508619\n",
      "train loss:0.005867669247849667\n",
      "train loss:0.025655612366987247\n",
      "train loss:0.023027719782530293\n",
      "train loss:0.04675345602050898\n",
      "train loss:0.010631376768632095\n",
      "train loss:0.003508923963938222\n",
      "train loss:0.010159562837389216\n",
      "train loss:0.015222759025931575\n",
      "train loss:0.002771811799363341\n",
      "train loss:0.00489080436673376\n",
      "train loss:0.0013072761759357918\n",
      "train loss:0.004872857429414363\n",
      "train loss:0.014670934403625874\n",
      "train loss:0.004199259657833526\n",
      "train loss:0.016063155640275665\n",
      "train loss:0.0015159298352515895\n",
      "train loss:0.006238035094010216\n",
      "train loss:0.003919869248304446\n",
      "train loss:0.006537033412944366\n",
      "train loss:0.0012028696830962864\n",
      "train loss:0.005874469574313399\n",
      "train loss:0.0133390943450045\n",
      "train loss:0.02649329583230379\n",
      "train loss:0.03813310425286923\n",
      "train loss:0.009310724906987516\n",
      "train loss:0.005294646916140203\n",
      "train loss:0.0032447880902917005\n",
      "train loss:0.003398624976541713\n",
      "train loss:0.005258150377056876\n",
      "train loss:0.015640003251992992\n",
      "train loss:0.00907681709749715\n",
      "train loss:0.01270661150351532\n",
      "train loss:0.014678754232446101\n",
      "train loss:0.020841868601579737\n",
      "train loss:0.008696624891983475\n",
      "train loss:0.0041065812321883196\n",
      "train loss:0.005323350495008582\n",
      "train loss:0.002595985212441456\n",
      "train loss:0.010541438606693834\n",
      "train loss:0.001350287925739923\n",
      "train loss:0.0035007953165835316\n",
      "train loss:0.004621997491264816\n",
      "train loss:0.0318359505242154\n",
      "train loss:0.03410543461656756\n",
      "train loss:0.024037244714930295\n",
      "train loss:0.0036188628794068833\n",
      "train loss:0.012286742917758863\n",
      "train loss:0.018969364401278152\n",
      "train loss:0.0012675513178573073\n",
      "train loss:0.013412515791452327\n",
      "train loss:0.002329099173553087\n",
      "train loss:0.005817477834226326\n",
      "train loss:0.009847096723343086\n",
      "train loss:0.005196629166840855\n",
      "train loss:0.0061915833252468725\n",
      "train loss:0.0209534651855533\n",
      "train loss:0.0019115857643784468\n",
      "train loss:0.014935070322844695\n",
      "train loss:0.0013888661547954606\n",
      "train loss:0.0084852249755508\n",
      "train loss:0.011381275539509662\n",
      "train loss:0.011145082688802805\n",
      "train loss:0.019472899882702194\n",
      "train loss:0.0043437199561026305\n",
      "train loss:0.0033663937322213735\n",
      "train loss:0.009030362220110328\n",
      "train loss:0.011096937950195753\n",
      "train loss:0.014013160677309093\n",
      "train loss:0.00884497160301288\n",
      "train loss:0.024860566337805246\n",
      "train loss:0.009066375398983195\n",
      "train loss:0.0035016201254353635\n",
      "train loss:0.0019353964763201825\n",
      "train loss:0.01524207342834627\n",
      "train loss:0.010362082594512148\n",
      "train loss:0.00307958193922725\n",
      "train loss:0.005136650641770003\n",
      "train loss:0.013452392741223795\n",
      "train loss:0.013559391363030408\n",
      "train loss:0.03330136351765455\n",
      "train loss:0.0073014422660175275\n",
      "train loss:0.0036140261734880163\n",
      "train loss:0.008257916734883502\n",
      "train loss:0.02773174525669534\n",
      "train loss:0.0038013541374093155\n",
      "train loss:0.030612897884968092\n",
      "train loss:0.02797401581328843\n",
      "train loss:0.06355568645939133\n",
      "train loss:0.007039065458142048\n",
      "train loss:0.027376619485656582\n",
      "train loss:0.002459141678286731\n",
      "train loss:0.005046772502088597\n",
      "train loss:0.007178942566290614\n",
      "train loss:0.007511073285462191\n",
      "train loss:0.005165549891526352\n",
      "train loss:0.010646931521674056\n",
      "train loss:0.005045231318167559\n",
      "train loss:0.0029569347435494248\n",
      "train loss:0.007257463360638662\n",
      "=== epoch:9, train acc:0.996, test acc:0.982 ===\n",
      "train loss:0.016362217351156675\n",
      "train loss:0.00230724290090908\n",
      "train loss:0.05258208586476819\n",
      "train loss:0.015807240526674215\n",
      "train loss:0.0009644187116797261\n",
      "train loss:0.0028918372932282676\n",
      "train loss:0.03442362324050835\n",
      "train loss:0.0033379446362118204\n",
      "train loss:0.008409442781091635\n",
      "train loss:0.0023333315898812633\n",
      "train loss:0.0012864736988341438\n",
      "train loss:0.002357149465993561\n",
      "train loss:0.01140884506974886\n",
      "train loss:0.004128933847208748\n",
      "train loss:0.002527263806604028\n",
      "train loss:0.0026705017074802433\n",
      "train loss:0.0011841599611509418\n",
      "train loss:0.007145202085479414\n",
      "train loss:0.002815514846214251\n",
      "train loss:0.005911603333031361\n",
      "train loss:0.002601210292633206\n",
      "train loss:0.024438826770071604\n",
      "train loss:0.006219993430017914\n",
      "train loss:0.003543059722296649\n",
      "train loss:0.00510801822362315\n",
      "train loss:0.03367989386666864\n",
      "train loss:0.006637336430276646\n",
      "train loss:0.004993389283928264\n",
      "train loss:0.0019187877471747556\n",
      "train loss:0.0009376181677751105\n",
      "train loss:0.008827687595984355\n",
      "train loss:0.03769513954111044\n",
      "train loss:0.007012219454325694\n",
      "train loss:0.0006981442896373205\n",
      "train loss:0.0033478613135474646\n",
      "train loss:0.0012937190489137461\n",
      "train loss:0.033992392946224304\n",
      "train loss:0.008978700470325906\n",
      "train loss:0.0036727640730122237\n",
      "train loss:0.004367095111430127\n",
      "train loss:0.001014247256352941\n",
      "train loss:0.0014595546085798472\n",
      "train loss:0.025210009101554263\n",
      "train loss:0.005063126115053069\n",
      "train loss:0.01142596656153989\n",
      "train loss:0.005303692461865648\n",
      "train loss:0.005175184231454227\n",
      "train loss:0.009637055358806124\n",
      "train loss:0.0076193100717179656\n",
      "train loss:0.0057572243891998165\n",
      "train loss:0.0008878011310316574\n",
      "train loss:0.03732538491267702\n",
      "train loss:0.006362913848323841\n",
      "train loss:0.004747471091325884\n",
      "train loss:0.009682419706522566\n",
      "train loss:0.0024391457180639405\n",
      "train loss:0.002122475896167432\n",
      "train loss:0.0021891650142887046\n",
      "train loss:0.01713682727860636\n",
      "train loss:0.0019485673543960514\n",
      "train loss:0.019512080129418952\n",
      "train loss:0.008322732007125166\n",
      "train loss:0.009320705703536521\n",
      "train loss:0.0021944118765628625\n",
      "train loss:0.02951971579450195\n",
      "train loss:0.05511600204328138\n",
      "train loss:0.05224122745659734\n",
      "train loss:0.0049874795735309055\n",
      "train loss:0.009110790363543161\n",
      "train loss:0.006762319295841768\n",
      "train loss:0.0026663227420683855\n",
      "train loss:0.04512985896197156\n",
      "train loss:0.019955829787914704\n",
      "train loss:0.021548145295272304\n",
      "train loss:0.007616227298366068\n",
      "train loss:0.04244452426205147\n",
      "train loss:0.03553350725963559\n",
      "train loss:0.008351715238912084\n",
      "train loss:0.0037985688869638734\n",
      "train loss:0.004348238867474481\n",
      "train loss:0.0018850624331709371\n",
      "train loss:0.009469934304576953\n",
      "train loss:0.028616151813527342\n",
      "train loss:0.0033046393466215507\n",
      "train loss:0.002050288882606287\n",
      "train loss:0.005059962792273582\n",
      "train loss:0.002112173333571287\n",
      "train loss:0.004943743913730735\n",
      "train loss:0.0026058581046066896\n",
      "train loss:0.008442135008684884\n",
      "train loss:0.0066945570085053694\n",
      "train loss:0.002180229362247264\n",
      "train loss:0.007827570318332365\n",
      "train loss:0.0030849046541560226\n",
      "train loss:0.0005891958170306127\n",
      "train loss:0.00952618881143271\n",
      "train loss:0.00961616507097626\n",
      "train loss:0.007157383653645636\n",
      "train loss:0.004726474208625014\n",
      "train loss:0.0013889856943660598\n",
      "train loss:0.04425616275808595\n",
      "train loss:0.006162895307681508\n",
      "train loss:0.017650224363926933\n",
      "train loss:0.0028079232045357273\n",
      "train loss:0.002068775679925633\n",
      "train loss:0.007540935345186903\n",
      "train loss:0.00349265211260308\n",
      "train loss:0.02293743979082086\n",
      "train loss:0.01873760982871336\n",
      "train loss:0.008465423737067686\n",
      "train loss:0.07443502233286856\n",
      "train loss:0.008834392219099705\n",
      "train loss:0.039455161729347085\n",
      "train loss:0.01475691809141117\n",
      "train loss:0.004849189044371321\n",
      "train loss:0.003273667051422417\n",
      "train loss:0.00676029706759352\n",
      "train loss:0.014572844206898162\n",
      "train loss:0.012866590785982228\n",
      "train loss:0.03525812905456797\n",
      "train loss:0.008169213258983175\n",
      "train loss:0.0030726812232439015\n",
      "train loss:0.008407514621523502\n",
      "train loss:0.011230941968587049\n",
      "train loss:0.009718178797877444\n",
      "train loss:0.002843455275127005\n",
      "train loss:0.0031649023114469453\n",
      "train loss:0.022610168394391908\n",
      "train loss:0.00681867144805772\n",
      "train loss:0.0014062868846318475\n",
      "train loss:0.005343414749336327\n",
      "train loss:0.0016345490007130428\n",
      "train loss:0.0010892609261255047\n",
      "train loss:0.003738141378337925\n",
      "train loss:0.005698942909672361\n",
      "train loss:0.00351073116097503\n",
      "train loss:0.0233938838640198\n",
      "train loss:0.004521887365080404\n",
      "train loss:0.016822607390815154\n",
      "train loss:0.16402854246055504\n",
      "train loss:0.0036042522945008886\n",
      "train loss:0.009256881231894498\n",
      "train loss:0.005790263693164588\n",
      "train loss:0.006720540022660283\n",
      "train loss:0.003412656693358651\n",
      "train loss:0.0009483687642353483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009444248714196965\n",
      "train loss:0.004639632859358186\n",
      "train loss:0.01510868508748668\n",
      "train loss:0.01717546390372114\n",
      "train loss:0.01771448414820771\n",
      "train loss:0.004715948013242281\n",
      "train loss:0.003302607315632682\n",
      "train loss:0.0019574519426093563\n",
      "train loss:0.006347688223864036\n",
      "train loss:0.007230770015083889\n",
      "train loss:0.034415972112605636\n",
      "train loss:0.03543430008201405\n",
      "train loss:0.011997612949867183\n",
      "train loss:0.021628175167763247\n",
      "train loss:0.004085637838885651\n",
      "train loss:0.004557291992199574\n",
      "train loss:0.007542072200461468\n",
      "train loss:0.005399623894701243\n",
      "train loss:0.012599156994954435\n",
      "train loss:0.00676388266745223\n",
      "train loss:0.008164264838569886\n",
      "train loss:0.002505551548649587\n",
      "train loss:0.01559253442699366\n",
      "train loss:0.007175182470170907\n",
      "train loss:0.0030341805709365455\n",
      "train loss:0.003123078127123969\n",
      "train loss:0.006223922845850266\n",
      "train loss:0.013667678315316711\n",
      "train loss:0.00228556674765148\n",
      "train loss:0.009885551869632931\n",
      "train loss:0.0036808779006608206\n",
      "train loss:0.004611374264989533\n",
      "train loss:0.0012347354734087734\n",
      "train loss:0.002301397793111756\n",
      "train loss:0.0019237172753553224\n",
      "train loss:0.008668668992986767\n",
      "train loss:0.0011850347416503637\n",
      "train loss:0.0020923694898456035\n",
      "train loss:0.010383452686207419\n",
      "train loss:0.0070405815574735185\n",
      "train loss:0.005972280152935336\n",
      "train loss:0.008808941109004936\n",
      "train loss:0.013159775808330372\n",
      "train loss:0.004854408417950772\n",
      "train loss:0.018297575383127332\n",
      "train loss:0.019829382072455243\n",
      "train loss:0.02264624103892515\n",
      "train loss:0.003373241047326548\n",
      "train loss:0.012078457082885574\n",
      "train loss:0.0031353183818820015\n",
      "train loss:0.00979995120960883\n",
      "train loss:0.013107544160618606\n",
      "train loss:0.0015090130220161415\n",
      "train loss:0.017371469094731723\n",
      "train loss:0.04858812010157786\n",
      "train loss:0.041002512322794754\n",
      "train loss:0.018062265688903366\n",
      "train loss:0.006859344896790134\n",
      "train loss:0.01696134990857367\n",
      "train loss:0.008578164524075086\n",
      "train loss:0.002798641688132044\n",
      "train loss:0.005078550467454478\n",
      "train loss:0.0035200427764187085\n",
      "train loss:0.00119995584369831\n",
      "train loss:0.003733747234019167\n",
      "train loss:0.006359812945009083\n",
      "train loss:0.005404365823990299\n",
      "train loss:0.0032664216282882923\n",
      "train loss:0.008716406602518732\n",
      "train loss:0.005847798676313165\n",
      "train loss:0.008328013396505643\n",
      "train loss:0.0016232642006771\n",
      "train loss:0.0033197421259463728\n",
      "train loss:0.023487523922246966\n",
      "train loss:0.005474164725807625\n",
      "train loss:0.01199002066907534\n",
      "train loss:0.0039005270099681886\n",
      "train loss:0.0063236779660270186\n",
      "train loss:0.0077889450262262185\n",
      "train loss:0.006875024623564427\n",
      "train loss:0.003889779161715228\n",
      "train loss:0.00949398901466407\n",
      "train loss:0.010565241936358622\n",
      "train loss:0.004659990807477593\n",
      "train loss:0.01912030028060633\n",
      "train loss:0.00381856967924446\n",
      "train loss:0.020530975803812187\n",
      "train loss:0.0025520853024378117\n",
      "train loss:0.0009334757696034099\n",
      "train loss:0.014251325887193012\n",
      "train loss:0.00634810805640785\n",
      "train loss:0.023005328639780154\n",
      "train loss:0.0016200290698708806\n",
      "train loss:0.004331200130323647\n",
      "train loss:0.001683857495412929\n",
      "train loss:0.012587915617732958\n",
      "train loss:0.05020548302856292\n",
      "train loss:0.0035984342923911085\n",
      "train loss:0.003720569609880658\n",
      "train loss:0.014913749512416086\n",
      "train loss:0.007199772137274551\n",
      "train loss:0.003878391717912679\n",
      "train loss:0.02410317030456286\n",
      "train loss:0.011696551284729793\n",
      "train loss:0.005284406950960634\n",
      "train loss:0.001614065953558681\n",
      "train loss:0.002950723876073797\n",
      "train loss:0.059038841583376536\n",
      "train loss:0.0006750990935191982\n",
      "train loss:0.008290098116800598\n",
      "train loss:0.019685957481612747\n",
      "train loss:0.0014101174852432128\n",
      "train loss:0.0011416962600873668\n",
      "train loss:0.014034277406172689\n",
      "train loss:0.004764114559941886\n",
      "train loss:0.0029239262165448314\n",
      "train loss:0.010653998423706972\n",
      "train loss:0.0036884379296966145\n",
      "train loss:0.004258554690893404\n",
      "train loss:0.006999849564279651\n",
      "train loss:0.015443955449578274\n",
      "train loss:0.04466333946832248\n",
      "train loss:0.003954544409487689\n",
      "train loss:0.06659350858212926\n",
      "train loss:0.013627108123921176\n",
      "train loss:0.006199912780626446\n",
      "train loss:0.006450241228503084\n",
      "train loss:0.00509716398568159\n",
      "train loss:0.0011758566878194289\n",
      "train loss:0.005444699221539205\n",
      "train loss:0.011322836464879728\n",
      "train loss:0.010309706426345253\n",
      "train loss:0.013658563210792807\n",
      "train loss:0.005144576575636708\n",
      "train loss:0.02638605926843813\n",
      "train loss:0.005484689742043219\n",
      "train loss:0.005273922629321115\n",
      "train loss:0.028894050658505043\n",
      "train loss:0.002668619852514316\n",
      "train loss:0.010241865694285675\n",
      "train loss:0.0063263873922773\n",
      "train loss:0.0059618805956048624\n",
      "train loss:0.0015055939428592305\n",
      "train loss:0.008910310085543695\n",
      "train loss:0.05286742039994501\n",
      "train loss:0.014390920652019922\n",
      "train loss:0.009157630459683912\n",
      "train loss:0.0007256139993084188\n",
      "train loss:0.0008878598398808259\n",
      "train loss:0.00400788059017269\n",
      "train loss:0.017143829611757977\n",
      "train loss:0.014428327167682114\n",
      "train loss:0.001593682201533323\n",
      "train loss:0.008534567457381103\n",
      "train loss:0.004935473466097876\n",
      "train loss:0.004494202196705895\n",
      "train loss:0.007280939698165563\n",
      "train loss:0.001501481545394488\n",
      "train loss:0.044607213979326786\n",
      "train loss:0.004263484842533675\n",
      "train loss:0.0036063610473552133\n",
      "train loss:0.009803496855216086\n",
      "train loss:0.0074947715859937205\n",
      "train loss:0.005424103809892334\n",
      "train loss:0.006505817960248231\n",
      "train loss:0.009242442495370526\n",
      "train loss:0.005918718880465328\n",
      "train loss:0.0009921234634863323\n",
      "train loss:0.007226192177345008\n",
      "train loss:0.007851490424601482\n",
      "train loss:0.00338449924605029\n",
      "train loss:0.014829479546044808\n",
      "train loss:0.017160927002463574\n",
      "train loss:0.0024245237508122124\n",
      "train loss:0.004718112762330961\n",
      "train loss:0.001760613551742716\n",
      "train loss:0.002624235151588229\n",
      "train loss:0.0008208132727964432\n",
      "train loss:0.003067411124651358\n",
      "train loss:0.03039147368504085\n",
      "train loss:0.0007848943847674186\n",
      "train loss:0.018980614442317474\n",
      "train loss:0.0034934464069619016\n",
      "train loss:0.01767292007638302\n",
      "train loss:0.0032012248474843855\n",
      "train loss:0.0039255782363446495\n",
      "train loss:0.01560051774650122\n",
      "train loss:0.010456109056366148\n",
      "train loss:0.0010321050745052518\n",
      "train loss:0.02118788921162336\n",
      "train loss:0.0013278231789134428\n",
      "train loss:0.0040702000369626035\n",
      "train loss:0.01136105328581668\n",
      "train loss:0.005877716084755302\n",
      "train loss:0.0005140453932789398\n",
      "train loss:0.014743082417143068\n",
      "train loss:0.016833559777797474\n",
      "train loss:0.009050539935345981\n",
      "train loss:0.0021282755423747517\n",
      "train loss:0.008293800811167915\n",
      "train loss:0.0011170904260462038\n",
      "train loss:0.0022046981096062192\n",
      "train loss:0.023349753641567175\n",
      "train loss:0.0014941951184069332\n",
      "train loss:0.001226004449873262\n",
      "train loss:0.021907129314141325\n",
      "train loss:0.001350035257411069\n",
      "train loss:0.015968673708229436\n",
      "train loss:0.0037568883464707365\n",
      "train loss:0.006225949519958215\n",
      "train loss:0.0027012747614011323\n",
      "train loss:0.011561471366695384\n",
      "train loss:0.0013071550506807018\n",
      "train loss:0.015755353080626665\n",
      "train loss:0.03889580829047654\n",
      "train loss:0.0029973350084479384\n",
      "train loss:0.01105608221214124\n",
      "train loss:0.002851595096418812\n",
      "train loss:0.0041928871062572055\n",
      "train loss:0.001864626698735727\n",
      "train loss:0.0016130287210585936\n",
      "train loss:0.0030197029097696016\n",
      "train loss:0.0017937052901466483\n",
      "train loss:0.0016193537427290022\n",
      "train loss:0.04184715268477282\n",
      "train loss:0.009669474007921869\n",
      "train loss:0.006799187204825279\n",
      "train loss:0.03745723822230172\n",
      "train loss:0.010489237001633596\n",
      "train loss:0.004854188236634776\n",
      "train loss:0.016316843064860434\n",
      "train loss:0.006966218730232249\n",
      "train loss:0.00790475348786634\n",
      "train loss:0.0066455320337668955\n",
      "train loss:0.009080255917330965\n",
      "train loss:0.009593303399448942\n",
      "train loss:0.03685095625717707\n",
      "train loss:0.005819640659793787\n",
      "train loss:0.0020273278752215153\n",
      "train loss:0.022989080762489303\n",
      "train loss:0.0038049795054275553\n",
      "train loss:0.005659493160904253\n",
      "train loss:0.003018606639656716\n",
      "train loss:0.002150547226448463\n",
      "train loss:0.007311904542273328\n",
      "train loss:0.025791545986388675\n",
      "train loss:0.0054715032312796915\n",
      "train loss:0.002943167915343428\n",
      "train loss:0.03292490422676744\n",
      "train loss:0.010515299458449194\n",
      "train loss:0.0026782191685568533\n",
      "train loss:0.0020055926771799064\n",
      "train loss:0.0005135161625032576\n",
      "train loss:0.013440976753240842\n",
      "train loss:0.018890034936788223\n",
      "train loss:0.009367850193916257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009306654693102214\n",
      "train loss:0.0030880639473155696\n",
      "train loss:0.0012465936475274844\n",
      "train loss:0.007588321126602122\n",
      "train loss:0.009986436311974716\n",
      "train loss:0.0016469652767345253\n",
      "train loss:0.006018930508743746\n",
      "train loss:0.011025565486166735\n",
      "train loss:0.05651888814801888\n",
      "train loss:0.0006288892838502745\n",
      "train loss:0.04085575468664638\n",
      "train loss:0.0028199683038032074\n",
      "train loss:0.0016489726655272482\n",
      "train loss:0.0008991232804718454\n",
      "train loss:0.001551028977338358\n",
      "train loss:0.008407452365705972\n",
      "train loss:0.004309602535193611\n",
      "train loss:0.009750706929413645\n",
      "train loss:0.004132039666164033\n",
      "train loss:0.025744875220781394\n",
      "train loss:0.0035983872467334668\n",
      "train loss:0.00937376298720412\n",
      "train loss:0.006201852128864094\n",
      "train loss:0.001881527438626874\n",
      "train loss:0.005104877095876996\n",
      "train loss:0.004141968165643209\n",
      "train loss:0.00042523114641559496\n",
      "train loss:0.006551950764199561\n",
      "train loss:0.04203154826862259\n",
      "train loss:0.003208531563883877\n",
      "train loss:0.007236931087812373\n",
      "train loss:0.00875096658819357\n",
      "train loss:0.00353745853459989\n",
      "train loss:0.00385367955179121\n",
      "train loss:0.002504287755565459\n",
      "train loss:0.0038864854596055032\n",
      "train loss:0.007695462480013905\n",
      "train loss:0.00830369880082935\n",
      "train loss:0.005308540367571374\n",
      "train loss:0.006209621487671093\n",
      "train loss:0.00469751529347\n",
      "train loss:0.008455893798709735\n",
      "train loss:0.0017525935439103176\n",
      "train loss:0.0010080096849722172\n",
      "train loss:0.008697690684273453\n",
      "train loss:0.005363344873092349\n",
      "train loss:0.015089893562051532\n",
      "train loss:0.006737044093364243\n",
      "train loss:0.000984189040810541\n",
      "train loss:0.00046696997715222775\n",
      "train loss:0.013258248300899955\n",
      "train loss:0.0032641929129715837\n",
      "train loss:0.0021706676974643136\n",
      "train loss:0.013566921277990298\n",
      "train loss:0.002686851477693349\n",
      "train loss:0.003675424276108016\n",
      "train loss:0.008758710922549257\n",
      "train loss:0.00045535714374510266\n",
      "train loss:0.0076810444477173265\n",
      "train loss:0.0129833120133658\n",
      "train loss:0.0008747025150802769\n",
      "train loss:0.004020979096871321\n",
      "train loss:0.004861733191716153\n",
      "train loss:0.0013458409720811745\n",
      "train loss:0.01595070395579966\n",
      "train loss:0.0010868221585444708\n",
      "train loss:0.003233294409558679\n",
      "train loss:0.0012505231003066566\n",
      "train loss:0.000742861277708191\n",
      "train loss:0.0018912175277959\n",
      "train loss:0.004098847634694088\n",
      "train loss:0.03251478799364946\n",
      "train loss:0.0031696228435853673\n",
      "train loss:0.023203187320249792\n",
      "train loss:0.010652544427564994\n",
      "train loss:0.003366421170928208\n",
      "train loss:0.005907945310651816\n",
      "train loss:0.008193966062004919\n",
      "train loss:0.0060056707796355925\n",
      "train loss:0.012492941766408906\n",
      "train loss:0.014061402526138215\n",
      "train loss:0.0049134885702182066\n",
      "train loss:0.003383956348384777\n",
      "train loss:0.005656095872768493\n",
      "train loss:0.007310489489414638\n",
      "train loss:0.011479408676428873\n",
      "train loss:0.002735782957112538\n",
      "train loss:0.007431826321664487\n",
      "train loss:0.0021059717567286046\n",
      "train loss:0.0058074889389707575\n",
      "train loss:0.005795088511076475\n",
      "train loss:0.007305389207172\n",
      "train loss:0.0013205091029181604\n",
      "train loss:0.0036852360740013035\n",
      "train loss:0.006974631073887628\n",
      "train loss:0.0042709554981903335\n",
      "train loss:0.00521295051891607\n",
      "train loss:0.0006109663865066594\n",
      "train loss:0.004809426434175144\n",
      "train loss:0.008167635202703225\n",
      "train loss:0.0014082020850343063\n",
      "train loss:0.0027400886039814724\n",
      "train loss:0.0033670371557833465\n",
      "train loss:0.001829259286269633\n",
      "train loss:0.0012547397331634175\n",
      "train loss:0.00032724944119405996\n",
      "train loss:0.004034168279120566\n",
      "train loss:0.00826291176951752\n",
      "train loss:0.0012552026257511837\n",
      "train loss:0.0009404680544235956\n",
      "train loss:0.00876382119816117\n",
      "train loss:0.005070178545607391\n",
      "train loss:0.008603593033626043\n",
      "train loss:0.0052670912418307314\n",
      "train loss:0.003922058747282592\n",
      "train loss:0.0038006026124610707\n",
      "train loss:0.0003440330273567672\n",
      "train loss:0.004620052631568955\n",
      "train loss:0.030149055899967716\n",
      "train loss:0.0024816848579744407\n",
      "train loss:0.0014904388188222894\n",
      "train loss:0.0072970711851697515\n",
      "train loss:0.0003212818873610685\n",
      "train loss:0.0015398279215235605\n",
      "train loss:0.035731493052779735\n",
      "train loss:0.011086132729435\n",
      "train loss:0.0013211957256705129\n",
      "train loss:0.0020530181700446023\n",
      "train loss:0.023691794796048247\n",
      "train loss:0.0008341040548695744\n",
      "train loss:0.0026884324515968907\n",
      "train loss:0.01241229733148199\n",
      "train loss:0.001486386156362243\n",
      "train loss:0.0034978616716981846\n",
      "train loss:0.009626284323897559\n",
      "train loss:0.0029233159137727217\n",
      "train loss:0.0018855180519910164\n",
      "train loss:0.002241487336676833\n",
      "train loss:0.0018834928688992152\n",
      "train loss:0.011678075061470013\n",
      "train loss:0.0031502762856058892\n",
      "train loss:0.0013227911642845747\n",
      "train loss:0.004384988598337873\n",
      "train loss:0.0024501419713320186\n",
      "train loss:0.02788209938579881\n",
      "train loss:0.0012102367027285372\n",
      "train loss:0.0017589711514746822\n",
      "train loss:0.00046732201240908114\n",
      "train loss:0.002487845043154768\n",
      "train loss:0.00501351379676876\n",
      "train loss:0.004012365115811788\n",
      "train loss:0.0006857458631769917\n",
      "train loss:0.0039990366818178314\n",
      "train loss:0.0003762439437168268\n",
      "train loss:0.005975798241062318\n",
      "train loss:0.0010497986931839879\n",
      "train loss:0.008225802643473114\n",
      "train loss:0.007925702246432034\n",
      "train loss:0.0017413961930469802\n",
      "train loss:0.000636200422475388\n",
      "train loss:0.0022084523218673384\n",
      "train loss:0.006585175242702987\n",
      "train loss:0.007596177361947478\n",
      "train loss:0.011463799289618269\n",
      "train loss:0.004159199020410576\n",
      "train loss:0.0030950863954295246\n",
      "train loss:0.007874702687052905\n",
      "train loss:0.0030373784282169496\n",
      "train loss:0.004499449157642056\n",
      "train loss:0.0010872607224362938\n",
      "train loss:0.008665064031839607\n",
      "train loss:0.013027432907838614\n",
      "train loss:0.0008807462598188377\n",
      "train loss:0.0012124307904183378\n",
      "train loss:0.005364721822882969\n",
      "train loss:0.0020574192431808166\n",
      "train loss:0.013017865113851492\n",
      "train loss:0.02699729864823436\n",
      "train loss:0.016562275092049085\n",
      "train loss:0.012595776154657545\n",
      "train loss:0.0009422509039358032\n",
      "train loss:0.0027468240523978583\n",
      "train loss:0.01716200985276614\n",
      "train loss:0.005453561311392973\n",
      "train loss:0.0020371224922604765\n",
      "train loss:0.009019312845521463\n",
      "train loss:0.0006980129038802702\n",
      "train loss:0.02257464360498492\n",
      "train loss:0.011013537236782625\n",
      "train loss:0.010493977811879805\n",
      "train loss:0.003791999509797972\n",
      "train loss:0.03476727281030454\n",
      "train loss:0.02504426084023561\n",
      "train loss:0.006853569599639777\n",
      "train loss:0.009842546762555318\n",
      "train loss:0.010262886554908833\n",
      "train loss:0.0031541678434711495\n",
      "train loss:0.0011035635257735936\n",
      "=== epoch:10, train acc:0.991, test acc:0.985 ===\n",
      "train loss:0.004107710026434098\n",
      "train loss:0.00840787398547318\n",
      "train loss:0.011723044944415688\n",
      "train loss:0.0019973722917295323\n",
      "train loss:0.0026509202465644114\n",
      "train loss:0.012374536154667135\n",
      "train loss:0.005271109575652057\n",
      "train loss:0.002532791494162096\n",
      "train loss:0.01261709932850245\n",
      "train loss:0.0005295994587983213\n",
      "train loss:0.005117082568313747\n",
      "train loss:0.0017613669700612747\n",
      "train loss:0.002912468224046374\n",
      "train loss:0.002494945346940585\n",
      "train loss:0.002625556801514539\n",
      "train loss:0.001632543914899805\n",
      "train loss:0.0020805843225294943\n",
      "train loss:0.013638449268569613\n",
      "train loss:0.005859301337155803\n",
      "train loss:0.02289104807552589\n",
      "train loss:0.007537833651057439\n",
      "train loss:0.0039040678716457376\n",
      "train loss:0.004553787313425452\n",
      "train loss:0.018255258923524836\n",
      "train loss:0.0053132593345622085\n",
      "train loss:0.009351108459238124\n",
      "train loss:0.008130657555732751\n",
      "train loss:0.0009225150639434768\n",
      "train loss:0.007768737371797141\n",
      "train loss:0.0032976565637447396\n",
      "train loss:0.007793989445542614\n",
      "train loss:0.01668316079600018\n",
      "train loss:0.02314695175937466\n",
      "train loss:0.028412175539339897\n",
      "train loss:0.005182740180772005\n",
      "train loss:0.011020686922745777\n",
      "train loss:0.002590336462590341\n",
      "train loss:0.002924179007583466\n",
      "train loss:0.014449528494614483\n",
      "train loss:0.0033872928420534665\n",
      "train loss:0.0018356906863854605\n",
      "train loss:0.012924063984955983\n",
      "train loss:0.005732844193300419\n",
      "train loss:0.05399323489464129\n",
      "train loss:0.005307616377046495\n",
      "train loss:0.010410615652294643\n",
      "train loss:0.0032237119198150165\n",
      "train loss:0.008108876182977225\n",
      "train loss:0.0683996327285821\n",
      "train loss:0.0057584243722576724\n",
      "train loss:0.003424156696191524\n",
      "train loss:0.007303423907764568\n",
      "train loss:0.010290863898843679\n",
      "train loss:0.01302059009131554\n",
      "train loss:0.011378237288477479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002926021777008333\n",
      "train loss:0.02255105386745836\n",
      "train loss:0.010031012450142296\n",
      "train loss:0.0014637133036176724\n",
      "train loss:0.0032908167514179632\n",
      "train loss:0.0036895195772955313\n",
      "train loss:0.0031279648496966707\n",
      "train loss:0.004230713104952634\n",
      "train loss:0.006019215795228166\n",
      "train loss:0.006010221102165935\n",
      "train loss:0.005194753143688685\n",
      "train loss:0.003212067657227345\n",
      "train loss:0.010580480533051757\n",
      "train loss:0.0023444551177998867\n",
      "train loss:0.0281216859162649\n",
      "train loss:0.012919205913918978\n",
      "train loss:0.0060914124860713195\n",
      "train loss:0.0037172150119658427\n",
      "train loss:0.00205945080459163\n",
      "train loss:0.000974463743937175\n",
      "train loss:0.0037166719040624525\n",
      "train loss:0.001143560965532354\n",
      "train loss:0.01004657645694219\n",
      "train loss:0.001481293185770609\n",
      "train loss:0.0018124320390635858\n",
      "train loss:0.006355965066266094\n",
      "train loss:0.004535351133678276\n",
      "train loss:0.002345328577743646\n",
      "train loss:0.0009499643331389526\n",
      "train loss:0.001468577107852773\n",
      "train loss:0.0027365296693654976\n",
      "train loss:0.004590827123080131\n",
      "train loss:0.060950920583284614\n",
      "train loss:0.003692916461824413\n",
      "train loss:0.002340757239756887\n",
      "train loss:0.030595879213157328\n",
      "train loss:0.0002305413386102831\n",
      "train loss:0.036069906042367685\n",
      "train loss:0.0033248991396454047\n",
      "train loss:0.007814603996500528\n",
      "train loss:0.013515896788736343\n",
      "train loss:0.0060643479820183845\n",
      "train loss:0.007643207396874408\n",
      "train loss:0.005670665958726273\n",
      "train loss:0.0035318194817516185\n",
      "train loss:0.0032484193313181333\n",
      "train loss:0.0032444393844245243\n",
      "train loss:0.003971198496083802\n",
      "train loss:0.04886733274446514\n",
      "train loss:0.03439740697330473\n",
      "train loss:0.0032697892404473412\n",
      "train loss:0.0034107806503821617\n",
      "train loss:0.006647804451541206\n",
      "train loss:0.0010822244328454495\n",
      "train loss:0.03329213600816403\n",
      "train loss:0.0028245650280660003\n",
      "train loss:0.0015989295916139297\n",
      "train loss:0.00698070826066174\n",
      "train loss:0.002687875922351644\n",
      "train loss:0.008062987614663399\n",
      "train loss:0.019194805371501727\n",
      "train loss:0.007846347650101634\n",
      "train loss:0.031829810594612526\n",
      "train loss:0.011768923658706559\n",
      "train loss:0.004307238190749851\n",
      "train loss:0.002138928352149688\n",
      "train loss:0.004816701442784586\n",
      "train loss:0.010950640744431852\n",
      "train loss:0.005185352280752149\n",
      "train loss:0.004206890508869199\n",
      "train loss:0.005414423122430552\n",
      "train loss:0.020126172862996675\n",
      "train loss:0.003329804223625654\n",
      "train loss:0.003066004675005186\n",
      "train loss:0.013811405822811509\n",
      "train loss:0.00115467220172377\n",
      "train loss:0.0007676899637730704\n",
      "train loss:0.012451838343503399\n",
      "train loss:0.0033142046285987853\n",
      "train loss:0.00044229930205645586\n",
      "train loss:0.0031886218959621708\n",
      "train loss:0.004475814493769596\n",
      "train loss:0.00678412926666553\n",
      "train loss:0.015807887094505427\n",
      "train loss:0.006552244064356139\n",
      "train loss:0.000980820762322782\n",
      "train loss:0.025823390033908832\n",
      "train loss:0.002423275280776351\n",
      "train loss:0.011927664770275442\n",
      "train loss:0.010627247293913917\n",
      "train loss:0.0024080709362722173\n",
      "train loss:0.002031982179318821\n",
      "train loss:0.007280635287333114\n",
      "train loss:0.015249637530742363\n",
      "train loss:0.006192606837222658\n",
      "train loss:0.0023378675513548307\n",
      "train loss:0.004376331913621346\n",
      "train loss:0.04980020613167237\n",
      "train loss:0.014397194244208178\n",
      "train loss:0.006625425299383675\n",
      "train loss:0.0024529943104678728\n",
      "train loss:0.0013192686446015657\n",
      "train loss:0.007082393353407733\n",
      "train loss:0.005606538858693281\n",
      "train loss:0.001248604726889504\n",
      "train loss:0.0020172218570524408\n",
      "train loss:0.0020953584629748497\n",
      "train loss:0.0022797439542405823\n",
      "train loss:0.005974823458448147\n",
      "train loss:0.006466324502798505\n",
      "train loss:0.0019242037836318371\n",
      "train loss:0.00809245429121482\n",
      "train loss:0.008416374845563375\n",
      "train loss:0.03193576351833545\n",
      "train loss:0.016656885427487274\n",
      "train loss:0.003805515256051759\n",
      "train loss:0.0030588817611471963\n",
      "train loss:0.003554035776062529\n",
      "train loss:0.012866601684357843\n",
      "train loss:0.001826009388290052\n",
      "train loss:0.0026765441309751516\n",
      "train loss:0.003009838350993023\n",
      "train loss:0.00787243537508995\n",
      "train loss:0.0033466202033948476\n",
      "train loss:0.004750248608652313\n",
      "train loss:0.007305591174257765\n",
      "train loss:0.023427223817921318\n",
      "train loss:0.011107639651181271\n",
      "train loss:0.009794074671500596\n",
      "train loss:0.02820582144701929\n",
      "train loss:0.011940569255146478\n",
      "train loss:0.0007280488153484094\n",
      "train loss:0.023136903744376998\n",
      "train loss:0.007740700409736481\n",
      "train loss:0.009139581789473144\n",
      "train loss:0.0012086531508876145\n",
      "train loss:0.012159286256390518\n",
      "train loss:0.010137062621311137\n",
      "train loss:0.0028171970131175717\n",
      "train loss:0.00871233532996031\n",
      "train loss:0.001764688096772025\n",
      "train loss:0.0046551810495744994\n",
      "train loss:0.002070465842061833\n",
      "train loss:0.002565245909406912\n",
      "train loss:0.004144406663019485\n",
      "train loss:0.003826958888913158\n",
      "train loss:0.03966666422646553\n",
      "train loss:0.028341329682171817\n",
      "train loss:0.0010432369592500545\n",
      "train loss:0.004715843146598685\n",
      "train loss:0.026835009814044363\n",
      "train loss:0.005876731375194656\n",
      "train loss:0.0008419457486125131\n",
      "train loss:0.04604119813208118\n",
      "train loss:0.030851217380536658\n",
      "train loss:0.005296812098827617\n",
      "train loss:0.014302660571700179\n",
      "train loss:0.002343394386119901\n",
      "train loss:0.0009376562627149956\n",
      "train loss:0.002649953903143055\n",
      "train loss:0.002859661955939793\n",
      "train loss:0.006805187849534988\n",
      "train loss:0.003915056259742525\n",
      "train loss:0.007279127402703064\n",
      "train loss:0.003398583095192151\n",
      "train loss:0.022966756824483778\n",
      "train loss:0.0010268402374985393\n",
      "train loss:0.002205762730681914\n",
      "train loss:0.008721137373373296\n",
      "train loss:0.023938079302222262\n",
      "train loss:0.012669935361652538\n",
      "train loss:0.0033367351403446235\n",
      "train loss:0.004539983535974295\n",
      "train loss:0.0010695885015060947\n",
      "train loss:0.0007076016788438674\n",
      "train loss:0.003590754563612714\n",
      "train loss:0.0304174660327026\n",
      "train loss:0.003328971499855965\n",
      "train loss:0.0014249079491320973\n",
      "train loss:0.00931664276946248\n",
      "train loss:0.03315073201029188\n",
      "train loss:0.01708334263386822\n",
      "train loss:0.0002564378453476223\n",
      "train loss:0.005988367703680324\n",
      "train loss:0.005039046304079123\n",
      "train loss:0.00035375457953583156\n",
      "train loss:0.010333081464088187\n",
      "train loss:0.003819846331142125\n",
      "train loss:0.003357308926072147\n",
      "train loss:0.004682299845462827\n",
      "train loss:0.000869002140470033\n",
      "train loss:0.009793974894884656\n",
      "train loss:0.007275853106718308\n",
      "train loss:0.009966465141093096\n",
      "train loss:0.00429853678953561\n",
      "train loss:0.0009583507180361416\n",
      "train loss:0.0053208361012949965\n",
      "train loss:0.005891997309124691\n",
      "train loss:0.008040922787290324\n",
      "train loss:0.0028253469883024796\n",
      "train loss:0.012227798699613704\n",
      "train loss:0.0036896071393896163\n",
      "train loss:0.0012429325721520171\n",
      "train loss:0.0038241204463746875\n",
      "train loss:0.0030337353663142386\n",
      "train loss:0.0014904100359322862\n",
      "train loss:0.0011573057334313753\n",
      "train loss:0.0033079250057763505\n",
      "train loss:0.005524256213390544\n",
      "train loss:0.0013008763067873467\n",
      "train loss:0.005731125932754492\n",
      "train loss:0.0017744932769075269\n",
      "train loss:0.0026560173112803774\n",
      "train loss:0.001834826683424089\n",
      "train loss:0.003051401970014913\n",
      "train loss:0.004590437367482795\n",
      "train loss:0.027000471838205437\n",
      "train loss:0.009474621070086071\n",
      "train loss:0.0038479481916176813\n",
      "train loss:0.0013557998322369198\n",
      "train loss:0.003025857635308572\n",
      "train loss:0.00957233403915814\n",
      "train loss:0.016965991896218332\n",
      "train loss:0.02253392965593235\n",
      "train loss:0.0007996959563508989\n",
      "train loss:0.0012172572758142282\n",
      "train loss:0.005837738457972007\n",
      "train loss:0.0008443476476302846\n",
      "train loss:0.001435722788405246\n",
      "train loss:0.0012398707330965961\n",
      "train loss:0.01509952039705145\n",
      "train loss:0.008274482438316006\n",
      "train loss:0.0017058354761574019\n",
      "train loss:0.0052440362162808115\n",
      "train loss:0.0013892019353149332\n",
      "train loss:0.0006487956925923031\n",
      "train loss:0.0021162604807370513\n",
      "train loss:0.023815540619818547\n",
      "train loss:0.0288904118983729\n",
      "train loss:0.005581552079895061\n",
      "train loss:0.0034168157447631146\n",
      "train loss:0.006127861893225699\n",
      "train loss:0.02159521937942355\n",
      "train loss:0.001355829663249898\n",
      "train loss:0.0010532808724916106\n",
      "train loss:0.01588797418102591\n",
      "train loss:0.01471461847773894\n",
      "train loss:0.0016500506852143296\n",
      "train loss:0.002058652688363666\n",
      "train loss:0.017218770218992638\n",
      "train loss:0.00636622491308084\n",
      "train loss:0.005983989302171828\n",
      "train loss:0.013913908452639236\n",
      "train loss:0.0020687628986818703\n",
      "train loss:0.0008939798696080899\n",
      "train loss:0.002785968268085494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002955684677906404\n",
      "train loss:0.0035570890548127605\n",
      "train loss:0.0008889110584304084\n",
      "train loss:0.0017985958950172945\n",
      "train loss:0.004476468108144752\n",
      "train loss:0.008059821887458463\n",
      "train loss:0.012249847663934775\n",
      "train loss:0.0010799073672725736\n",
      "train loss:0.001481279823319995\n",
      "train loss:0.004365246365298953\n",
      "train loss:0.03453068957334052\n",
      "train loss:0.013250445478874183\n",
      "train loss:0.1672455829426353\n",
      "train loss:0.0037256885042667547\n",
      "train loss:0.003387214879701321\n",
      "train loss:0.0010270859882618838\n",
      "train loss:0.011043945404991241\n",
      "train loss:0.00496917798823978\n",
      "train loss:0.005366976979929771\n",
      "train loss:0.0011176555189022193\n",
      "train loss:0.00040731578944694006\n",
      "train loss:0.0064437739563080985\n",
      "train loss:0.0020369470705794233\n",
      "train loss:0.011417265487334172\n",
      "train loss:0.00374237628797495\n",
      "train loss:0.0050151501950970725\n",
      "train loss:0.011006945315376541\n",
      "train loss:0.008610060152918908\n",
      "train loss:0.001868780534093617\n",
      "train loss:0.00673751817469379\n",
      "train loss:0.010778402916580675\n",
      "train loss:0.012006632126269057\n",
      "train loss:0.03620265800907149\n",
      "train loss:0.02874702277777273\n",
      "train loss:0.005649154870361345\n",
      "train loss:0.015288661132108264\n",
      "train loss:0.01229387984900892\n",
      "train loss:0.01240085250635506\n",
      "train loss:0.01273729862355099\n",
      "train loss:0.0036944058391049574\n",
      "train loss:0.00663525816243531\n",
      "train loss:0.003444641438486172\n",
      "train loss:0.0006185968693941534\n",
      "train loss:0.005223733646861474\n",
      "train loss:0.0016129490948388042\n",
      "train loss:0.002609759439408631\n",
      "train loss:0.004903840967379105\n",
      "train loss:0.02612407539131061\n",
      "train loss:0.028098073703368684\n",
      "train loss:0.010761234915143332\n",
      "train loss:0.000576897532738517\n",
      "train loss:0.00821664851728464\n",
      "train loss:0.005442740736274269\n",
      "train loss:0.0028988274239427243\n",
      "train loss:0.011017923016100915\n",
      "train loss:0.0030519496167809535\n",
      "train loss:0.007576293037925717\n",
      "train loss:0.006045911965335052\n",
      "train loss:0.0030609138222614522\n",
      "train loss:0.0032697864483587375\n",
      "train loss:0.0014339513580901618\n",
      "train loss:0.001448088592441438\n",
      "train loss:0.01557690051777737\n",
      "train loss:0.0011239580044465388\n",
      "train loss:0.005106392636782387\n",
      "train loss:0.0025395809166925947\n",
      "train loss:0.005563518996121888\n",
      "train loss:0.0071792961981138655\n",
      "train loss:0.004096429390525741\n",
      "train loss:0.014966362247066194\n",
      "train loss:0.020450478470358798\n",
      "train loss:0.0037606810951504284\n",
      "train loss:0.0017522908111204168\n",
      "train loss:0.004190808816280816\n",
      "train loss:0.0019496538832911594\n",
      "train loss:0.01151939151048867\n",
      "train loss:0.0029067535247776525\n",
      "train loss:0.0070593766964314785\n",
      "train loss:0.0007015341321725385\n",
      "train loss:0.009572362307887224\n",
      "train loss:0.007560558381341727\n",
      "train loss:0.0008429367365106326\n",
      "train loss:0.00431501974462195\n",
      "train loss:0.0036416522438142197\n",
      "train loss:0.002140730310570606\n",
      "train loss:0.006908022847982379\n",
      "train loss:0.002606003667279996\n",
      "train loss:0.0010688543256485014\n",
      "train loss:0.0045240251062866575\n",
      "train loss:0.0014045612543228776\n",
      "train loss:0.008254971521831385\n",
      "train loss:0.00022619572933746623\n",
      "train loss:0.005836415419044877\n",
      "train loss:0.00865934700238538\n",
      "train loss:0.0003241883038164184\n",
      "train loss:0.0033960688918841125\n",
      "train loss:0.0007051859394251968\n",
      "train loss:0.012557144186041688\n",
      "train loss:0.01786420635407026\n",
      "train loss:0.014141618670057636\n",
      "train loss:0.0043814850989961\n",
      "train loss:0.005899423560750996\n",
      "train loss:0.0014572652644097251\n",
      "train loss:0.001064001697644173\n",
      "train loss:0.028464604878800367\n",
      "train loss:0.0024484188422521144\n",
      "train loss:0.0029869884653936883\n",
      "train loss:0.0023673550799569163\n",
      "train loss:0.03586599415773875\n",
      "train loss:0.009494127318918645\n",
      "train loss:0.024738125792113354\n",
      "train loss:0.004736140144172206\n",
      "train loss:0.0037857011141393198\n",
      "train loss:0.0029846080697649197\n",
      "train loss:0.001954820707035337\n",
      "train loss:0.0022595482671622542\n",
      "train loss:0.0022348183694481023\n",
      "train loss:0.0006957988445285875\n",
      "train loss:0.0027503151591040994\n",
      "train loss:0.002782751533953338\n",
      "train loss:0.00409770442695263\n",
      "train loss:0.003461907916786716\n",
      "train loss:0.0010054648792829578\n",
      "train loss:0.0007560487343164936\n",
      "train loss:0.0010774156424982724\n",
      "train loss:0.013903840668557205\n",
      "train loss:0.0080716093271629\n",
      "train loss:0.0019254058491605522\n",
      "train loss:0.006768722726841142\n",
      "train loss:0.001962838547559057\n",
      "train loss:0.00584639758991894\n",
      "train loss:0.004438228962522747\n",
      "train loss:0.018801834612154934\n",
      "train loss:0.001196663998473587\n",
      "train loss:0.006883183996310505\n",
      "train loss:0.01798844668337194\n",
      "train loss:0.0005691706692093862\n",
      "train loss:0.0030734754276077036\n",
      "train loss:0.00564494212726815\n",
      "train loss:0.014069868240712973\n",
      "train loss:0.002181574213190267\n",
      "train loss:0.008481456425481726\n",
      "train loss:0.006508039974351685\n",
      "train loss:0.0013407130513056456\n",
      "train loss:0.004708476060093329\n",
      "train loss:0.005705805857425567\n",
      "train loss:0.0005811775748071698\n",
      "train loss:0.0005713000836793979\n",
      "train loss:0.009229702546135818\n",
      "train loss:0.004318935170077718\n",
      "train loss:0.0016718712116559125\n",
      "train loss:0.0019484115260672134\n",
      "train loss:0.003817605971090713\n",
      "train loss:0.0049839362947873165\n",
      "train loss:0.007102361962683828\n",
      "train loss:0.0020035508899784336\n",
      "train loss:0.009673792414751504\n",
      "train loss:0.007381191576867746\n",
      "train loss:0.009731004719854532\n",
      "train loss:0.004094984193745073\n",
      "train loss:0.00517684200569254\n",
      "train loss:0.0012698122131212686\n",
      "train loss:0.0009045377111606426\n",
      "train loss:0.00450779051742126\n",
      "train loss:0.009908507827495965\n",
      "train loss:0.0011657462902892799\n",
      "train loss:0.006028071049494646\n",
      "train loss:0.01505492118582437\n",
      "train loss:0.005601756711605876\n",
      "train loss:0.008066506206498233\n",
      "train loss:0.0029683762626792824\n",
      "train loss:0.002078576716907895\n",
      "train loss:0.0004179127268713402\n",
      "train loss:0.00173373500412434\n",
      "train loss:0.007375039288507743\n",
      "train loss:0.010081830146873173\n",
      "train loss:0.0015430735397608062\n",
      "train loss:0.00555367874152902\n",
      "train loss:0.0029433901336673087\n",
      "train loss:0.0017866041516469908\n",
      "train loss:0.007890409853414024\n",
      "train loss:0.0010766217901891652\n",
      "train loss:0.009148054481244582\n",
      "train loss:0.005174112449377634\n",
      "train loss:0.0042038501834433415\n",
      "train loss:0.0023638000889915373\n",
      "train loss:0.008250327923322363\n",
      "train loss:0.005595523491061767\n",
      "train loss:0.004952851444355092\n",
      "train loss:0.0007845981857736689\n",
      "train loss:0.004066028012542449\n",
      "train loss:0.0014745249646541925\n",
      "train loss:0.0388485421257213\n",
      "train loss:0.0003339450686481751\n",
      "train loss:0.0012884520001197252\n",
      "train loss:0.031747159174029344\n",
      "train loss:0.0035309469087835455\n",
      "train loss:0.004704674449410397\n",
      "train loss:0.020499556515249963\n",
      "train loss:0.0073869938731620875\n",
      "train loss:0.0032762981313455924\n",
      "train loss:0.0022569400813319176\n",
      "train loss:0.005061587471101371\n",
      "train loss:0.006666264504434285\n",
      "train loss:0.0006732871738866245\n",
      "train loss:0.0014770350777059782\n",
      "train loss:0.00025439357062649186\n",
      "train loss:0.005726472746333315\n",
      "train loss:0.002427543944634187\n",
      "train loss:0.0014463801107450663\n",
      "train loss:0.008102419533620942\n",
      "train loss:0.003074959173938092\n",
      "train loss:0.021239817672672256\n",
      "train loss:0.0036684061010303338\n",
      "train loss:0.010903565981644032\n",
      "train loss:0.006973947497333936\n",
      "train loss:0.00849841107966758\n",
      "train loss:0.0015206953206831314\n",
      "train loss:0.004478959720237118\n",
      "train loss:0.0027709616652752942\n",
      "train loss:0.003702841177401858\n",
      "train loss:0.0026752939804390325\n",
      "train loss:0.01460641959446213\n",
      "train loss:0.00332859043550024\n",
      "train loss:0.0015814684321668931\n",
      "train loss:0.005889371425155908\n",
      "train loss:0.011056457112858395\n",
      "train loss:0.001263319321589828\n",
      "train loss:0.01032034101001723\n",
      "train loss:0.0007668268500972465\n",
      "train loss:0.0022344576722572508\n",
      "train loss:0.005299222610486557\n",
      "train loss:0.009417512618698099\n",
      "train loss:0.0014094121391071074\n",
      "train loss:0.0010028015426580244\n",
      "train loss:0.0004488036263433677\n",
      "train loss:0.012573908538759037\n",
      "train loss:0.007326788843733079\n",
      "train loss:0.005397162822397367\n",
      "train loss:0.006099860136304344\n",
      "train loss:0.004600193975055929\n",
      "train loss:0.0068295035018483075\n",
      "train loss:0.002295934742343458\n",
      "train loss:0.004186217724366111\n",
      "train loss:0.001882657997262873\n",
      "train loss:0.005431668003513349\n",
      "train loss:0.005572064429614388\n",
      "train loss:0.004406454717740208\n",
      "train loss:0.017523731779569424\n",
      "train loss:0.006164950610778807\n",
      "train loss:0.002231720613090484\n",
      "train loss:0.0048969510217752935\n",
      "train loss:0.0029828526348547675\n",
      "train loss:0.00186880435687471\n",
      "train loss:0.004569863358268142\n",
      "train loss:0.002578069190911295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009268512240675346\n",
      "train loss:0.001545450326609789\n",
      "train loss:0.0036930097778170644\n",
      "train loss:0.001734707613626474\n",
      "train loss:0.0054121406394027705\n",
      "train loss:0.002467187502237605\n",
      "train loss:0.0005796494057354379\n",
      "train loss:0.007573788124978592\n",
      "train loss:0.01867108966688056\n",
      "train loss:0.003216405866170726\n",
      "train loss:0.009328269887521078\n",
      "train loss:0.0041152573795880465\n",
      "train loss:0.004081694245451877\n",
      "train loss:0.005295417394526377\n",
      "train loss:0.009442319381692047\n",
      "train loss:0.0031111043003854573\n",
      "train loss:0.0013101566594679217\n",
      "train loss:0.005198075711168126\n",
      "train loss:0.006198662547122752\n",
      "train loss:0.030802774793489328\n",
      "train loss:0.003032494648014391\n",
      "train loss:0.0002685896479722288\n",
      "train loss:0.0008405958288267515\n",
      "train loss:0.009192488903450842\n",
      "train loss:0.004253757709868431\n",
      "train loss:0.001356127735648259\n",
      "train loss:0.008586205988945203\n",
      "train loss:0.054064191635438685\n",
      "train loss:0.009987710123817094\n",
      "train loss:0.0021549999921131563\n",
      "train loss:0.0014124996991082494\n",
      "train loss:0.0037404124106198704\n",
      "train loss:0.005030684797540423\n",
      "=== epoch:11, train acc:0.997, test acc:0.989 ===\n",
      "train loss:0.00450339004464247\n",
      "train loss:0.004766116284612679\n",
      "train loss:0.008562296155458627\n",
      "train loss:0.016524297376309262\n",
      "train loss:0.004227930722729894\n",
      "train loss:0.0031848711680004292\n",
      "train loss:0.022192297100448496\n",
      "train loss:0.004327062538901428\n",
      "train loss:0.001008655391300576\n",
      "train loss:0.0015190366786582599\n",
      "train loss:0.0037051960710866956\n",
      "train loss:0.004909459382551905\n",
      "train loss:0.01092083296985381\n",
      "train loss:0.0005423205641796736\n",
      "train loss:0.0029448073133431485\n",
      "train loss:0.0011876793957803298\n",
      "train loss:0.0013524591679552203\n",
      "train loss:0.0076836234351348905\n",
      "train loss:0.0010323721351606584\n",
      "train loss:0.004838579858393179\n",
      "train loss:0.004100797924948132\n",
      "train loss:0.00717535817635835\n",
      "train loss:0.0026993218279858988\n",
      "train loss:0.0025388311006256403\n",
      "train loss:0.007190745463208656\n",
      "train loss:0.007502469424787836\n",
      "train loss:0.0062681387218005155\n",
      "train loss:0.019540938589138274\n",
      "train loss:0.0032264870316448236\n",
      "train loss:0.0004544197733367189\n",
      "train loss:0.0006775948621646593\n",
      "train loss:0.00458037569431425\n",
      "train loss:0.0032653567141513206\n",
      "train loss:0.004626677732206229\n",
      "train loss:0.0020398438159333725\n",
      "train loss:0.0023696990835857966\n",
      "train loss:0.002163658883106636\n",
      "train loss:0.0008389004498047719\n",
      "train loss:0.0035606721729686346\n",
      "train loss:0.004026846755455057\n",
      "train loss:0.0009862269870044348\n",
      "train loss:0.005203634363826104\n",
      "train loss:0.0008129199907490177\n",
      "train loss:0.007504704553990679\n",
      "train loss:0.005023028252208002\n",
      "train loss:0.010886140251899023\n",
      "train loss:0.010457189096332992\n",
      "train loss:0.006261600335643424\n",
      "train loss:0.004458126660081167\n",
      "train loss:0.012673038411919087\n",
      "train loss:0.005353979714510385\n",
      "train loss:0.0029663200558914878\n",
      "train loss:0.007233772576849653\n",
      "train loss:0.0017667181052472233\n",
      "train loss:0.0020721553808700144\n",
      "train loss:0.003837287228008372\n",
      "train loss:0.0031178330432297748\n",
      "train loss:0.007738892962628083\n",
      "train loss:0.001037315504030177\n",
      "train loss:0.008988428272959908\n",
      "train loss:0.0025831866282893436\n",
      "train loss:0.0031106562992352475\n",
      "train loss:0.005655091489040025\n",
      "train loss:0.0005128478759074445\n",
      "train loss:0.028531625471802803\n",
      "train loss:0.0016582893239618683\n",
      "train loss:0.0017032669549051265\n",
      "train loss:0.002110749181345799\n",
      "train loss:0.0035639493901992413\n",
      "train loss:0.003102732735332236\n",
      "train loss:0.0007571489325589102\n",
      "train loss:0.0054375677443811036\n",
      "train loss:0.005600192678379906\n",
      "train loss:0.09596584084065726\n",
      "train loss:0.0024488272123710177\n",
      "train loss:0.0010854123028571092\n",
      "train loss:0.013841549324485836\n",
      "train loss:0.003914116715442352\n",
      "train loss:0.0009950115800184808\n",
      "train loss:0.0021327557657389324\n",
      "train loss:0.010380445052650207\n",
      "train loss:0.0019326935577182272\n",
      "train loss:0.002936970657994728\n",
      "train loss:0.0026199186306159914\n",
      "train loss:0.0023515231723262604\n",
      "train loss:0.10975013238231147\n",
      "train loss:0.004744661808611975\n",
      "train loss:0.003778722288363324\n",
      "train loss:0.0013319324719531201\n",
      "train loss:0.006439185105579547\n",
      "train loss:0.00042622339717873255\n",
      "train loss:0.010607157663992776\n",
      "train loss:0.005656736569621513\n",
      "train loss:0.0038145218354663476\n",
      "train loss:0.005824895402382215\n",
      "train loss:0.016702442351365837\n",
      "train loss:0.005461928428623226\n",
      "train loss:0.0013778319186054239\n",
      "train loss:0.004689825658712122\n",
      "train loss:0.004699416961330665\n",
      "train loss:0.0002497787605489221\n",
      "train loss:0.005212783753575221\n",
      "train loss:0.006104571216972348\n",
      "train loss:0.0037525418059881593\n",
      "train loss:0.0063809752792219655\n",
      "train loss:0.0004490629359472503\n",
      "train loss:0.0023800149226878946\n",
      "train loss:0.0005992291880175531\n",
      "train loss:0.0023831342108043777\n",
      "train loss:0.001134644093441948\n",
      "train loss:0.0019063237044527393\n",
      "train loss:0.0034978534148170076\n",
      "train loss:0.0028593248380874435\n",
      "train loss:0.014418678735216527\n",
      "train loss:0.016725398458621876\n",
      "train loss:0.003704076349796106\n",
      "train loss:0.005044177917060727\n",
      "train loss:0.010575599243243868\n",
      "train loss:0.0029074887345145765\n",
      "train loss:0.001275515371431849\n",
      "train loss:0.0006079232315870748\n",
      "train loss:0.0013175286570275922\n",
      "train loss:0.004829100593795151\n",
      "train loss:0.003936585510557065\n",
      "train loss:0.00032832393557366763\n",
      "train loss:0.004483915973483434\n",
      "train loss:0.0004586694279442508\n",
      "train loss:0.0017343585349423644\n",
      "train loss:0.001954926699127087\n",
      "train loss:0.013203051884414922\n",
      "train loss:0.015544445012714545\n",
      "train loss:0.0048795619483778035\n",
      "train loss:0.0005284235163135382\n",
      "train loss:0.0018951586611977472\n",
      "train loss:0.00924834927505735\n",
      "train loss:0.009607702694165166\n",
      "train loss:0.039958430108826964\n",
      "train loss:0.012614039211054275\n",
      "train loss:0.004019887682260705\n",
      "train loss:0.008712467214607875\n",
      "train loss:0.002038828802122425\n",
      "train loss:0.004860199040221757\n",
      "train loss:0.0015360140741214345\n",
      "train loss:0.009506416618724358\n",
      "train loss:0.0037316902727904705\n",
      "train loss:0.008247803263571316\n",
      "train loss:0.0005434980693153305\n",
      "train loss:0.008738329618019213\n",
      "train loss:0.01131932135081629\n",
      "train loss:0.01901341874489018\n",
      "train loss:0.0035828653671810297\n",
      "train loss:0.0004265694581615693\n",
      "train loss:0.00864335660947005\n",
      "train loss:0.017944563183724317\n",
      "train loss:0.0037926403314557495\n",
      "train loss:0.00021230917219429709\n",
      "train loss:0.0021425685927500895\n",
      "train loss:0.0004486009218366576\n",
      "train loss:0.00268002114830332\n",
      "train loss:0.008544715247674048\n",
      "train loss:0.011566871150235249\n",
      "train loss:0.0018118982246687872\n",
      "train loss:0.048910029283582436\n",
      "train loss:0.07631006635079746\n",
      "train loss:0.003862792395117245\n",
      "train loss:0.0031732172864443304\n",
      "train loss:0.002478815102851798\n",
      "train loss:0.0018149127943315202\n",
      "train loss:0.007858070393882461\n",
      "train loss:0.0022401427398804773\n",
      "train loss:0.008155961140730115\n",
      "train loss:0.008365193308521202\n",
      "train loss:0.0028201847980297403\n",
      "train loss:0.0012060003284644397\n",
      "train loss:0.004106533662466338\n",
      "train loss:0.0033995832018913525\n",
      "train loss:0.01083598093515097\n",
      "train loss:0.017760604569914688\n",
      "train loss:0.0007378053427885601\n",
      "train loss:0.006082115433289133\n",
      "train loss:0.0007331773089245808\n",
      "train loss:0.01518500725358899\n",
      "train loss:0.002724131558269865\n",
      "train loss:0.03211000618076995\n",
      "train loss:0.007282972075767367\n",
      "train loss:0.0027866923283348\n",
      "train loss:0.005950386993316751\n",
      "train loss:0.03364430842651882\n",
      "train loss:0.003960014631963336\n",
      "train loss:0.0023351821741304617\n",
      "train loss:0.03384941274941256\n",
      "train loss:0.005111797157128542\n",
      "train loss:0.008713688086720926\n",
      "train loss:0.0022015238838295815\n",
      "train loss:0.0053648034187276095\n",
      "train loss:0.0023387365863893287\n",
      "train loss:0.001802579571506791\n",
      "train loss:0.0018134688527020944\n",
      "train loss:0.003270049975436318\n",
      "train loss:0.0018431739446917702\n",
      "train loss:0.004956776284263679\n",
      "train loss:0.0050761594059020206\n",
      "train loss:0.005374260124381956\n",
      "train loss:0.0009487569177390838\n",
      "train loss:0.0025853041171315073\n",
      "train loss:0.0005497428392472882\n",
      "train loss:0.0027971714804025296\n",
      "train loss:0.004919120101221161\n",
      "train loss:0.0016778297543044655\n",
      "train loss:0.003477552898438781\n",
      "train loss:0.0029680392271346496\n",
      "train loss:0.001977289186139075\n",
      "train loss:0.00028308926492166955\n",
      "train loss:0.01220015433384115\n",
      "train loss:0.008620510860571697\n",
      "train loss:0.0016032051430903277\n",
      "train loss:0.0018162533863335412\n",
      "train loss:0.0056774245581983586\n",
      "train loss:0.003924043475091105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0023988343096588275\n",
      "train loss:0.0020991300780143643\n",
      "train loss:0.002429799300369338\n",
      "train loss:0.00018357023303709999\n",
      "train loss:0.0035640565905000533\n",
      "train loss:0.002868777844914844\n",
      "train loss:0.004437968347033778\n",
      "train loss:0.0025424065221444437\n",
      "train loss:0.012915907397007497\n",
      "train loss:0.0013848992537907263\n",
      "train loss:0.0004513198029413433\n",
      "train loss:0.04789844155613784\n",
      "train loss:0.002980410894701472\n",
      "train loss:0.0021521063093399634\n",
      "train loss:0.0029492796404153405\n",
      "train loss:0.0008374163624295968\n",
      "train loss:0.0018203560739868162\n",
      "train loss:0.0029941845080443045\n",
      "train loss:0.02577973485540601\n",
      "train loss:0.027740942627338366\n",
      "train loss:0.030317880513728423\n",
      "train loss:0.0006521596040121884\n",
      "train loss:0.0028792471042095895\n",
      "train loss:0.003427190128378875\n",
      "train loss:0.010059923975098544\n",
      "train loss:0.010270507603543618\n",
      "train loss:0.0018175542342532241\n",
      "train loss:0.0041885163407294175\n",
      "train loss:0.0033129444575428885\n",
      "train loss:0.0007442494016243653\n",
      "train loss:0.0002341481172341341\n",
      "train loss:0.00938492247406118\n",
      "train loss:0.008670254674715449\n",
      "train loss:0.0033547891508954953\n",
      "train loss:0.0008690610269950747\n",
      "train loss:0.0009040416420492722\n",
      "train loss:0.013218061526648553\n",
      "train loss:0.0034135766014106476\n",
      "train loss:0.00888900219155227\n",
      "train loss:0.0015663749181577087\n",
      "train loss:0.004701180077052142\n",
      "train loss:0.00046077979681953443\n",
      "train loss:0.004527774491639312\n",
      "train loss:0.009942666593536008\n",
      "train loss:0.003278366510586183\n",
      "train loss:0.0035679973159244817\n",
      "train loss:0.004983500964112388\n",
      "train loss:0.0022785529832927993\n",
      "train loss:0.003770260551577817\n",
      "train loss:0.004895014495679978\n",
      "train loss:0.0016053203084186855\n",
      "train loss:0.008630954426792127\n",
      "train loss:0.003670120597865956\n",
      "train loss:0.013936809711120213\n",
      "train loss:0.0026847526574201083\n",
      "train loss:0.006279799948632576\n",
      "train loss:0.004441518456296129\n",
      "train loss:0.008772385560391848\n",
      "train loss:0.008480201341034922\n",
      "train loss:0.00074449154155623\n",
      "train loss:0.0036612608511261396\n",
      "train loss:0.005455147188856567\n",
      "train loss:0.002727337005548256\n",
      "train loss:0.0006589127731496925\n",
      "train loss:0.003799261080592095\n",
      "train loss:0.0028565610857276807\n",
      "train loss:0.0020918936048794938\n",
      "train loss:0.0010792363733451756\n",
      "train loss:0.0010035621633018965\n",
      "train loss:0.0009550383837777042\n",
      "train loss:0.005838934099337175\n",
      "train loss:0.010243559624654423\n",
      "train loss:0.004148129985899873\n",
      "train loss:0.0006068331506580585\n",
      "train loss:0.003729358171912792\n",
      "train loss:0.00032846641347547735\n",
      "train loss:0.016539089947072448\n",
      "train loss:0.0018244852968683507\n",
      "train loss:0.0006036100275431613\n",
      "train loss:0.0014602591983600205\n",
      "train loss:0.0019179589470362623\n",
      "train loss:0.0006949806710004676\n",
      "train loss:0.005033625775084325\n",
      "train loss:0.004703255033685755\n",
      "train loss:0.01397558233527413\n",
      "train loss:0.0021409218970477035\n",
      "train loss:0.0038656456367685654\n",
      "train loss:0.005471865772593735\n",
      "train loss:0.0031204835010596264\n",
      "train loss:0.005457284525131771\n",
      "train loss:0.003912640368886326\n",
      "train loss:0.0006248719649702209\n",
      "train loss:0.0034278217928249283\n",
      "train loss:0.001208320538436553\n",
      "train loss:0.0025847359980127314\n",
      "train loss:0.0012531549691852247\n",
      "train loss:0.0022749116020097664\n",
      "train loss:0.02658606117990037\n",
      "train loss:0.0023375131618989806\n",
      "train loss:0.0019958768461818656\n",
      "train loss:0.0009059137399260762\n",
      "train loss:0.002995637694376863\n",
      "train loss:0.0028943537688187766\n",
      "train loss:0.0014610125586970528\n",
      "train loss:0.007939739914313178\n",
      "train loss:0.002609195821761785\n",
      "train loss:0.0030045675888354232\n",
      "train loss:0.02498825262311003\n",
      "train loss:0.0010543485291651012\n",
      "train loss:0.006558870462049398\n",
      "train loss:0.0005614697873435948\n",
      "train loss:0.004807506297321942\n",
      "train loss:0.0005089858238443477\n",
      "train loss:0.0038664477781603945\n",
      "train loss:0.000756524477191438\n",
      "train loss:0.005867984362719447\n",
      "train loss:0.001701519993048769\n",
      "train loss:0.0013242144568005303\n",
      "train loss:0.001040781282980273\n",
      "train loss:0.0022404010076676685\n",
      "train loss:0.017561013598734194\n",
      "train loss:0.00027479855948981486\n",
      "train loss:0.011594387420035913\n",
      "train loss:0.0028131318734303428\n",
      "train loss:0.0017799165209837885\n",
      "train loss:0.0016860973178109329\n",
      "train loss:0.0045827346101900675\n",
      "train loss:0.0009779652541427556\n",
      "train loss:0.004499509726693317\n",
      "train loss:0.001002127207975019\n",
      "train loss:0.002151896720619637\n",
      "train loss:0.0015111374108640419\n",
      "train loss:0.0041944271443605605\n",
      "train loss:0.0008562836361935198\n",
      "train loss:0.006767437275606689\n",
      "train loss:0.022181793533768465\n",
      "train loss:0.0014976335975637252\n",
      "train loss:0.00023335398021500552\n",
      "train loss:0.001761893370763117\n",
      "train loss:0.005581092227734023\n",
      "train loss:0.0039488782774901796\n",
      "train loss:0.003228878997708057\n",
      "train loss:0.008784488881003213\n",
      "train loss:0.015894639388084747\n",
      "train loss:0.0056276494938735525\n",
      "train loss:0.003502569336138751\n",
      "train loss:0.02075653890857506\n",
      "train loss:0.004314850155418366\n",
      "train loss:0.01385249937749024\n",
      "train loss:0.005721533811617993\n",
      "train loss:0.034801988353757196\n",
      "train loss:0.0011216985828548841\n",
      "train loss:0.0014940527547811302\n",
      "train loss:0.001265491795905573\n",
      "train loss:0.0018644909765547929\n",
      "train loss:0.0032084810456984494\n",
      "train loss:0.009121758533540136\n",
      "train loss:0.002338665801047305\n",
      "train loss:0.008696006150452781\n",
      "train loss:0.0016883608254398906\n",
      "train loss:0.0016500748314177151\n",
      "train loss:0.002283541233106256\n",
      "train loss:0.0012609366775214927\n",
      "train loss:0.002734691985826735\n",
      "train loss:0.001161876160696389\n",
      "train loss:0.000551940910796272\n",
      "train loss:0.039657931747834094\n",
      "train loss:0.009600576712450338\n",
      "train loss:0.0010289891571754414\n",
      "train loss:0.004176705494100573\n",
      "train loss:0.003139441543661996\n",
      "train loss:0.005147627147036867\n",
      "train loss:0.0076196088260405285\n",
      "train loss:0.0019007519947850768\n",
      "train loss:0.0020893016944779222\n",
      "train loss:0.0021478010939783737\n",
      "train loss:0.0030432035367329736\n",
      "train loss:0.005234958099389525\n",
      "train loss:0.04843664379050766\n",
      "train loss:0.003544017988339669\n",
      "train loss:0.0020007493325505297\n",
      "train loss:0.040206991825184966\n",
      "train loss:0.0011521389216444416\n",
      "train loss:0.001989176192141862\n",
      "train loss:0.009889438956449186\n",
      "train loss:0.0014161851090928835\n",
      "train loss:0.0015935009903059825\n",
      "train loss:0.0009135232360264611\n",
      "train loss:0.0006176326191144207\n",
      "train loss:0.0022478730423722733\n",
      "train loss:0.0012171982091303281\n",
      "train loss:0.0006226234655928959\n",
      "train loss:0.003480902898078271\n",
      "train loss:0.009926195093887223\n",
      "train loss:0.0037742505778785994\n",
      "train loss:0.0062923239787166995\n",
      "train loss:0.004793636970843817\n",
      "train loss:0.004625859478228322\n",
      "train loss:0.0005202868050772934\n",
      "train loss:0.02192500945798499\n",
      "train loss:0.006309114135318482\n",
      "train loss:0.0014019041526696075\n",
      "train loss:0.007785429690866483\n",
      "train loss:0.00711352090495119\n",
      "train loss:0.0036745156083488307\n",
      "train loss:0.005476022339807075\n",
      "train loss:0.0005399363823357437\n",
      "train loss:0.001129520364709976\n",
      "train loss:0.006388352046287036\n",
      "train loss:0.004801268888543534\n",
      "train loss:0.005024769086363366\n",
      "train loss:0.004153170553474614\n",
      "train loss:0.004606031478699791\n",
      "train loss:0.004415605406047713\n",
      "train loss:0.004653400220367704\n",
      "train loss:0.0049070303488166715\n",
      "train loss:0.0004918353247766355\n",
      "train loss:0.0033368434709190437\n",
      "train loss:0.0023303884668068363\n",
      "train loss:0.002814763585691918\n",
      "train loss:0.0016402492424926424\n",
      "train loss:0.0017787764130143644\n",
      "train loss:0.0009900866964673296\n",
      "train loss:0.00465127080825206\n",
      "train loss:0.0026678895493007894\n",
      "train loss:0.0005845222160981594\n",
      "train loss:0.0024511558269326127\n",
      "train loss:0.0003020065662596951\n",
      "train loss:0.006817518908757329\n",
      "train loss:0.00019404378605624524\n",
      "train loss:0.0021343540296956936\n",
      "train loss:0.0013480854289091254\n",
      "train loss:0.009667593864059269\n",
      "train loss:0.015816102739518677\n",
      "train loss:0.002048883056170391\n",
      "train loss:0.0022741037122280595\n",
      "train loss:0.0013921573288298958\n",
      "train loss:0.0003648934223520949\n",
      "train loss:0.008911613932606024\n",
      "train loss:0.005488270063624083\n",
      "train loss:0.0023239646806777125\n",
      "train loss:0.0007616051048134787\n",
      "train loss:0.0025471615163272852\n",
      "train loss:0.0007422888489051122\n",
      "train loss:0.003474179711035944\n",
      "train loss:0.019977121533991813\n",
      "train loss:0.00016250692015850474\n",
      "train loss:0.0025335215707702374\n",
      "train loss:0.014070929026577845\n",
      "train loss:0.0023050151917374663\n",
      "train loss:0.0019850713349882716\n",
      "train loss:0.007825459610584597\n",
      "train loss:0.00046972238915783644\n",
      "train loss:0.004380692659716008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022202617516611143\n",
      "train loss:0.010194911407637503\n",
      "train loss:0.008347967585204171\n",
      "train loss:0.0018145782617565978\n",
      "train loss:0.0008750804490019763\n",
      "train loss:0.0015351568037801772\n",
      "train loss:0.004324292126674324\n",
      "train loss:0.0009483995000196348\n",
      "train loss:0.0007558200531394926\n",
      "train loss:0.005011550674344313\n",
      "train loss:0.00046264534550343703\n",
      "train loss:0.010209665630461504\n",
      "train loss:0.0002523267996084777\n",
      "train loss:0.002317697773316052\n",
      "train loss:0.027044117288655446\n",
      "train loss:0.006423577422639136\n",
      "train loss:0.003169703141195665\n",
      "train loss:0.0029816300974115414\n",
      "train loss:0.000342026549116584\n",
      "train loss:0.003144694839177558\n",
      "train loss:0.0016096166860809016\n",
      "train loss:0.005186884725670205\n",
      "train loss:0.0017828665019428694\n",
      "train loss:0.002007097285454078\n",
      "train loss:0.0015480639234040727\n",
      "train loss:0.0059394856759430155\n",
      "train loss:0.0008651106516291288\n",
      "train loss:0.004157879143599143\n",
      "train loss:0.014175328556154916\n",
      "train loss:0.0025747589989163016\n",
      "train loss:0.006408406957565377\n",
      "train loss:0.0021904981869206503\n",
      "train loss:0.007410386629894385\n",
      "train loss:0.0033677834419345103\n",
      "train loss:0.001563522818078361\n",
      "train loss:0.007925515610798368\n",
      "train loss:0.0031954236727400383\n",
      "train loss:0.0011859371132890563\n",
      "train loss:0.020370836296780995\n",
      "train loss:0.004420538177147283\n",
      "train loss:0.0017918942687200673\n",
      "train loss:0.0018492265416339521\n",
      "train loss:0.0007160450514237839\n",
      "train loss:0.00027296422524362556\n",
      "train loss:0.001396109529063836\n",
      "train loss:0.005997656113933084\n",
      "train loss:0.0020229417959317366\n",
      "train loss:0.004560848326894564\n",
      "train loss:0.0005425855273780288\n",
      "train loss:0.005364653720105889\n",
      "train loss:0.0005061597519697325\n",
      "train loss:0.0016682504579194235\n",
      "train loss:0.027386543861392828\n",
      "train loss:0.0033298759979899072\n",
      "train loss:0.02986705548080634\n",
      "train loss:0.0019472065779053\n",
      "train loss:0.002241748164162818\n",
      "train loss:0.000660836889538252\n",
      "train loss:0.0480605562962208\n",
      "train loss:0.0006093316656403301\n",
      "train loss:0.004134032361067709\n",
      "train loss:0.0075282484869656306\n",
      "train loss:0.011543972419041877\n",
      "train loss:0.0025332771244341397\n",
      "train loss:0.001010126720489295\n",
      "train loss:0.004318803364313467\n",
      "train loss:0.0160091447214842\n",
      "train loss:0.028729575111770024\n",
      "train loss:0.004209005716797613\n",
      "train loss:0.0010886155424881616\n",
      "train loss:0.002130901189329432\n",
      "train loss:0.0029425680002371246\n",
      "train loss:0.00202245029144258\n",
      "train loss:0.0016058872559636937\n",
      "train loss:0.0013398423983826708\n",
      "train loss:0.012623281680539236\n",
      "train loss:0.003758712780231675\n",
      "train loss:0.0011092821605538064\n",
      "train loss:0.0034584280794015664\n",
      "train loss:0.0051754265409031655\n",
      "train loss:0.003487111335667245\n",
      "train loss:0.002963592837249744\n",
      "train loss:0.013702351398415831\n",
      "train loss:0.001255511485927805\n",
      "train loss:0.0003234770650437072\n",
      "train loss:0.002296720722841696\n",
      "train loss:0.009243635842851053\n",
      "train loss:0.0031732275939098985\n",
      "train loss:0.0003937552412252973\n",
      "train loss:0.0012750794866131334\n",
      "train loss:0.0006480900318899089\n",
      "train loss:0.006556715545352681\n",
      "train loss:0.003210349777325735\n",
      "train loss:0.002594138736510836\n",
      "train loss:0.0018400228714291105\n",
      "train loss:0.003761430468561933\n",
      "train loss:0.00044335179765030505\n",
      "train loss:0.001271203677313861\n",
      "train loss:0.002422092229659641\n",
      "train loss:0.0007880878351336616\n",
      "train loss:0.0008809636384794163\n",
      "train loss:0.0044564008458668\n",
      "train loss:0.0023678191420574888\n",
      "train loss:0.018035114217134867\n",
      "train loss:0.0017348919650717934\n",
      "train loss:0.0029031553183184343\n",
      "train loss:0.003923526699506737\n",
      "train loss:0.0008391653037994719\n",
      "train loss:0.0005940410161374985\n",
      "train loss:0.004344038248203396\n",
      "train loss:0.006801996359240379\n",
      "train loss:0.007761972706516404\n",
      "train loss:0.006224430967375\n",
      "train loss:0.025506334929403657\n",
      "train loss:0.0018851851272664128\n",
      "train loss:0.0004854983913267333\n",
      "train loss:0.004252845124264395\n",
      "train loss:0.004094872216125792\n",
      "train loss:0.009763926883467978\n",
      "train loss:0.001596680870167028\n",
      "train loss:0.011030652102977044\n",
      "train loss:0.0008219197815959189\n",
      "train loss:0.0009654267460096786\n",
      "train loss:0.009495175083938774\n",
      "train loss:0.005859990634201099\n",
      "train loss:0.010319277294618713\n",
      "train loss:0.0007199677520506976\n",
      "=== epoch:12, train acc:0.996, test acc:0.985 ===\n",
      "train loss:0.0012573285254796986\n",
      "train loss:0.00037575489229687556\n",
      "train loss:0.004182122881056463\n",
      "train loss:0.005091689635281078\n",
      "train loss:0.005431402274799067\n",
      "train loss:0.02263559102740683\n",
      "train loss:0.047803169136530696\n",
      "train loss:0.002104365265658529\n",
      "train loss:0.0036614505614127164\n",
      "train loss:0.006903351256263001\n",
      "train loss:0.002341938269967413\n",
      "train loss:0.000687546387340558\n",
      "train loss:0.009289340900406581\n",
      "train loss:0.0017237621286755051\n",
      "train loss:0.0013416518809386663\n",
      "train loss:0.0020827559910272762\n",
      "train loss:0.009291920819415184\n",
      "train loss:0.0009943587037269288\n",
      "train loss:0.0068298705929472955\n",
      "train loss:0.0035365158400073\n",
      "train loss:0.005876414960216441\n",
      "train loss:0.0004178893520363255\n",
      "train loss:0.0005878923080915855\n",
      "train loss:0.005946584346047898\n",
      "train loss:0.0003664118662099192\n",
      "train loss:0.0017191266148641458\n",
      "train loss:0.0015621128303182077\n",
      "train loss:0.0014983189369370523\n",
      "train loss:0.003268090178236538\n",
      "train loss:0.004103545788120905\n",
      "train loss:0.0017679074922345578\n",
      "train loss:0.006351452892319186\n",
      "train loss:0.0030937305598944136\n",
      "train loss:0.005328304022329518\n",
      "train loss:0.00271554896704434\n",
      "train loss:0.0015493189756675067\n",
      "train loss:0.0015297257973072658\n",
      "train loss:0.001314802701885046\n",
      "train loss:0.0007172654151851837\n",
      "train loss:0.004103829124979074\n",
      "train loss:0.0018614019861742858\n",
      "train loss:0.00040154630628354114\n",
      "train loss:0.004301504079681968\n",
      "train loss:0.008316683162154937\n",
      "train loss:0.006788251530785145\n",
      "train loss:0.00015530128251059876\n",
      "train loss:0.0073232626820467425\n",
      "train loss:0.01300355229191963\n",
      "train loss:0.005648934926556603\n",
      "train loss:0.001878406836452486\n",
      "train loss:0.002623087708926551\n",
      "train loss:0.12991445337986843\n",
      "train loss:0.0013676222583939696\n",
      "train loss:0.004005071046209226\n",
      "train loss:0.004289150308339127\n",
      "train loss:0.025154047105616383\n",
      "train loss:0.0002111899690150338\n",
      "train loss:0.008009587292160522\n",
      "train loss:0.0036181179793287974\n",
      "train loss:0.0014695539291202445\n",
      "train loss:0.0013101848400301525\n",
      "train loss:0.004729783942884566\n",
      "train loss:0.011908676624711088\n",
      "train loss:0.0033563767165180015\n",
      "train loss:0.004678272721056498\n",
      "train loss:0.006887511797635434\n",
      "train loss:0.004521954125739836\n",
      "train loss:0.003135167031555974\n",
      "train loss:0.0017190605314135535\n",
      "train loss:0.0019859371770673886\n",
      "train loss:0.003637121865607865\n",
      "train loss:0.00521511699391281\n",
      "train loss:0.005350167368698558\n",
      "train loss:0.0009627045653294012\n",
      "train loss:0.005576484156968356\n",
      "train loss:0.0029640283000311163\n",
      "train loss:0.001552288156091612\n",
      "train loss:0.019716967326598438\n",
      "train loss:0.0004785261211654004\n",
      "train loss:0.005376335782518631\n",
      "train loss:0.0012087860294964323\n",
      "train loss:0.005531427404996998\n",
      "train loss:0.0017151417339270917\n",
      "train loss:0.031275162077438\n",
      "train loss:0.001640464510963349\n",
      "train loss:0.0070144183428375055\n",
      "train loss:0.015256869734109679\n",
      "train loss:0.00106662368637913\n",
      "train loss:0.003422483574903631\n",
      "train loss:0.003227325213329218\n",
      "train loss:0.00627691016398298\n",
      "train loss:0.002592797645768919\n",
      "train loss:0.0006060023265208681\n",
      "train loss:0.0011225093503056062\n",
      "train loss:0.022174643336124115\n",
      "train loss:0.003566931238971299\n",
      "train loss:0.0003952416186983581\n",
      "train loss:0.0035917254818104163\n",
      "train loss:0.00547581334674535\n",
      "train loss:0.0013424082203915932\n",
      "train loss:0.007104766081134794\n",
      "train loss:0.00270210711126483\n",
      "train loss:0.0037072095869750393\n",
      "train loss:0.003101036060695702\n",
      "train loss:0.0010784596691153013\n",
      "train loss:0.0014196011554885681\n",
      "train loss:0.002253298994349102\n",
      "train loss:0.0006418898383630732\n",
      "train loss:0.007926993072380031\n",
      "train loss:0.0033563901377304346\n",
      "train loss:0.07623724289095984\n",
      "train loss:0.0013547347479785604\n",
      "train loss:0.012985149849963582\n",
      "train loss:0.0012983649858230196\n",
      "train loss:0.0037069317014066195\n",
      "train loss:0.001135201879766419\n",
      "train loss:0.006606536611749805\n",
      "train loss:0.0011905073455007501\n",
      "train loss:0.006555220145028911\n",
      "train loss:0.004591876345134304\n",
      "train loss:9.487563901921585e-05\n",
      "train loss:0.002577299593561106\n",
      "train loss:0.003882682190567647\n",
      "train loss:0.04279997361022919\n",
      "train loss:0.0007492064267956592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0038200268062962874\n",
      "train loss:0.0017010142765422854\n",
      "train loss:0.03466415976367078\n",
      "train loss:0.0016527762034070322\n",
      "train loss:0.003732529812343688\n",
      "train loss:0.005386034401240445\n",
      "train loss:0.0010322037782912639\n",
      "train loss:0.00220157603806368\n",
      "train loss:0.008609978961071348\n",
      "train loss:0.008384304382337386\n",
      "train loss:0.037090159789775104\n",
      "train loss:0.0010889124465160035\n",
      "train loss:0.00614240646436667\n",
      "train loss:0.0007016149315127934\n",
      "train loss:0.0004400760174327219\n",
      "train loss:0.0029987029112984597\n",
      "train loss:0.008309772441973486\n",
      "train loss:0.0155438774211981\n",
      "train loss:0.0007961376734199224\n",
      "train loss:0.0034524979028107534\n",
      "train loss:0.004377645314682249\n",
      "train loss:0.008094595997347043\n",
      "train loss:0.0004912575240599733\n",
      "train loss:0.02751724419182246\n",
      "train loss:0.026567263976165933\n",
      "train loss:0.009752701697774029\n",
      "train loss:0.0022641800840758415\n",
      "train loss:0.0005016419234622605\n",
      "train loss:0.013004469849128033\n",
      "train loss:0.01618975580972558\n",
      "train loss:0.004155938331846323\n",
      "train loss:0.009461978015001146\n",
      "train loss:0.00047309860228580167\n",
      "train loss:0.0013754213913346497\n",
      "train loss:0.0037270411877964\n",
      "train loss:0.001707884232084826\n",
      "train loss:0.006048160508522142\n",
      "train loss:0.001881989085939155\n",
      "train loss:0.006085501456237359\n",
      "train loss:0.004743398157303153\n",
      "train loss:0.005283088008640579\n",
      "train loss:0.0021414662977380493\n",
      "train loss:0.013734721041069115\n",
      "train loss:0.013759772507984123\n",
      "train loss:0.001139324767978451\n",
      "train loss:0.0016514508112664057\n",
      "train loss:0.003954957844518573\n",
      "train loss:0.004789966808062141\n",
      "train loss:0.0009924745634815558\n",
      "train loss:0.0024173893734174647\n",
      "train loss:0.028641531097451732\n",
      "train loss:0.005530976484587856\n",
      "train loss:0.024701399015839943\n",
      "train loss:0.003168695830299598\n",
      "train loss:0.00036259582515451146\n",
      "train loss:0.00056278374286102\n",
      "train loss:0.013479033730138791\n",
      "train loss:0.007594825372721988\n",
      "train loss:0.0018538250890348998\n",
      "train loss:0.03309778123738391\n",
      "train loss:0.002392749571746712\n",
      "train loss:0.010793122647899278\n",
      "train loss:0.0009462974437183599\n",
      "train loss:0.004215142749973442\n",
      "train loss:0.0008856654191059728\n",
      "train loss:0.0012385406011256829\n",
      "train loss:0.002634430988811321\n",
      "train loss:0.002627055291456472\n",
      "train loss:0.033448501246209815\n",
      "train loss:0.006170968189462106\n",
      "train loss:0.0009932231593104276\n",
      "train loss:0.017554752371540507\n",
      "train loss:0.007243015320328738\n",
      "train loss:0.04374514112492686\n",
      "train loss:0.001689282021147511\n",
      "train loss:0.005184534148079114\n",
      "train loss:0.002111174156364215\n",
      "train loss:0.0047933539132624416\n",
      "train loss:0.09661792474137788\n",
      "train loss:0.00198898249519137\n",
      "train loss:0.01629801049251374\n",
      "train loss:0.006867599447558893\n",
      "train loss:0.0005028702895467373\n",
      "train loss:0.004607502616065976\n",
      "train loss:0.016148190391908023\n",
      "train loss:0.028975933696889312\n",
      "train loss:0.00537128246950957\n",
      "train loss:0.0029014962978253346\n",
      "train loss:0.0014828766388989931\n",
      "train loss:0.0022750993581375487\n",
      "train loss:0.013144381654500938\n",
      "train loss:0.0030059666738970476\n",
      "train loss:0.013557960137793987\n",
      "train loss:0.0011432459979088042\n",
      "train loss:0.004064060569230205\n",
      "train loss:0.0018918281705816173\n",
      "train loss:0.0026262380071811814\n",
      "train loss:0.004335713727768607\n",
      "train loss:0.011988231227777552\n",
      "train loss:0.001113090322306551\n",
      "train loss:0.012873897066941389\n",
      "train loss:0.00034793023987876684\n",
      "train loss:0.002674535443341692\n",
      "train loss:0.06856895365507225\n",
      "train loss:0.0008983188407697965\n",
      "train loss:0.0016977104639626986\n",
      "train loss:0.00985132016421202\n",
      "train loss:0.015496930261927522\n",
      "train loss:0.015069902603267977\n",
      "train loss:0.004730900358311906\n",
      "train loss:0.004467371529313499\n",
      "train loss:0.0032053401758639277\n",
      "train loss:0.00046953916298826713\n",
      "train loss:0.0036089898957102286\n",
      "train loss:0.011177815429324051\n",
      "train loss:0.010299890683355023\n",
      "train loss:0.0016319381878955597\n",
      "train loss:0.014173565648945981\n",
      "train loss:0.002463221298983546\n",
      "train loss:0.004080850550144019\n",
      "train loss:0.0030287114938224585\n",
      "train loss:0.01717387001359656\n",
      "train loss:0.004942361655367852\n",
      "train loss:0.001530410933296934\n",
      "train loss:0.01159682683981845\n",
      "train loss:0.0032419928346706455\n",
      "train loss:0.005967527489920177\n",
      "train loss:0.0028975639865287408\n",
      "train loss:0.0005477742739209716\n",
      "train loss:0.0029981547250997114\n",
      "train loss:0.005482018529214407\n",
      "train loss:0.0049460096529074975\n",
      "train loss:0.004334186155633934\n",
      "train loss:0.0007922551071051702\n",
      "train loss:0.0026114929158127693\n",
      "train loss:0.0014304363954556743\n",
      "train loss:0.0013397051509331536\n",
      "train loss:0.010351004174928784\n",
      "train loss:0.007191972166037168\n",
      "train loss:0.005474397294919268\n",
      "train loss:0.005279805331220003\n",
      "train loss:0.008273142140753382\n",
      "train loss:0.008031114612037678\n",
      "train loss:0.007720088333347212\n",
      "train loss:0.0026415578663842383\n",
      "train loss:0.0041358960714834355\n",
      "train loss:0.006167077790020337\n",
      "train loss:0.0018932540125618966\n",
      "train loss:0.0001984565039576728\n",
      "train loss:0.0005130401483790047\n",
      "train loss:0.0011399651542569574\n",
      "train loss:0.013006315501972048\n",
      "train loss:0.0039436250111973565\n",
      "train loss:0.011043941829027291\n",
      "train loss:0.014447361978646198\n",
      "train loss:0.053936282998579825\n",
      "train loss:0.0017662097905471236\n",
      "train loss:0.0008244139484220321\n",
      "train loss:0.0020019614165946954\n",
      "train loss:0.028245880044615364\n",
      "train loss:0.004359284488884187\n",
      "train loss:0.0028624700457813047\n",
      "train loss:0.0010465323937187004\n",
      "train loss:0.0029555129505293614\n",
      "train loss:0.009937257214903182\n",
      "train loss:0.00025826126216484097\n",
      "train loss:0.0005140207212219834\n",
      "train loss:0.004108176376025309\n",
      "train loss:0.0012687742476403601\n",
      "train loss:0.0015532987317630803\n",
      "train loss:0.00038525153305013856\n",
      "train loss:0.008316135062956835\n",
      "train loss:0.014361109219003769\n",
      "train loss:0.0018944359196904936\n",
      "train loss:0.0018096538133745444\n",
      "train loss:0.0037965533143282677\n",
      "train loss:0.011736042899758577\n",
      "train loss:0.0035300306089251815\n",
      "train loss:0.017375975847173347\n",
      "train loss:0.0019944474463000155\n",
      "train loss:0.000847984525801631\n",
      "train loss:0.005780422304916104\n",
      "train loss:0.0018592740449461798\n",
      "train loss:0.004880869798275014\n",
      "train loss:0.0004814214793854772\n",
      "train loss:0.02130468577382819\n",
      "train loss:0.0010454259439204542\n",
      "train loss:0.00829973955256326\n",
      "train loss:0.0015512684381386072\n",
      "train loss:0.0016647550753906577\n",
      "train loss:0.0019179090801690912\n",
      "train loss:0.004778621804646071\n",
      "train loss:0.015373118284523311\n",
      "train loss:0.0030594438871691335\n",
      "train loss:0.0014202711909447844\n",
      "train loss:0.0004017383476013801\n",
      "train loss:0.005796859575763166\n",
      "train loss:0.003939690744272555\n",
      "train loss:0.00011133957405503408\n",
      "train loss:0.0012502269192529597\n",
      "train loss:0.0024036969834708185\n",
      "train loss:0.009285593347472034\n",
      "train loss:0.024923888402259075\n",
      "train loss:0.0007923050743520504\n",
      "train loss:0.01485620240665279\n",
      "train loss:0.0008979436715637871\n",
      "train loss:0.001002023621857792\n",
      "train loss:0.0011033337911932394\n",
      "train loss:0.0005161039809099446\n",
      "train loss:0.0018075693692702697\n",
      "train loss:0.015718270755211216\n",
      "train loss:0.004676376682404695\n",
      "train loss:0.007635783665344803\n",
      "train loss:0.005057559816849038\n",
      "train loss:0.003987891831158558\n",
      "train loss:0.0014710975632538622\n",
      "train loss:0.00021648525840764414\n",
      "train loss:0.00026024829528761297\n",
      "train loss:0.005354199536219481\n",
      "train loss:0.006802906955559629\n",
      "train loss:0.008070005787767015\n",
      "train loss:0.007297734285400908\n",
      "train loss:0.0044104580684758\n",
      "train loss:0.011340071697713167\n",
      "train loss:0.0034355505350683073\n",
      "train loss:0.00032071567283260935\n",
      "train loss:0.005625163527793298\n",
      "train loss:0.0014762524224278745\n",
      "train loss:0.0009947704635070208\n",
      "train loss:0.0006103761826409439\n",
      "train loss:0.008104665856218645\n",
      "train loss:0.003564711853360256\n",
      "train loss:0.0003584729355354932\n",
      "train loss:0.002141250780909236\n",
      "train loss:0.002656985146430805\n",
      "train loss:0.006230476761475442\n",
      "train loss:0.0007124228617409946\n",
      "train loss:0.0013292025474834432\n",
      "train loss:0.0016465598935099456\n",
      "train loss:0.0009142688163470136\n",
      "train loss:0.0032704320521828424\n",
      "train loss:0.001836035631568432\n",
      "train loss:0.0038783039822935955\n",
      "train loss:0.0030759286520516587\n",
      "train loss:0.0007794081572669236\n",
      "train loss:0.0001972065303752433\n",
      "train loss:0.0024275507776686405\n",
      "train loss:0.0009184726329375208\n",
      "train loss:0.0003799817153509636\n",
      "train loss:0.009699656789905675\n",
      "train loss:0.007372242631840996\n",
      "train loss:0.0016882192005346955\n",
      "train loss:0.0031433322271874438\n",
      "train loss:0.0025525808713429145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022934359213582535\n",
      "train loss:0.001210288590020276\n",
      "train loss:0.003204728925003477\n",
      "train loss:0.006849863892689929\n",
      "train loss:0.000546259593986972\n",
      "train loss:0.00028924864170487113\n",
      "train loss:0.001983919249130531\n",
      "train loss:0.007230711194577664\n",
      "train loss:0.009686747647120842\n",
      "train loss:0.002236357386522787\n",
      "train loss:0.0019155221981920184\n",
      "train loss:0.0010588418335682253\n",
      "train loss:0.001110962036769301\n",
      "train loss:0.0005750997921293268\n",
      "train loss:0.00598869087830645\n",
      "train loss:0.0006144776896622026\n",
      "train loss:0.0012228534859674847\n",
      "train loss:0.002228672627067025\n",
      "train loss:0.03300260513071649\n",
      "train loss:0.00817476917592143\n",
      "train loss:0.0007054155023087906\n",
      "train loss:0.006145279505403028\n",
      "train loss:0.0022263772491653085\n",
      "train loss:0.000497816121347575\n",
      "train loss:0.001968694179648263\n",
      "train loss:0.0037782099287294057\n",
      "train loss:0.001536983352008581\n",
      "train loss:0.0005854572620077131\n",
      "train loss:0.0012464681478807859\n",
      "train loss:0.01527378039730373\n",
      "train loss:0.008689263051282637\n",
      "train loss:0.002830482132572706\n",
      "train loss:0.0003369628222763431\n",
      "train loss:0.0008661179850220532\n",
      "train loss:0.0017050176917486235\n",
      "train loss:0.0036668433027936343\n",
      "train loss:0.00036416847447691967\n",
      "train loss:0.000996613945260442\n",
      "train loss:0.0013419702738366082\n",
      "train loss:0.004702602414099016\n",
      "train loss:0.0019185775104991574\n",
      "train loss:0.0025939852641606452\n",
      "train loss:0.005552208384986134\n",
      "train loss:0.028303154096069646\n",
      "train loss:0.0007513772738541569\n",
      "train loss:0.007944017350207715\n",
      "train loss:0.005718305994530214\n",
      "train loss:0.004353619739959897\n",
      "train loss:0.003493180386467139\n",
      "train loss:0.0007766327183058644\n",
      "train loss:0.00021557143381727235\n",
      "train loss:0.001789076803641518\n",
      "train loss:0.004866975823144908\n",
      "train loss:0.004026438272172574\n",
      "train loss:0.0004515265876694709\n",
      "train loss:0.0019009403737119531\n",
      "train loss:0.00023019626293722272\n",
      "train loss:0.0006191724397637578\n",
      "train loss:0.002098627488128265\n",
      "train loss:0.0014538781536382564\n",
      "train loss:0.001559950255995141\n",
      "train loss:0.0029454053821695563\n",
      "train loss:0.010091450826414255\n",
      "train loss:0.0003753790168510442\n",
      "train loss:0.016040913700060125\n",
      "train loss:0.0002839954631694048\n",
      "train loss:0.0009740204159649723\n",
      "train loss:0.0004401356287554809\n",
      "train loss:0.0037917446770782924\n",
      "train loss:0.0017749823845773494\n",
      "train loss:0.0001959963517366021\n",
      "train loss:0.002410847692917885\n",
      "train loss:0.0032420575797568424\n",
      "train loss:0.004268875225420275\n",
      "train loss:0.0019649855756506437\n",
      "train loss:0.004323819656314237\n",
      "train loss:0.0007323744768858193\n",
      "train loss:0.00983894174067886\n",
      "train loss:0.008475984430422023\n",
      "train loss:0.037622221773567735\n",
      "train loss:9.698342563584741e-05\n",
      "train loss:0.004961614002892627\n",
      "train loss:0.007046870479284675\n",
      "train loss:0.003350533085122323\n",
      "train loss:0.003465556865357457\n",
      "train loss:0.0014617326647863433\n",
      "train loss:0.004163664944355484\n",
      "train loss:0.000520781950134477\n",
      "train loss:0.009760421960822427\n",
      "train loss:0.0032726200744609903\n",
      "train loss:0.002731420211697049\n",
      "train loss:0.06519669908984162\n",
      "train loss:0.0010706734109414246\n",
      "train loss:0.0023282112625560873\n",
      "train loss:0.00967754385905034\n",
      "train loss:0.0025843220726555183\n",
      "train loss:0.005847591768679918\n",
      "train loss:0.0065796090878378274\n",
      "train loss:0.0025761037428358047\n",
      "train loss:0.0005212995328253922\n",
      "train loss:0.0006628481687445052\n",
      "train loss:0.00036515347871096963\n",
      "train loss:0.005989202885271495\n",
      "train loss:0.0013345814820449776\n",
      "train loss:0.001915707671139893\n",
      "train loss:0.011357341621213381\n",
      "train loss:0.0064726689289531306\n",
      "train loss:0.005004797082201517\n",
      "train loss:0.002955537205874889\n",
      "train loss:0.0060013857820021485\n",
      "train loss:0.0005046827887053108\n",
      "train loss:0.0007948539642782229\n",
      "train loss:0.00012907162016320887\n",
      "train loss:0.00010252564519576079\n",
      "train loss:0.00047742463040315497\n",
      "train loss:0.03146819674152774\n",
      "train loss:0.003415078177476832\n",
      "train loss:0.001515260749304277\n",
      "train loss:0.003504941267201824\n",
      "train loss:0.003513002849679831\n",
      "train loss:0.0007102078737785375\n",
      "train loss:0.0014140425079440196\n",
      "train loss:0.005713320178432632\n",
      "train loss:0.0002421419011181913\n",
      "train loss:0.0024456409623517293\n",
      "train loss:0.009294710473513497\n",
      "train loss:0.001654179270800258\n",
      "train loss:0.0019250759626159469\n",
      "train loss:0.000927551038815588\n",
      "train loss:0.0015579800969220139\n",
      "train loss:0.002457476832926401\n",
      "train loss:0.008086955395424334\n",
      "train loss:0.003363431056452133\n",
      "train loss:0.0013636216130271436\n",
      "train loss:0.0008867412577642692\n",
      "train loss:0.0030732501510727767\n",
      "train loss:0.002552512601899031\n",
      "train loss:0.001304891088583619\n",
      "train loss:0.001871161238658603\n",
      "train loss:0.0027425309066183927\n",
      "train loss:0.0015690313881272725\n",
      "train loss:0.0017889636141816482\n",
      "train loss:0.003109098707453034\n",
      "train loss:0.0022394082089662883\n",
      "train loss:0.0012148085615075587\n",
      "train loss:0.0014577233045856696\n",
      "train loss:0.0009764406282523723\n",
      "train loss:0.003738691806601502\n",
      "train loss:0.0036834478162708867\n",
      "train loss:0.0013849668157214661\n",
      "train loss:0.002009046239711138\n",
      "train loss:0.0023272216932138275\n",
      "train loss:0.0028581495661904686\n",
      "train loss:0.004654305652794479\n",
      "train loss:0.005006231445747447\n",
      "train loss:0.0013816955153776096\n",
      "train loss:0.001982260982466923\n",
      "train loss:0.009311271090812534\n",
      "train loss:0.0038522567122625654\n",
      "train loss:0.006309293110627637\n",
      "train loss:0.002919117599330516\n",
      "train loss:0.002408846519165812\n",
      "train loss:0.0017652889587837595\n",
      "train loss:0.008582574155281492\n",
      "train loss:0.0021613884924816134\n",
      "train loss:0.0012735550275767876\n",
      "train loss:0.0036072316568403523\n",
      "train loss:0.0028960385127208515\n",
      "train loss:0.0036323100939291285\n",
      "train loss:0.010573363205805335\n",
      "train loss:0.00525878894175941\n",
      "train loss:0.00027563973571520734\n",
      "train loss:0.002871486820459034\n",
      "train loss:0.0004114804953594831\n",
      "train loss:5.080810972719289e-05\n",
      "train loss:0.0033457022240572887\n",
      "train loss:0.008577510568844586\n",
      "train loss:0.005054531841324523\n",
      "train loss:0.0023400913558195642\n",
      "train loss:0.0017327300927335429\n",
      "train loss:0.00010480365909500498\n",
      "train loss:0.003509350413393007\n",
      "train loss:0.004937571058158178\n",
      "train loss:0.0025423374523444635\n",
      "train loss:0.002078845032106206\n",
      "train loss:0.0006678324495915538\n",
      "train loss:0.01809106498561951\n",
      "train loss:0.0007101416270447605\n",
      "train loss:0.001680004953967155\n",
      "train loss:0.002627185988984605\n",
      "train loss:0.0023713600273672906\n",
      "train loss:0.006763258850505423\n",
      "train loss:0.003519995927883086\n",
      "train loss:9.786670464423836e-05\n",
      "train loss:0.001010935760954739\n",
      "train loss:0.009119217025155639\n",
      "train loss:0.004475533423556697\n",
      "train loss:0.0004784189659418633\n",
      "train loss:0.0009993032770943173\n",
      "train loss:0.024647668523774913\n",
      "train loss:0.0005745506723900106\n",
      "train loss:0.0008161818315469441\n",
      "train loss:0.010147174663739347\n",
      "train loss:0.003963989712479477\n",
      "train loss:0.00722223526071582\n",
      "train loss:0.006340176779490198\n",
      "train loss:0.0026185534120497724\n",
      "train loss:0.002515145603208361\n",
      "train loss:0.001510009475476591\n",
      "train loss:0.006236190956036416\n",
      "train loss:0.0007664471353429971\n",
      "train loss:0.008252718933423484\n",
      "train loss:0.0012030579876220497\n",
      "train loss:0.0006428461888477228\n",
      "train loss:0.005231373357564163\n",
      "train loss:0.0016385458352413086\n",
      "train loss:0.003021274641891839\n",
      "train loss:0.0005681968558549058\n",
      "train loss:0.047283261021433515\n",
      "train loss:0.0016911750978704113\n",
      "train loss:0.006050984550381658\n",
      "=== epoch:13, train acc:0.999, test acc:0.987 ===\n",
      "train loss:0.027985429433790916\n",
      "train loss:0.00014823148697817092\n",
      "train loss:0.1003506713165393\n",
      "train loss:0.0003392634394206173\n",
      "train loss:0.0018183838332610017\n",
      "train loss:0.0020656068522995805\n",
      "train loss:0.007450674632533325\n",
      "train loss:0.0011801495956448719\n",
      "train loss:0.0007348959181136806\n",
      "train loss:0.00027139596898245917\n",
      "train loss:0.0010947098924392789\n",
      "train loss:0.0008404637888404098\n",
      "train loss:0.029781513955117096\n",
      "train loss:0.0010483020770285197\n",
      "train loss:0.01884031517357308\n",
      "train loss:0.026523538288686935\n",
      "train loss:0.0036305072395935974\n",
      "train loss:0.0008871291605246972\n",
      "train loss:5.4642212251065495e-05\n",
      "train loss:0.006677592728192987\n",
      "train loss:0.005411818302369999\n",
      "train loss:0.0013213381466201462\n",
      "train loss:0.005420993112561296\n",
      "train loss:0.001673259744530472\n",
      "train loss:0.0008208697172414177\n",
      "train loss:0.005474025121713355\n",
      "train loss:0.0023867726470299315\n",
      "train loss:0.0008586221648741896\n",
      "train loss:0.0018654790520855537\n",
      "train loss:0.0034784725786098925\n",
      "train loss:0.0035056702165192507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0016274729600150087\n",
      "train loss:0.0013111362231023125\n",
      "train loss:0.006008622216966453\n",
      "train loss:0.0015406325915764255\n",
      "train loss:0.0005871774485768518\n",
      "train loss:0.0011348416251910221\n",
      "train loss:0.007425669190744317\n",
      "train loss:0.003587599725478593\n",
      "train loss:0.0008312207989485291\n",
      "train loss:0.0017335602789049149\n",
      "train loss:0.003248051912255157\n",
      "train loss:0.00041313486384096545\n",
      "train loss:0.0020052535474093893\n",
      "train loss:0.006841887058455181\n",
      "train loss:0.008336636459619991\n",
      "train loss:0.012738375852250704\n",
      "train loss:0.002227732570583607\n",
      "train loss:0.004357571308874784\n",
      "train loss:0.01073862783045895\n",
      "train loss:0.0012793412598382256\n",
      "train loss:0.0017696926931535298\n",
      "train loss:0.006067444446359252\n",
      "train loss:0.002831191429617611\n",
      "train loss:0.0013158853912735597\n",
      "train loss:0.0011382961064042671\n",
      "train loss:0.00028813070431975003\n",
      "train loss:0.00029790274641595553\n",
      "train loss:0.0007588558282176304\n",
      "train loss:0.002496512544776496\n",
      "train loss:0.004643636458008742\n",
      "train loss:0.005650350095535184\n",
      "train loss:0.022423410632121592\n",
      "train loss:0.0005384868364977061\n",
      "train loss:0.0003481361458832075\n",
      "train loss:0.005011872083658469\n",
      "train loss:0.0006220295522450895\n",
      "train loss:0.005221904034790396\n",
      "train loss:0.0064528562372450846\n",
      "train loss:0.019537505471612978\n",
      "train loss:0.002805003850225962\n",
      "train loss:0.00018366572849505558\n",
      "train loss:0.0016366452832968553\n",
      "train loss:0.0019208909841457117\n",
      "train loss:0.028438049157283304\n",
      "train loss:0.002608595439574981\n",
      "train loss:0.007188731351269101\n",
      "train loss:0.0034277126510176524\n",
      "train loss:0.010469709720411597\n",
      "train loss:0.0004870728143602908\n",
      "train loss:0.0006294267498103384\n",
      "train loss:0.0018071617030267855\n",
      "train loss:0.0007517951997262271\n",
      "train loss:0.000645632510885747\n",
      "train loss:0.0022778601445626505\n",
      "train loss:0.00023844370522007233\n",
      "train loss:5.308693970058062e-05\n",
      "train loss:0.003032101916492142\n",
      "train loss:0.021963466522557283\n",
      "train loss:0.0015398609767851303\n",
      "train loss:0.0010001903012659082\n",
      "train loss:0.005012814304567763\n",
      "train loss:0.0023910977534861108\n",
      "train loss:0.0006867478797310631\n",
      "train loss:0.010183377700576366\n",
      "train loss:0.0035082107412432247\n",
      "train loss:0.00041654029097180987\n",
      "train loss:0.0006285358115046452\n",
      "train loss:0.0018102351246577614\n",
      "train loss:0.003913600765178536\n",
      "train loss:0.0015254244933073915\n",
      "train loss:0.00414579145970671\n",
      "train loss:0.002237450486022211\n",
      "train loss:0.0010717335163560428\n",
      "train loss:0.0005051730518268729\n",
      "train loss:0.0014797031964300259\n",
      "train loss:0.0025885033949167224\n",
      "train loss:0.0018801830126423987\n",
      "train loss:0.006746686724651823\n",
      "train loss:0.0008603457645920996\n",
      "train loss:0.0010713882886509577\n",
      "train loss:0.0019040837439793297\n",
      "train loss:0.02431187976403109\n",
      "train loss:0.0017916699485981758\n",
      "train loss:0.0012882615634169094\n",
      "train loss:0.0014641076093140466\n",
      "train loss:0.0008007061079851453\n",
      "train loss:0.0012807042490403243\n",
      "train loss:0.00038157277481565803\n",
      "train loss:0.001630922976840139\n",
      "train loss:0.0003106440289956663\n",
      "train loss:0.0020461401564496593\n",
      "train loss:0.0009358763635344085\n",
      "train loss:0.00010887152390107054\n",
      "train loss:0.0012574114930701125\n",
      "train loss:0.0045755801945702055\n",
      "train loss:0.0037874233351703206\n",
      "train loss:0.0022560913255200267\n",
      "train loss:0.00143052925449608\n",
      "train loss:0.003085614660547883\n",
      "train loss:0.00020664877564225705\n",
      "train loss:0.00013175670350453026\n",
      "train loss:0.000889449640243783\n",
      "train loss:0.000348335403006005\n",
      "train loss:0.0011809384336037402\n",
      "train loss:7.814170114669979e-05\n",
      "train loss:0.0002762955549204875\n",
      "train loss:0.003266277938076188\n",
      "train loss:0.00029208709287472653\n",
      "train loss:0.0026825138964257683\n",
      "train loss:0.0026402876525094044\n",
      "train loss:0.00237801958655979\n",
      "train loss:0.0005188291346879043\n",
      "train loss:0.0007570875695689011\n",
      "train loss:0.0009849813685844928\n",
      "train loss:0.0036122196524973195\n",
      "train loss:0.0006909396921728093\n",
      "train loss:0.014372988469023112\n",
      "train loss:0.007572476552932386\n",
      "train loss:0.0015712190605075566\n",
      "train loss:0.00016607129291219363\n",
      "train loss:0.0023005506754832403\n",
      "train loss:0.0006092778609546199\n",
      "train loss:0.0005591063647642661\n",
      "train loss:0.001431579025741076\n",
      "train loss:0.0014296031086534348\n",
      "train loss:0.006286400603808964\n",
      "train loss:0.000628772884401854\n",
      "train loss:0.003318554741887194\n",
      "train loss:0.0004482619425144438\n",
      "train loss:0.004562486474145831\n",
      "train loss:0.0048306035410394105\n",
      "train loss:0.0005213390663266147\n",
      "train loss:0.0009205697228442636\n",
      "train loss:0.00037692971795390815\n",
      "train loss:0.0038878704248064134\n",
      "train loss:0.0010442856008961532\n",
      "train loss:0.0009159714963939043\n",
      "train loss:0.00048623155558289913\n",
      "train loss:0.00324637190103091\n",
      "train loss:0.00272643512218978\n",
      "train loss:0.0009186282668110269\n",
      "train loss:0.0006199104696111971\n",
      "train loss:0.000137193837218625\n",
      "train loss:0.002139124014346017\n",
      "train loss:0.0008719216595843877\n",
      "train loss:0.0009853580460883928\n",
      "train loss:0.0020322325775918833\n",
      "train loss:0.00017776755308080534\n",
      "train loss:0.0070258813888726054\n",
      "train loss:0.012816604116079416\n",
      "train loss:0.0017517224642581329\n",
      "train loss:0.00043007977302414306\n",
      "train loss:0.004482662419368088\n",
      "train loss:0.01939536834844671\n",
      "train loss:0.005439537534083243\n",
      "train loss:0.004942264626233007\n",
      "train loss:0.0011556526869045518\n",
      "train loss:0.004673030763252895\n",
      "train loss:0.0007470065095761987\n",
      "train loss:0.00126610672358303\n",
      "train loss:0.0026471883148934793\n",
      "train loss:0.0010354186812460858\n",
      "train loss:0.0004863750584904826\n",
      "train loss:0.020808882010522337\n",
      "train loss:0.0015852564392639695\n",
      "train loss:0.0011664199390096926\n",
      "train loss:0.004346355061419182\n",
      "train loss:0.004457028317234039\n",
      "train loss:0.0010086018585773713\n",
      "train loss:0.000308951165557741\n",
      "train loss:0.003979686028724219\n",
      "train loss:0.001933994636827462\n",
      "train loss:0.0051743620649924915\n",
      "train loss:0.0019437383546162472\n",
      "train loss:0.000144187482280379\n",
      "train loss:0.0018958149425285333\n",
      "train loss:0.003501987095844277\n",
      "train loss:0.003719795541757573\n",
      "train loss:0.0008963662634520277\n",
      "train loss:0.0012896024969334607\n",
      "train loss:0.005076800205287359\n",
      "train loss:0.0015166741264483626\n",
      "train loss:0.0014177813502699946\n",
      "train loss:0.0010464668927885347\n",
      "train loss:0.0009084814866299165\n",
      "train loss:0.0020110894251560794\n",
      "train loss:0.006701148161102308\n",
      "train loss:0.0006088659492668985\n",
      "train loss:0.004640271669011941\n",
      "train loss:0.0004174423904446503\n",
      "train loss:0.00013176894166008898\n",
      "train loss:0.0024620626146627856\n",
      "train loss:0.0024393649097695907\n",
      "train loss:0.0012200360507125109\n",
      "train loss:0.00026389102412050945\n",
      "train loss:0.0005217159980783473\n",
      "train loss:0.0010182307127600367\n",
      "train loss:0.0015785562961476525\n",
      "train loss:0.0017338442364319654\n",
      "train loss:0.0010617081050617498\n",
      "train loss:0.0022659724872710106\n",
      "train loss:0.00062331882417983\n",
      "train loss:0.0002031670349653957\n",
      "train loss:0.00019712616474954704\n",
      "train loss:0.0017877915920735906\n",
      "train loss:0.003160907225440187\n",
      "train loss:0.004080665505603138\n",
      "train loss:0.0010639520384779265\n",
      "train loss:0.0015892659649257884\n",
      "train loss:0.0027901889807847163\n",
      "train loss:0.0010879889053519803\n",
      "train loss:0.0006474958299497417\n",
      "train loss:9.388738192538902e-05\n",
      "train loss:0.0009663745641996949\n",
      "train loss:0.003648154098478363\n",
      "train loss:0.0032561024354097346\n",
      "train loss:0.0009784838622644734\n",
      "train loss:0.0020294744290668522\n",
      "train loss:0.000566608496331835\n",
      "train loss:0.0002571713394261533\n",
      "train loss:0.0007004072723902004\n",
      "train loss:0.0006111928876616917\n",
      "train loss:0.0003017763984481507\n",
      "train loss:0.0012669757855319735\n",
      "train loss:0.002870722138895632\n",
      "train loss:0.00019944032515382777\n",
      "train loss:0.002114588491768985\n",
      "train loss:0.003794869702096528\n",
      "train loss:0.0007930703058312582\n",
      "train loss:0.004459278164700322\n",
      "train loss:0.0034820609330941917\n",
      "train loss:0.0027802890746573307\n",
      "train loss:0.0022085475783454943\n",
      "train loss:0.0009801841747517199\n",
      "train loss:0.0002412083659703667\n",
      "train loss:0.0028167125712557006\n",
      "train loss:0.012599790877310618\n",
      "train loss:0.009522228968054892\n",
      "train loss:0.002839670273588351\n",
      "train loss:0.019291153637084717\n",
      "train loss:0.00029991632023066377\n",
      "train loss:0.0032538533926937192\n",
      "train loss:0.022159750510918372\n",
      "train loss:0.004751000411071324\n",
      "train loss:0.0006991609342975172\n",
      "train loss:0.0048365003770867035\n",
      "train loss:0.001509000938544331\n",
      "train loss:0.0002735065396310044\n",
      "train loss:0.0036649631948633375\n",
      "train loss:0.002453827356341645\n",
      "train loss:0.002067450357689132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008154072078441434\n",
      "train loss:0.0021711848398179986\n",
      "train loss:0.018914241972988785\n",
      "train loss:0.0008264255740211071\n",
      "train loss:0.0061841568272868455\n",
      "train loss:0.0018768773081475098\n",
      "train loss:0.010928681340399206\n",
      "train loss:0.0008328181094957492\n",
      "train loss:0.002077345542924497\n",
      "train loss:0.001489267055770775\n",
      "train loss:0.0004868083070305409\n",
      "train loss:0.004573502240890826\n",
      "train loss:0.011989943531319385\n",
      "train loss:0.0023964111835845722\n",
      "train loss:0.0029240242138751536\n",
      "train loss:0.020054583021115922\n",
      "train loss:0.0015048532295942449\n",
      "train loss:0.0004732248987269954\n",
      "train loss:0.004685584329064111\n",
      "train loss:0.00464964885019365\n",
      "train loss:0.00035256198308406943\n",
      "train loss:0.0025283514639595065\n",
      "train loss:9.110258209346467e-05\n",
      "train loss:0.0003570676479119028\n",
      "train loss:0.005392779985733841\n",
      "train loss:0.0017093144523340526\n",
      "train loss:0.001525405989241382\n",
      "train loss:0.00124929273398609\n",
      "train loss:0.008095294738659845\n",
      "train loss:0.0011994272176892402\n",
      "train loss:0.000182763468104096\n",
      "train loss:0.0030767810922671447\n",
      "train loss:0.0008823428449016616\n",
      "train loss:9.350896237736977e-05\n",
      "train loss:0.0018071643403360144\n",
      "train loss:0.0021401215951777058\n",
      "train loss:0.002509285349267865\n",
      "train loss:0.003104541996674875\n",
      "train loss:0.0024513073633622563\n",
      "train loss:0.002260724159651847\n",
      "train loss:0.017276280272586108\n",
      "train loss:0.00011655059949792709\n",
      "train loss:0.0024146630881724464\n",
      "train loss:0.0016572425252681696\n",
      "train loss:0.008668483815366595\n",
      "train loss:0.0005575180288499703\n",
      "train loss:0.00247398241219921\n",
      "train loss:0.0009578850512567702\n",
      "train loss:0.0028927427962727854\n",
      "train loss:0.0017050377065308143\n",
      "train loss:0.0002485984799451687\n",
      "train loss:0.0020582907501832666\n",
      "train loss:0.0025404137446561363\n",
      "train loss:0.0037821155968370108\n",
      "train loss:0.0020569852816291877\n",
      "train loss:0.003995717700138099\n",
      "train loss:0.0016095982839823123\n",
      "train loss:0.00797757638637533\n",
      "train loss:0.0022129918008570986\n",
      "train loss:0.004677446428536405\n",
      "train loss:0.0007389947277014595\n",
      "train loss:0.0022779378180234236\n",
      "train loss:0.004488428443363817\n",
      "train loss:0.003413060744562966\n",
      "train loss:0.0009234541122337948\n",
      "train loss:0.001540483765815705\n",
      "train loss:0.0037289004712079826\n",
      "train loss:0.003311222154884701\n",
      "train loss:0.0004427146636634242\n",
      "train loss:0.0019698361278094653\n",
      "train loss:0.0023111293409573365\n",
      "train loss:0.0010456913589479875\n",
      "train loss:0.0005375743595349218\n",
      "train loss:0.0020848494461898036\n",
      "train loss:0.0005250706280645216\n",
      "train loss:0.005806818010760488\n",
      "train loss:0.001793588461043211\n",
      "train loss:0.0020888560338133185\n",
      "train loss:0.006242498401524235\n",
      "train loss:0.0005792094423350195\n",
      "train loss:0.0013682771001070455\n",
      "train loss:0.001120562875851199\n",
      "train loss:0.001106332473228064\n",
      "train loss:0.002949809830562835\n",
      "train loss:0.0008959768701771542\n",
      "train loss:0.0009810380989489333\n",
      "train loss:0.0043073671194155784\n",
      "train loss:0.0005510260371715154\n",
      "train loss:0.0006500468582755834\n",
      "train loss:0.025565141571141786\n",
      "train loss:0.004941773231455056\n",
      "train loss:0.011273492564968292\n",
      "train loss:0.00013746247895231697\n",
      "train loss:0.0003871014907479931\n",
      "train loss:0.004515060404024823\n",
      "train loss:0.000552773370823812\n",
      "train loss:0.0063065458486849\n",
      "train loss:0.004243135015578659\n",
      "train loss:0.0026725029610103037\n",
      "train loss:0.05778734477988313\n",
      "train loss:0.003464247830696601\n",
      "train loss:0.000818298358338195\n",
      "train loss:0.0002612554638780773\n",
      "train loss:0.0011948812686792287\n",
      "train loss:0.001571299516032204\n",
      "train loss:0.0023944195030654834\n",
      "train loss:0.0012147143583912108\n",
      "train loss:0.005598916273364635\n",
      "train loss:0.008681416341800117\n",
      "train loss:0.00013486003426308382\n",
      "train loss:0.0007384213022441899\n",
      "train loss:0.005663698044167782\n",
      "train loss:0.0005569310950048135\n",
      "train loss:0.0014946907488758152\n",
      "train loss:0.004892910295607145\n",
      "train loss:0.0015147650146637357\n",
      "train loss:0.0007966722336713252\n",
      "train loss:0.0010422809594724657\n",
      "train loss:0.0008061339165935151\n",
      "train loss:0.0020725641341157387\n",
      "train loss:0.0018221575358471048\n",
      "train loss:0.02396466704868254\n",
      "train loss:9.72497417638629e-05\n",
      "train loss:0.0007003632652888887\n",
      "train loss:0.0004478267140371701\n",
      "train loss:0.0005354821821731039\n",
      "train loss:0.0010285270732431637\n",
      "train loss:0.0002159804268779514\n",
      "train loss:0.0005563141210461038\n",
      "train loss:0.00022022319776079282\n",
      "train loss:0.003266488388953626\n",
      "train loss:0.0015382539666254171\n",
      "train loss:0.011125601113729225\n",
      "train loss:0.001657621719851626\n",
      "train loss:0.002549171242562509\n",
      "train loss:0.010441236843655303\n",
      "train loss:0.0022128378147900666\n",
      "train loss:0.0071856347552876195\n",
      "train loss:0.001607629761883555\n",
      "train loss:0.002246503831289679\n",
      "train loss:0.0011891732992427991\n",
      "train loss:0.00835920101888581\n",
      "train loss:0.0013196603299770477\n",
      "train loss:0.007182182943327908\n",
      "train loss:0.0043385868883848745\n",
      "train loss:0.03203246941457902\n",
      "train loss:0.008471003298695904\n",
      "train loss:0.015476014514041871\n",
      "train loss:0.001842080343348312\n",
      "train loss:0.006796064931025792\n",
      "train loss:0.0003138588649519669\n",
      "train loss:6.829953531387289e-05\n",
      "train loss:0.011753412725018786\n",
      "train loss:0.031187958448099882\n",
      "train loss:0.013622974402669566\n",
      "train loss:0.0025227712821312776\n",
      "train loss:0.022207558695083902\n",
      "train loss:0.010273028558315262\n",
      "train loss:0.004943014225271687\n",
      "train loss:0.00022899469043941232\n",
      "train loss:0.0044596044132436076\n",
      "train loss:0.0039845133432719225\n",
      "train loss:0.007633731732525128\n",
      "train loss:0.0010255792645641755\n",
      "train loss:0.0055922121889988305\n",
      "train loss:0.0013279591653194403\n",
      "train loss:0.0007014132160254033\n",
      "train loss:0.004935011232322725\n",
      "train loss:0.004050247084189439\n",
      "train loss:0.006671062714487641\n",
      "train loss:0.007329938881606568\n",
      "train loss:0.0042975989353135555\n",
      "train loss:0.002803763640625383\n",
      "train loss:0.0013634239651094638\n",
      "train loss:0.0010874428348821188\n",
      "train loss:0.0022271856205405218\n",
      "train loss:0.0032789660402460807\n",
      "train loss:0.0022364219081036727\n",
      "train loss:0.00046799117051862083\n",
      "train loss:0.004260706356751135\n",
      "train loss:0.00038680093560628155\n",
      "train loss:0.0027270335341658754\n",
      "train loss:0.003394304632966255\n",
      "train loss:0.004651955074722977\n",
      "train loss:0.029555134439864322\n",
      "train loss:0.00028104048973568547\n",
      "train loss:0.0011580621855608912\n",
      "train loss:0.002183092259194295\n",
      "train loss:0.0035622726911088186\n",
      "train loss:0.0012856937951075216\n",
      "train loss:0.00017327805059759845\n",
      "train loss:0.006430977917921352\n",
      "train loss:0.0008305895998237658\n",
      "train loss:0.003168413497673582\n",
      "train loss:0.008300673460488772\n",
      "train loss:0.00013824889897163275\n",
      "train loss:0.00031191378268948726\n",
      "train loss:0.00397565553479708\n",
      "train loss:0.006450077384072464\n",
      "train loss:0.001706478613939009\n",
      "train loss:0.0039716483146276385\n",
      "train loss:0.002422348860558671\n",
      "train loss:0.00029649612845354775\n",
      "train loss:0.0018395196609213582\n",
      "train loss:0.0020143682255670415\n",
      "train loss:0.00046448109193232036\n",
      "train loss:0.0010679474060499212\n",
      "train loss:0.0032416884781503036\n",
      "train loss:0.0009454314914883506\n",
      "train loss:0.0002815091559443908\n",
      "train loss:0.009661754624313318\n",
      "train loss:0.0016489578641979872\n",
      "train loss:0.0018373888874264402\n",
      "train loss:0.002302917060101577\n",
      "train loss:0.045989246268899935\n",
      "train loss:0.006770064038407645\n",
      "train loss:0.0009174285624148279\n",
      "train loss:0.0003791914750714896\n",
      "train loss:0.008842464557658936\n",
      "train loss:0.00541849301715942\n",
      "train loss:0.0004380354437565656\n",
      "train loss:0.0011849809062245782\n",
      "train loss:0.001058956347568884\n",
      "train loss:0.003198218480704981\n",
      "train loss:0.01614911900186532\n",
      "train loss:0.0006426729933679196\n",
      "train loss:0.0014805617086875384\n",
      "train loss:0.05799752567960795\n",
      "train loss:0.001243011189906589\n",
      "train loss:0.0003053764818050654\n",
      "train loss:0.0015043311717670806\n",
      "train loss:0.007312163022160794\n",
      "train loss:0.0008409706340885742\n",
      "train loss:0.0033445390403178603\n",
      "train loss:0.0043018914304406965\n",
      "train loss:0.0013326113904574197\n",
      "train loss:0.0017246033860611571\n",
      "train loss:0.002200633680324402\n",
      "train loss:0.02271582009780466\n",
      "train loss:0.0010933270629348367\n",
      "train loss:0.002719606692688929\n",
      "train loss:0.0029184248086728294\n",
      "train loss:0.0023048774424200276\n",
      "train loss:0.006786473996715248\n",
      "train loss:0.0032102341104057576\n",
      "train loss:0.013235787239386392\n",
      "train loss:0.0019353919590111856\n",
      "train loss:0.0003873180195036882\n",
      "train loss:0.0007076203039959068\n",
      "train loss:0.00033361694674892954\n",
      "train loss:0.0004953174622022443\n",
      "train loss:0.0011219094281026815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0017712821900023664\n",
      "train loss:0.001378508808938457\n",
      "train loss:0.006994567304184366\n",
      "train loss:0.0015041554167240876\n",
      "train loss:0.002904750900952933\n",
      "train loss:0.00028128183358023075\n",
      "train loss:0.03906946384260071\n",
      "train loss:0.0014419182980216494\n",
      "train loss:0.0023520316967572063\n",
      "train loss:0.001222683651183066\n",
      "train loss:0.00041169933389454007\n",
      "train loss:0.0009812128645438323\n",
      "train loss:0.006736132015919604\n",
      "train loss:0.0012435232453186832\n",
      "train loss:0.0015465687207220549\n",
      "train loss:0.0010516369109714473\n",
      "train loss:0.004560872178186639\n",
      "train loss:0.0007680762838946671\n",
      "train loss:0.0005825326637017083\n",
      "train loss:0.0012289114151196165\n",
      "train loss:0.00018974664176141752\n",
      "train loss:0.0004080343482745863\n",
      "train loss:0.001116259153501391\n",
      "train loss:0.07316564900060961\n",
      "train loss:0.003087709867273213\n",
      "train loss:0.003260233744110386\n",
      "train loss:0.0010166207980322817\n",
      "train loss:0.0003236246153043098\n",
      "train loss:0.005441696740792119\n",
      "train loss:0.0030305712689693244\n",
      "train loss:0.0011323270398407705\n",
      "train loss:0.0041912096531183975\n",
      "train loss:0.0008539386106304923\n",
      "train loss:0.002513553282325806\n",
      "train loss:0.008955622718803834\n",
      "train loss:0.009337713891936356\n",
      "train loss:0.0016627036570062848\n",
      "train loss:0.005122777145126541\n",
      "train loss:0.005192542818991102\n",
      "train loss:0.004973915431338729\n",
      "train loss:0.0018519522647728157\n",
      "train loss:0.0037534242721206207\n",
      "train loss:0.0022540507739234623\n",
      "train loss:0.009731584491015133\n",
      "train loss:0.0017900470763810988\n",
      "train loss:0.003003849766479778\n",
      "train loss:0.00366634068119113\n",
      "train loss:0.002218785656526645\n",
      "train loss:0.006972359854203964\n",
      "train loss:0.0008326542815632479\n",
      "train loss:0.0010142001767899198\n",
      "train loss:0.002214777618094473\n",
      "train loss:0.004897169715232868\n",
      "train loss:0.01048162173373177\n",
      "train loss:0.0033454160455934096\n",
      "train loss:0.0013096516982687323\n",
      "train loss:0.002552856713184423\n",
      "train loss:0.0008442725614568098\n",
      "train loss:0.0013267503309556444\n",
      "train loss:0.0011509389606556139\n",
      "train loss:0.006768090608211451\n",
      "train loss:0.006557350934807146\n",
      "train loss:0.00019251446038902236\n",
      "train loss:0.0042365425898855825\n",
      "train loss:0.003424258884616788\n",
      "train loss:0.003836103939523291\n",
      "=== epoch:14, train acc:0.994, test acc:0.988 ===\n",
      "train loss:0.02069606593562741\n",
      "train loss:0.0027007976987628696\n",
      "train loss:0.0010773523012216285\n",
      "train loss:0.002888239925893133\n",
      "train loss:0.0006795148547471665\n",
      "train loss:0.003275094149677449\n",
      "train loss:0.0010669073021604648\n",
      "train loss:0.002019356766302723\n",
      "train loss:0.0006350173182556074\n",
      "train loss:0.0025415289817340915\n",
      "train loss:0.006314957810400593\n",
      "train loss:0.007583190906330543\n",
      "train loss:0.00033144639199442043\n",
      "train loss:0.001901201867698338\n",
      "train loss:0.0025968987258001676\n",
      "train loss:0.0037155096037918196\n",
      "train loss:0.0006537718618642014\n",
      "train loss:0.0006972696390398057\n",
      "train loss:0.003196799739236435\n",
      "train loss:0.0017222286625860287\n",
      "train loss:0.0019746118916594987\n",
      "train loss:0.0036485290901335575\n",
      "train loss:0.013040492762782565\n",
      "train loss:0.003611145568431484\n",
      "train loss:0.00033028091990908024\n",
      "train loss:0.0015999613784177522\n",
      "train loss:8.867305948961288e-05\n",
      "train loss:0.0009037971740465242\n",
      "train loss:0.0008245673328219454\n",
      "train loss:0.0014274126938557251\n",
      "train loss:0.0022310807981239305\n",
      "train loss:0.0009602674016064328\n",
      "train loss:0.00269536680187043\n",
      "train loss:0.002500360177763741\n",
      "train loss:0.0028175684490112083\n",
      "train loss:0.0026962689492741267\n",
      "train loss:0.0059304440836752004\n",
      "train loss:0.0020316657090891106\n",
      "train loss:0.0071495671799122595\n",
      "train loss:0.0008593342903481353\n",
      "train loss:0.004952716826116798\n",
      "train loss:0.0012211134843051784\n",
      "train loss:0.0035734261794305223\n",
      "train loss:0.004271544264511218\n",
      "train loss:0.002824462784351788\n",
      "train loss:0.0003451542745960271\n",
      "train loss:0.00021852367921018116\n",
      "train loss:0.00017043244099808387\n",
      "train loss:0.0032037935123349743\n",
      "train loss:0.002644194521940002\n",
      "train loss:0.00036945608040305064\n",
      "train loss:0.0004891088955780652\n",
      "train loss:0.000958158333329961\n",
      "train loss:3.849564602203938e-05\n",
      "train loss:0.006600983060823882\n",
      "train loss:0.005112215688396211\n",
      "train loss:0.0016992563333459957\n",
      "train loss:0.0014484484867064071\n",
      "train loss:0.0023358745449659343\n",
      "train loss:0.0028089164065146282\n",
      "train loss:0.0018637087666989432\n",
      "train loss:6.177686350699571e-05\n",
      "train loss:0.001807056340686129\n",
      "train loss:0.002743894137415927\n",
      "train loss:0.0008995486725528319\n",
      "train loss:0.0016265448357858352\n",
      "train loss:0.005392697604322339\n",
      "train loss:0.0006456971586318576\n",
      "train loss:0.0026011281692687677\n",
      "train loss:0.0012349908845995907\n",
      "train loss:0.00014861602432404542\n",
      "train loss:0.002295861204033035\n",
      "train loss:0.0005623381099553639\n",
      "train loss:0.0021570763278683145\n",
      "train loss:0.00026282161236766027\n",
      "train loss:0.006601694446705143\n",
      "train loss:0.0024759351621175553\n",
      "train loss:0.0002082573635968628\n",
      "train loss:0.01931544293312839\n",
      "train loss:0.001113713783148724\n",
      "train loss:0.0024775715846073504\n",
      "train loss:0.0003674917973297154\n",
      "train loss:0.0005209689789190131\n",
      "train loss:0.004279295087911347\n",
      "train loss:0.006254947019351901\n",
      "train loss:0.003317532174243137\n",
      "train loss:0.0007792966428482109\n",
      "train loss:0.0003150223739061887\n",
      "train loss:0.0006026577988913561\n",
      "train loss:0.006802036260678609\n",
      "train loss:0.0006727314005360933\n",
      "train loss:0.004838038454110231\n",
      "train loss:0.0003197513874773117\n",
      "train loss:0.005867189246627869\n",
      "train loss:0.005730307032944193\n",
      "train loss:0.0008664338358983389\n",
      "train loss:0.006721910573463862\n",
      "train loss:0.00398361717918912\n",
      "train loss:0.002579619390051155\n",
      "train loss:0.0021525974727075107\n",
      "train loss:0.0022357149998881286\n",
      "train loss:0.004040010643918453\n",
      "train loss:0.004818803788653246\n",
      "train loss:0.001336530384888282\n",
      "train loss:0.00040049324153783994\n",
      "train loss:0.001143682595528457\n",
      "train loss:0.0005528870119962444\n",
      "train loss:0.0008735955597285497\n",
      "train loss:0.000661764604212795\n",
      "train loss:0.001575222074000657\n",
      "train loss:0.016457856110083876\n",
      "train loss:0.0011760594170046094\n",
      "train loss:0.00800273971220707\n",
      "train loss:0.0015606282142309475\n",
      "train loss:7.771028226209431e-05\n",
      "train loss:0.003420907995379113\n",
      "train loss:0.0008058618302524557\n",
      "train loss:6.203051694245201e-05\n",
      "train loss:0.004044221638450143\n",
      "train loss:0.00592670463322751\n",
      "train loss:0.0017898063179314404\n",
      "train loss:0.0004707505041417439\n",
      "train loss:0.0012416477332316978\n",
      "train loss:0.0005435579945088808\n",
      "train loss:0.004026547773408312\n",
      "train loss:0.00018071551956791776\n",
      "train loss:0.004536949911714414\n",
      "train loss:0.001218412133134575\n",
      "train loss:0.00280827244413679\n",
      "train loss:0.008616306345022574\n",
      "train loss:0.0035840767200384254\n",
      "train loss:0.0007872377091783894\n",
      "train loss:0.003873416673885558\n",
      "train loss:0.003632076693393743\n",
      "train loss:0.0013778952848888424\n",
      "train loss:0.002979113804397707\n",
      "train loss:0.001996613813918343\n",
      "train loss:0.0004256821107126297\n",
      "train loss:0.0001367919599246683\n",
      "train loss:0.0014907139281617734\n",
      "train loss:0.013479391646025869\n",
      "train loss:0.001687739641913476\n",
      "train loss:0.0035401164869530433\n",
      "train loss:0.0025784731671070742\n",
      "train loss:0.001568743972017993\n",
      "train loss:0.0025259310006379944\n",
      "train loss:0.004943961895236719\n",
      "train loss:0.003087526378921328\n",
      "train loss:0.0004156283512648332\n",
      "train loss:0.0003099246214041008\n",
      "train loss:0.00022293745195832565\n",
      "train loss:0.000687103701031045\n",
      "train loss:0.0020245090655540447\n",
      "train loss:0.0003362673719404387\n",
      "train loss:0.007055824093554322\n",
      "train loss:0.00035289575226076663\n",
      "train loss:0.0003307142839703559\n",
      "train loss:0.0009222152935434787\n",
      "train loss:0.0006324506271032529\n",
      "train loss:0.002458725593211048\n",
      "train loss:0.0006379497213821654\n",
      "train loss:0.0036640169199615245\n",
      "train loss:0.0017280255866453703\n",
      "train loss:0.0005489091385835639\n",
      "train loss:0.0017803626323482922\n",
      "train loss:0.0009969491780737658\n",
      "train loss:0.001480703478336054\n",
      "train loss:0.0001815182213754355\n",
      "train loss:0.0023288737764178323\n",
      "train loss:0.0011249856330966866\n",
      "train loss:0.0015726203317165766\n",
      "train loss:0.0024733689805103323\n",
      "train loss:0.005266897817296559\n",
      "train loss:0.0007487199779603144\n",
      "train loss:0.0007523726744270169\n",
      "train loss:0.0005995938189552938\n",
      "train loss:0.00021578122659361574\n",
      "train loss:0.0026536531262816715\n",
      "train loss:0.001833171556995582\n",
      "train loss:0.0036535865401130423\n",
      "train loss:0.0025801704445926176\n",
      "train loss:0.0030577327425212776\n",
      "train loss:0.0008171665820749165\n",
      "train loss:0.004504073667504471\n",
      "train loss:0.00038344437762519076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0030515969879067635\n",
      "train loss:0.00016771608449684414\n",
      "train loss:0.0010372182710871147\n",
      "train loss:0.0001663089254001298\n",
      "train loss:0.007171016449275892\n",
      "train loss:0.0025976057548137417\n",
      "train loss:0.0006636140221537112\n",
      "train loss:0.0011176356970178298\n",
      "train loss:0.0008350167829887184\n",
      "train loss:0.02950260507623692\n",
      "train loss:0.0021712823922699844\n",
      "train loss:0.0016559012397225517\n",
      "train loss:0.0015364636803250722\n",
      "train loss:0.000517402031613762\n",
      "train loss:0.002800861771973336\n",
      "train loss:0.0004088869445119297\n",
      "train loss:0.0050832619791742984\n",
      "train loss:0.002052172398991088\n",
      "train loss:0.001918904279947023\n",
      "train loss:0.014846941964649796\n",
      "train loss:0.0018676717423762351\n",
      "train loss:0.001591619750953657\n",
      "train loss:0.0016958246665365634\n",
      "train loss:0.000326406470385728\n",
      "train loss:0.00012053082512000899\n",
      "train loss:0.0010423342708477782\n",
      "train loss:0.000955275999919385\n",
      "train loss:0.0018932482946985006\n",
      "train loss:0.02357433573024537\n",
      "train loss:0.0008162664267883102\n",
      "train loss:0.001268156219656106\n",
      "train loss:0.0037581633674850013\n",
      "train loss:0.0019443429628360424\n",
      "train loss:0.007442889115343953\n",
      "train loss:0.001274615942467478\n",
      "train loss:0.00023644515313054416\n",
      "train loss:0.0002442923714345151\n",
      "train loss:0.0017741760917258224\n",
      "train loss:0.004954528749631309\n",
      "train loss:0.0002506029651636027\n",
      "train loss:0.0011490828617552195\n",
      "train loss:0.004998245200366756\n",
      "train loss:0.0020992263897729267\n",
      "train loss:0.00065562971418773\n",
      "train loss:0.0010639291357914817\n",
      "train loss:0.0026475512114782647\n",
      "train loss:0.005067674934531564\n",
      "train loss:0.0010914064409927801\n",
      "train loss:0.0019093763194232085\n",
      "train loss:0.0013964574632450177\n",
      "train loss:0.00784182632532677\n",
      "train loss:0.008699517610087193\n",
      "train loss:0.0036779917197202693\n",
      "train loss:0.0027455643893859122\n",
      "train loss:8.491099884706775e-05\n",
      "train loss:0.0005177904832523887\n",
      "train loss:0.0019607012858054943\n",
      "train loss:0.00034642456506211566\n",
      "train loss:0.0005656630830733483\n",
      "train loss:0.0009899406600361773\n",
      "train loss:0.022679251214926845\n",
      "train loss:0.00013424355345553814\n",
      "train loss:0.004794185369588642\n",
      "train loss:0.0007336966049132454\n",
      "train loss:0.001612227038943745\n",
      "train loss:0.007026948282126751\n",
      "train loss:0.02377143163477318\n",
      "train loss:0.00014884542817957832\n",
      "train loss:0.0015584373113331795\n",
      "train loss:0.00020596136824841207\n",
      "train loss:0.008232756968212317\n",
      "train loss:0.0005879659179066298\n",
      "train loss:0.0026219495131010904\n",
      "train loss:0.008930669317569067\n",
      "train loss:0.00036746951600799516\n",
      "train loss:0.0001873555930079446\n",
      "train loss:0.0004358527987475428\n",
      "train loss:0.003174281984634223\n",
      "train loss:0.01585483026847717\n",
      "train loss:0.0004809616221569634\n",
      "train loss:0.0016604311985858524\n",
      "train loss:0.0021143487366385993\n",
      "train loss:0.001133048239837247\n",
      "train loss:0.0007458588990833778\n",
      "train loss:0.002040047054092005\n",
      "train loss:0.00048163871109161024\n",
      "train loss:0.002719522638541873\n",
      "train loss:0.0030903652560167524\n",
      "train loss:0.019900789509030365\n",
      "train loss:0.0012721098375083556\n",
      "train loss:0.001496852186394966\n",
      "train loss:0.0029485876327502948\n",
      "train loss:0.003302808397602083\n",
      "train loss:0.0008797811891525637\n",
      "train loss:0.02399923923063045\n",
      "train loss:0.0002242054069912614\n",
      "train loss:0.0031253740882434293\n",
      "train loss:0.0005033288719934382\n",
      "train loss:0.002513701378628488\n",
      "train loss:0.0007574205970062865\n",
      "train loss:0.00020454353335969667\n",
      "train loss:0.004154025805841281\n",
      "train loss:0.005470361466271622\n",
      "train loss:0.005687974775918483\n",
      "train loss:0.00519613844637074\n",
      "train loss:0.00374855001103835\n",
      "train loss:0.008308577657174757\n",
      "train loss:0.00018976588673317405\n",
      "train loss:0.0017939267205224387\n",
      "train loss:0.013832410301575511\n",
      "train loss:0.00022557907598814406\n",
      "train loss:0.0051760808382022095\n",
      "train loss:0.00024346482132010534\n",
      "train loss:0.002458639200499864\n",
      "train loss:0.0008476750362556622\n",
      "train loss:0.001066956276389286\n",
      "train loss:0.003765134650639077\n",
      "train loss:0.0003716921080957386\n",
      "train loss:0.0007649784483472543\n",
      "train loss:0.0015023977028850311\n",
      "train loss:0.0012141230456700757\n",
      "train loss:0.003296085134026931\n",
      "train loss:0.000674574317620171\n",
      "train loss:0.0016077813410215976\n",
      "train loss:0.0018769410057528893\n",
      "train loss:0.013299420119178805\n",
      "train loss:0.01892490429346993\n",
      "train loss:0.01445972303198702\n",
      "train loss:0.001536403847286823\n",
      "train loss:0.010288048105926664\n",
      "train loss:0.002244267315731696\n",
      "train loss:0.0024460322698637814\n",
      "train loss:0.0008293234270989443\n",
      "train loss:0.0016325821185396926\n",
      "train loss:0.0009220939227196278\n",
      "train loss:0.0018707820902420613\n",
      "train loss:0.0019392769204977151\n",
      "train loss:0.007416715326391349\n",
      "train loss:0.0007764377051579884\n",
      "train loss:0.0005060399511516396\n",
      "train loss:0.0050143942023141265\n",
      "train loss:0.0004376713671785315\n",
      "train loss:0.0025635701354354266\n",
      "train loss:0.001983263636995238\n",
      "train loss:0.003917455951708226\n",
      "train loss:0.001655680952464695\n",
      "train loss:0.0008363185475613421\n",
      "train loss:0.006142628408847\n",
      "train loss:0.0013060613106650745\n",
      "train loss:0.0012074645676725415\n",
      "train loss:0.0019173578446499099\n",
      "train loss:0.0015123479187184954\n",
      "train loss:0.0024592869418236115\n",
      "train loss:0.00026142905245559426\n",
      "train loss:0.0006130730763253818\n",
      "train loss:0.0011498294877266885\n",
      "train loss:0.007291680620560532\n",
      "train loss:0.003943349628838561\n",
      "train loss:0.023002534926853495\n",
      "train loss:0.0012056521511869028\n",
      "train loss:0.00040229197447814053\n",
      "train loss:0.002353450074426561\n",
      "train loss:0.006950199832940285\n",
      "train loss:0.00167506130784718\n",
      "train loss:0.00018770212316328828\n",
      "train loss:0.0015119840355526362\n",
      "train loss:0.002118607292582073\n",
      "train loss:0.0016810808828932801\n",
      "train loss:0.00044982975077793413\n",
      "train loss:0.0007444014791952991\n",
      "train loss:0.003347373064790526\n",
      "train loss:0.0002549335617756409\n",
      "train loss:0.00499185762942492\n",
      "train loss:0.002392291513379772\n",
      "train loss:0.0004163807069382007\n",
      "train loss:0.009942778904124911\n",
      "train loss:0.0002700530985682179\n",
      "train loss:0.0002779295111742915\n",
      "train loss:0.0010342618180665718\n",
      "train loss:0.0008460358864452295\n",
      "train loss:0.00042775245936741346\n",
      "train loss:0.00031184103328614433\n",
      "train loss:0.002045549798482904\n",
      "train loss:0.0011565237752795144\n",
      "train loss:0.0010665544520695965\n",
      "train loss:0.003625965586889455\n",
      "train loss:0.0006869165788145165\n",
      "train loss:0.0018029479291939553\n",
      "train loss:0.00216471268116646\n",
      "train loss:0.00010934073947880509\n",
      "train loss:0.00013770609192471795\n",
      "train loss:0.0007025087938598356\n",
      "train loss:0.001946484875478621\n",
      "train loss:0.0006640699495433173\n",
      "train loss:0.01173318751234395\n",
      "train loss:0.00217663928460585\n",
      "train loss:0.0019375757880778957\n",
      "train loss:0.001499006096358004\n",
      "train loss:0.0005617215064846246\n",
      "train loss:0.0033092550044928276\n",
      "train loss:0.0014511652442645224\n",
      "train loss:0.0008803303335238188\n",
      "train loss:0.0014800992170555377\n",
      "train loss:6.994730602641618e-05\n",
      "train loss:0.00026981353097293883\n",
      "train loss:0.0005486719816730231\n",
      "train loss:0.0006860087736523958\n",
      "train loss:0.0031811660949001884\n",
      "train loss:0.006599469004914731\n",
      "train loss:0.0009532243242922232\n",
      "train loss:0.0008383942410033143\n",
      "train loss:0.0011205070685912785\n",
      "train loss:0.0018994613538377962\n",
      "train loss:0.00029459015945200993\n",
      "train loss:0.0007708374378648501\n",
      "train loss:0.0013055581094381713\n",
      "train loss:0.00040345450645200726\n",
      "train loss:0.0006354804029955292\n",
      "train loss:0.00047356585907160813\n",
      "train loss:0.0030581254241518214\n",
      "train loss:0.0062586907667441845\n",
      "train loss:0.003252553411925495\n",
      "train loss:0.007939006196747261\n",
      "train loss:0.00046844227291949794\n",
      "train loss:0.0015698248395040353\n",
      "train loss:0.0009835015877621095\n",
      "train loss:0.0006121651067651842\n",
      "train loss:0.0005448810135538111\n",
      "train loss:0.0009470467450651867\n",
      "train loss:0.001185561473631976\n",
      "train loss:0.0011790026297298249\n",
      "train loss:0.001052566595292475\n",
      "train loss:0.000513628984434137\n",
      "train loss:0.00015977624289485764\n",
      "train loss:0.0011974115890749377\n",
      "train loss:0.002186314966457912\n",
      "train loss:0.00044222922989891494\n",
      "train loss:0.00030831351453569514\n",
      "train loss:0.0012593525815585394\n",
      "train loss:0.00013308424714864172\n",
      "train loss:0.004172485741109722\n",
      "train loss:0.0009479672773205186\n",
      "train loss:0.0010927651036156385\n",
      "train loss:0.0022196884305967658\n",
      "train loss:0.0013785372061859821\n",
      "train loss:0.0006708439864901314\n",
      "train loss:0.0005126227642163442\n",
      "train loss:0.00016113057342796936\n",
      "train loss:0.02045358208105793\n",
      "train loss:0.003235907630036268\n",
      "train loss:0.0009798996816086803\n",
      "train loss:0.0002546474694183098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014285238144552698\n",
      "train loss:0.0024501867662071347\n",
      "train loss:0.0006887340013937824\n",
      "train loss:0.0004831652577206622\n",
      "train loss:0.0022015986077829394\n",
      "train loss:0.00273772993660768\n",
      "train loss:0.00475944778913934\n",
      "train loss:0.0008398787928858465\n",
      "train loss:0.007044545353107858\n",
      "train loss:0.00047637825519374863\n",
      "train loss:0.0013921648466461902\n",
      "train loss:0.00011535838148012946\n",
      "train loss:0.00028012715860281764\n",
      "train loss:0.023688612372899053\n",
      "train loss:0.0021569073879426294\n",
      "train loss:0.00011014472596066137\n",
      "train loss:0.010909894567632883\n",
      "train loss:0.0015448284895364277\n",
      "train loss:6.606196805505619e-05\n",
      "train loss:0.0001258557245565976\n",
      "train loss:0.0011147653256744433\n",
      "train loss:0.002476852464006949\n",
      "train loss:0.006490454668888619\n",
      "train loss:0.0008328441604338174\n",
      "train loss:0.005344391282963126\n",
      "train loss:0.001501888050406867\n",
      "train loss:0.0003979723415860413\n",
      "train loss:0.002101209567848605\n",
      "train loss:0.0008273461882926709\n",
      "train loss:0.0022276828188702706\n",
      "train loss:0.001213516818626037\n",
      "train loss:0.0018251670835855596\n",
      "train loss:0.005639382379961224\n",
      "train loss:0.0002542746573994087\n",
      "train loss:0.004275311070673873\n",
      "train loss:0.00010780490559103516\n",
      "train loss:0.005004342217888991\n",
      "train loss:0.0023465475004727484\n",
      "train loss:0.00043919089389402835\n",
      "train loss:0.029747170234804398\n",
      "train loss:0.0010546769589352373\n",
      "train loss:0.0010992766975467959\n",
      "train loss:0.0012088981280667039\n",
      "train loss:0.0003018191238488007\n",
      "train loss:0.002996237264789009\n",
      "train loss:0.0012390128584228164\n",
      "train loss:0.00029820395141282366\n",
      "train loss:0.0009745127301591047\n",
      "train loss:0.0016975132258299874\n",
      "train loss:0.005779533656636958\n",
      "train loss:0.002402696469617019\n",
      "train loss:0.001473255817238491\n",
      "train loss:0.0009595754849329141\n",
      "train loss:0.00022846869993314943\n",
      "train loss:0.000660505387854297\n",
      "train loss:0.0005230169834097333\n",
      "train loss:0.005183131551786355\n",
      "train loss:0.003212015381441965\n",
      "train loss:0.004079171242147337\n",
      "train loss:0.002839986808599039\n",
      "train loss:0.0024818111884569757\n",
      "train loss:0.00010762127763870402\n",
      "train loss:0.003697158313017114\n",
      "train loss:0.0004203119377971394\n",
      "train loss:0.00044357002708138375\n",
      "train loss:0.018644971017105057\n",
      "train loss:0.0009363627151679375\n",
      "train loss:0.0012117595446886613\n",
      "train loss:0.0006816459325997469\n",
      "train loss:0.007361405919054853\n",
      "train loss:0.0018623113625473764\n",
      "train loss:0.0032815536036583277\n",
      "train loss:0.0007496952497464587\n",
      "train loss:0.0014096094670035988\n",
      "train loss:0.0038798827766757566\n",
      "train loss:0.0006962802717700545\n",
      "train loss:0.0007965490598764135\n",
      "train loss:0.003558699839359896\n",
      "train loss:0.0007731177775192328\n",
      "train loss:0.0010629239799086077\n",
      "train loss:0.001016946463577011\n",
      "train loss:0.009030189987080243\n",
      "train loss:0.0013305604290646026\n",
      "train loss:0.003173649429224615\n",
      "train loss:0.015211498112679259\n",
      "train loss:0.0007558382285852159\n",
      "train loss:0.00038205529613982264\n",
      "train loss:0.001790948866751341\n",
      "train loss:0.0003062258401256011\n",
      "train loss:0.0003909488636366097\n",
      "train loss:0.0013513105685698298\n",
      "train loss:0.00038611816559974157\n",
      "train loss:0.004964391725205039\n",
      "train loss:0.0008161210241392747\n",
      "train loss:0.002633011537345595\n",
      "train loss:0.006077822149666568\n",
      "train loss:0.0008958388742606563\n",
      "train loss:0.002084275785401898\n",
      "train loss:0.006103672434465185\n",
      "train loss:0.0013639668385706713\n",
      "train loss:0.0021517087022726506\n",
      "train loss:0.002358807368180336\n",
      "train loss:0.005258919210113672\n",
      "train loss:0.0014642099088578876\n",
      "train loss:0.004000785401879947\n",
      "train loss:0.00047868364777378045\n",
      "train loss:0.001312278519437273\n",
      "train loss:0.0009562131732734004\n",
      "train loss:0.0014950484600427148\n",
      "train loss:0.0060850721396851016\n",
      "train loss:0.000596888371987847\n",
      "train loss:0.00041588438351690795\n",
      "train loss:0.0004560010521208794\n",
      "train loss:0.0022768539023727526\n",
      "train loss:0.00023425173205255133\n",
      "train loss:0.005164409345569176\n",
      "train loss:0.0011961783702711228\n",
      "train loss:0.0017211705064237603\n",
      "train loss:0.0002645384729931249\n",
      "train loss:0.0016404462625079009\n",
      "train loss:0.0022821126878465633\n",
      "train loss:0.0006526546564502126\n",
      "train loss:0.0011921174172515286\n",
      "train loss:0.003358889426373054\n",
      "train loss:0.011489467571691997\n",
      "train loss:0.004263963421413726\n",
      "train loss:0.00044387334586845227\n",
      "train loss:0.0009975288535231709\n",
      "train loss:0.0006237494656863153\n",
      "train loss:0.0019357282856720156\n",
      "train loss:0.0018008667577433194\n",
      "train loss:0.00037344280554425736\n",
      "train loss:0.0011215167869218976\n",
      "train loss:0.005703348348843471\n",
      "train loss:0.0041150775151806065\n",
      "train loss:0.000886246542193643\n",
      "train loss:0.0010401020935102865\n",
      "train loss:0.0028062448569505477\n",
      "train loss:0.0008712738889003035\n",
      "train loss:0.013186193746321451\n",
      "train loss:0.00046108791694139645\n",
      "train loss:0.00100790632473409\n",
      "train loss:0.005660592326488143\n",
      "train loss:0.0005558394930940253\n",
      "train loss:0.00074544008013947\n",
      "train loss:0.0038755245270413003\n",
      "train loss:0.000715842945175222\n",
      "train loss:0.07376729203904123\n",
      "train loss:0.0017063537558547177\n",
      "train loss:0.0006409320937214966\n",
      "train loss:0.0027443587806537484\n",
      "train loss:0.005130609750111926\n",
      "train loss:0.02507451761506246\n",
      "train loss:0.0007504857470469145\n",
      "train loss:0.0007934967982953759\n",
      "train loss:0.0012044781838722392\n",
      "train loss:0.004113358888301069\n",
      "train loss:0.0024257854931565735\n",
      "train loss:0.0002193656488943158\n",
      "train loss:0.0017441621971610193\n",
      "train loss:0.006124775255764283\n",
      "train loss:0.00220233336911182\n",
      "train loss:0.0025094527754711583\n",
      "=== epoch:15, train acc:0.999, test acc:0.989 ===\n",
      "train loss:0.006660956444907155\n",
      "train loss:0.0012388307908058358\n",
      "train loss:0.0022101264057710576\n",
      "train loss:0.004815434925347256\n",
      "train loss:0.0009098367973815493\n",
      "train loss:0.001796110939698001\n",
      "train loss:0.0022234242660470332\n",
      "train loss:0.012642770270856512\n",
      "train loss:0.0018306681262809717\n",
      "train loss:0.0012356609912301745\n",
      "train loss:0.0014263259359987462\n",
      "train loss:0.0008035488840912594\n",
      "train loss:0.00043452395613697534\n",
      "train loss:0.0001554900409663255\n",
      "train loss:0.0121777826336357\n",
      "train loss:0.003318484725213302\n",
      "train loss:0.0023336537509172843\n",
      "train loss:0.0031568839661020452\n",
      "train loss:0.0015824294521812835\n",
      "train loss:0.000949188295995337\n",
      "train loss:0.0016516832679714642\n",
      "train loss:0.0030283573527415007\n",
      "train loss:0.002749670343927743\n",
      "train loss:0.001973863365708825\n",
      "train loss:0.0001939374441197381\n",
      "train loss:0.0018169528946124615\n",
      "train loss:0.008712511307606297\n",
      "train loss:0.000282177629207902\n",
      "train loss:0.002573045762556175\n",
      "train loss:0.0014932116500201212\n",
      "train loss:0.0012365931148678691\n",
      "train loss:0.0001941757459382982\n",
      "train loss:0.004036656808512753\n",
      "train loss:0.0003856947348666216\n",
      "train loss:0.002901629832544526\n",
      "train loss:0.002864111555241294\n",
      "train loss:0.00225268428829544\n",
      "train loss:0.00014954060482308176\n",
      "train loss:0.0002629175850988839\n",
      "train loss:0.000372366965706512\n",
      "train loss:7.809480401962501e-05\n",
      "train loss:0.0018633598360490084\n",
      "train loss:0.0010940266516191494\n",
      "train loss:0.004831346723614338\n",
      "train loss:0.0011128943256845114\n",
      "train loss:0.0016340114976390555\n",
      "train loss:0.00036453155292460256\n",
      "train loss:0.0013772303070941857\n",
      "train loss:0.00019060761712943886\n",
      "train loss:0.0018982668942865402\n",
      "train loss:0.000999586363148583\n",
      "train loss:0.0048219464937800695\n",
      "train loss:0.001138652627140614\n",
      "train loss:0.013585105562432453\n",
      "train loss:0.000291528368118373\n",
      "train loss:0.0005669948817991086\n",
      "train loss:0.001609793816668625\n",
      "train loss:0.004411789828492444\n",
      "train loss:0.0003864170299459955\n",
      "train loss:0.0005804807829739956\n",
      "train loss:0.002304660634414013\n",
      "train loss:0.0017657945535475325\n",
      "train loss:0.000717334124852487\n",
      "train loss:0.001242358590750145\n",
      "train loss:0.0037329107422609054\n",
      "train loss:0.0012056830523830223\n",
      "train loss:0.004218715692284277\n",
      "train loss:0.0013819802518216693\n",
      "train loss:0.00013698222015402415\n",
      "train loss:0.0005322213228257924\n",
      "train loss:0.0004517626626592448\n",
      "train loss:0.0011721442016181531\n",
      "train loss:0.0012929769522547737\n",
      "train loss:0.002328943308008222\n",
      "train loss:0.0005240763561125204\n",
      "train loss:0.002279333022773978\n",
      "train loss:0.000479812970171992\n",
      "train loss:0.00023267794583201228\n",
      "train loss:0.0011297481908434908\n",
      "train loss:0.00205441864325004\n",
      "train loss:0.0006637835293052837\n",
      "train loss:0.007901704595122787\n",
      "train loss:0.0025744128676432406\n",
      "train loss:0.0008029738175297854\n",
      "train loss:0.0010470274040503583\n",
      "train loss:0.0025434009796948655\n",
      "train loss:0.00028017333952044197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00020850104983295356\n",
      "train loss:0.0004591557714023238\n",
      "train loss:0.0003289319790547159\n",
      "train loss:0.00022348007580866874\n",
      "train loss:0.02143914917794517\n",
      "train loss:0.0022210903429721028\n",
      "train loss:0.002297269531948835\n",
      "train loss:0.00039863973520439585\n",
      "train loss:0.000240483330085872\n",
      "train loss:0.0017174609624295905\n",
      "train loss:0.001389862364510232\n",
      "train loss:0.00051460244031469\n",
      "train loss:0.000709481236967184\n",
      "train loss:0.0019590055554805775\n",
      "train loss:0.0020132614990702887\n",
      "train loss:0.0001305315730977517\n",
      "train loss:0.0001990645511802705\n",
      "train loss:0.004906166316781757\n",
      "train loss:0.0012230984989557493\n",
      "train loss:0.0005602932901489419\n",
      "train loss:0.0002639098568531547\n",
      "train loss:0.001507843376500756\n",
      "train loss:0.0007831740714821898\n",
      "train loss:0.0003749648846826377\n",
      "train loss:0.0010231764892995323\n",
      "train loss:0.0014634192994149226\n",
      "train loss:0.0024882472838150035\n",
      "train loss:0.0005487333272281712\n",
      "train loss:0.00815605849046478\n",
      "train loss:0.0003479824553875166\n",
      "train loss:0.0010191492798188994\n",
      "train loss:0.0003270568059391049\n",
      "train loss:0.0021886337945154592\n",
      "train loss:0.0009845533970299226\n",
      "train loss:0.0009852002210947077\n",
      "train loss:0.00025388344550018605\n",
      "train loss:0.0023948376979207524\n",
      "train loss:0.0022643689411897135\n",
      "train loss:0.0034474682906786257\n",
      "train loss:0.0009174389229278716\n",
      "train loss:0.0023302331548023143\n",
      "train loss:0.0016131592814696107\n",
      "train loss:0.00026655541503732197\n",
      "train loss:0.0002728587567139786\n",
      "train loss:0.0023107334927224264\n",
      "train loss:0.0001469698829178438\n",
      "train loss:7.601783149152978e-05\n",
      "train loss:0.002162514983176783\n",
      "train loss:0.0020340898179184836\n",
      "train loss:0.00033937235637553824\n",
      "train loss:0.00013517920872091718\n",
      "train loss:0.009102142521932638\n",
      "train loss:0.0005494437831879885\n",
      "train loss:0.0006448644552188452\n",
      "train loss:0.007884341270009665\n",
      "train loss:0.00036052676750553044\n",
      "train loss:0.00466503556055699\n",
      "train loss:0.0032850674630977633\n",
      "train loss:0.0001527444532925603\n",
      "train loss:0.0009521074769577652\n",
      "train loss:0.001631230736277957\n",
      "train loss:0.001928275734537088\n",
      "train loss:0.0027513576756975056\n",
      "train loss:0.0012276190848090763\n",
      "train loss:0.00041163500632294465\n",
      "train loss:0.00031102021301109326\n",
      "train loss:0.000106661680560922\n",
      "train loss:0.0009575178853894157\n",
      "train loss:0.0004739268633130325\n",
      "train loss:0.00034821387670017144\n",
      "train loss:0.000762183794684393\n",
      "train loss:0.06961589923230338\n",
      "train loss:0.0034339711963231444\n",
      "train loss:0.0010502481949785957\n",
      "train loss:0.002531922486117111\n",
      "train loss:0.0003218004170632292\n",
      "train loss:0.0009183077197617541\n",
      "train loss:0.004169789965138328\n",
      "train loss:0.0001949103028694582\n",
      "train loss:0.0009685731182696944\n",
      "train loss:0.0002469531865049027\n",
      "train loss:0.001359966608150211\n",
      "train loss:0.0009314233537109985\n",
      "train loss:0.001404524565538292\n",
      "train loss:0.0006959407936286965\n",
      "train loss:0.0006893928056897504\n",
      "train loss:0.00033329361242475465\n",
      "train loss:0.0024485461045040814\n",
      "train loss:5.448132189049242e-05\n",
      "train loss:0.0004202100998345007\n",
      "train loss:0.0014885608549398625\n",
      "train loss:0.0002278609858053084\n",
      "train loss:0.002784826667863534\n",
      "train loss:0.00020214220369210175\n",
      "train loss:0.000865661033408195\n",
      "train loss:0.0002488365446350274\n",
      "train loss:0.002538804063293396\n",
      "train loss:0.00017079223963416723\n",
      "train loss:0.03171544748505778\n",
      "train loss:0.0001854710027758927\n",
      "train loss:0.00031616462820231945\n",
      "train loss:0.001628226049882318\n",
      "train loss:0.00021038738960528478\n",
      "train loss:0.0016977156238340437\n",
      "train loss:0.0012184399429209713\n",
      "train loss:0.003547074501636212\n",
      "train loss:0.00040021059992228174\n",
      "train loss:0.0006899567701696653\n",
      "train loss:0.002120413775827913\n",
      "train loss:4.453203376325141e-05\n",
      "train loss:0.0011713716147640932\n",
      "train loss:0.003845440293875958\n",
      "train loss:0.002329632206900015\n",
      "train loss:0.0017542761151810506\n",
      "train loss:0.0004558481801121334\n",
      "train loss:0.0009303194084779521\n",
      "train loss:0.0015563454979680056\n",
      "train loss:0.0011526253879904714\n",
      "train loss:0.00016904406463128606\n",
      "train loss:0.00047131271403546876\n",
      "train loss:0.00046010956198985444\n",
      "train loss:0.0007842504740623534\n",
      "train loss:0.0003244339583856575\n",
      "train loss:0.0003695632029281558\n",
      "train loss:0.0011909325835244824\n",
      "train loss:0.001192219411026275\n",
      "train loss:4.9665352168924895e-05\n",
      "train loss:0.00048491522255576444\n",
      "train loss:0.001181742939945488\n",
      "train loss:0.0007580327610411222\n",
      "train loss:0.002785667889303765\n",
      "train loss:0.00012906268343319713\n",
      "train loss:0.0013343355786943041\n",
      "train loss:0.0005447494579751154\n",
      "train loss:0.0008396414467796947\n",
      "train loss:0.0006969422784080431\n",
      "train loss:0.002218387876499796\n",
      "train loss:0.00020301640150995206\n",
      "train loss:0.01688767663228258\n",
      "train loss:0.0021255157860285336\n",
      "train loss:0.00021179708227646928\n",
      "train loss:0.003565823380776217\n",
      "train loss:0.0003641466604409844\n",
      "train loss:0.0013442586863813195\n",
      "train loss:0.0009303407351567438\n",
      "train loss:0.00010259813113066223\n",
      "train loss:0.0002517881866614906\n",
      "train loss:0.00048804607541433847\n",
      "train loss:0.0012981356805711179\n",
      "train loss:0.005673424841868796\n",
      "train loss:0.00028774302760912367\n",
      "train loss:0.0027853333510781337\n",
      "train loss:0.0009207843943488676\n",
      "train loss:0.004446335536283794\n",
      "train loss:0.0019917894687310213\n",
      "train loss:0.0005213360304830732\n",
      "train loss:0.00020727656839998555\n",
      "train loss:0.0009567365072514276\n",
      "train loss:0.0004993433418102335\n",
      "train loss:0.0004668848210756235\n",
      "train loss:0.0001974943542660484\n",
      "train loss:0.004305246020915448\n",
      "train loss:0.0005219775597893614\n",
      "train loss:0.0006763882268652491\n",
      "train loss:0.0013758763838095911\n",
      "train loss:0.0012881776299959362\n",
      "train loss:0.000370167600086661\n",
      "train loss:0.0006126926607533143\n",
      "train loss:0.0032700240610661997\n",
      "train loss:0.00040362576348172853\n",
      "train loss:0.00013726555867113075\n",
      "train loss:0.00043615324079009484\n",
      "train loss:0.0017883891106109074\n",
      "train loss:0.001961165019505369\n",
      "train loss:0.0008222839220397358\n",
      "train loss:0.0012737121375685167\n",
      "train loss:0.0004887316988171838\n",
      "train loss:0.001298162085618407\n",
      "train loss:0.0007162888330784225\n",
      "train loss:0.004408010701170937\n",
      "train loss:0.0010673357285030166\n",
      "train loss:0.0009872225584558617\n",
      "train loss:0.0004641680383998829\n",
      "train loss:0.0009220402743671781\n",
      "train loss:0.0023850125332514236\n",
      "train loss:0.001331758522154563\n",
      "train loss:0.000628052520289531\n",
      "train loss:0.0007712891775094435\n",
      "train loss:5.216270969074347e-05\n",
      "train loss:0.0002426629042340672\n",
      "train loss:0.001948372097798178\n",
      "train loss:0.0031226241314948966\n",
      "train loss:0.004734206032526319\n",
      "train loss:0.0011164717060839083\n",
      "train loss:3.1406204697160525e-05\n",
      "train loss:0.010220641629709426\n",
      "train loss:0.0029715776908670905\n",
      "train loss:0.0019474005008517426\n",
      "train loss:0.0019058015634465103\n",
      "train loss:0.00031860602136297343\n",
      "train loss:0.0005030245314653816\n",
      "train loss:8.531581724138382e-05\n",
      "train loss:0.0008701651192228706\n",
      "train loss:0.001426165046588094\n",
      "train loss:0.00024232418500079163\n",
      "train loss:0.004316901667238752\n",
      "train loss:0.033161258754473545\n",
      "train loss:0.0006942140826622146\n",
      "train loss:0.0014998782176951855\n",
      "train loss:0.0035405224218031535\n",
      "train loss:0.0005630519974832665\n",
      "train loss:0.00042929916569323887\n",
      "train loss:0.0007619759830453501\n",
      "train loss:0.0037044628601281384\n",
      "train loss:0.0002825187893091983\n",
      "train loss:0.00045123561204022495\n",
      "train loss:0.00048802587945050423\n",
      "train loss:0.001916135519108035\n",
      "train loss:0.0032911699560803083\n",
      "train loss:0.0002717010478054328\n",
      "train loss:0.014541557645978906\n",
      "train loss:0.0034900800287980664\n",
      "train loss:0.0006565250199330189\n",
      "train loss:0.0007398474705789388\n",
      "train loss:0.0006399735534531833\n",
      "train loss:0.004761714702398119\n",
      "train loss:0.0027206076949381035\n",
      "train loss:0.0005511775422308507\n",
      "train loss:0.0021040557081401816\n",
      "train loss:0.0020065991484746345\n",
      "train loss:0.003701337464285874\n",
      "train loss:0.0017800208180427995\n",
      "train loss:0.005957728216638864\n",
      "train loss:0.0024367598997564934\n",
      "train loss:0.0017605748559931986\n",
      "train loss:0.0015651114186913647\n",
      "train loss:0.0017946323578755263\n",
      "train loss:0.0010810924031877398\n",
      "train loss:0.0005316852704263798\n",
      "train loss:0.0009573898185072807\n",
      "train loss:0.005807698232159268\n",
      "train loss:0.00017405623521183023\n",
      "train loss:0.0001529455386294015\n",
      "train loss:0.0019391531293299505\n",
      "train loss:0.0005662661018789647\n",
      "train loss:0.0009078789814008063\n",
      "train loss:0.001555907374749101\n",
      "train loss:0.00623635789383292\n",
      "train loss:0.00018664964080839817\n",
      "train loss:0.0021778407253803447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:7.494096754075572e-05\n",
      "train loss:0.00048434186636243037\n",
      "train loss:0.0054291960830457064\n",
      "train loss:0.0018248184582636082\n",
      "train loss:0.006392020378037429\n",
      "train loss:0.0039904671513534265\n",
      "train loss:0.0007426295480961498\n",
      "train loss:0.0011662671466653245\n",
      "train loss:0.005847848842742552\n",
      "train loss:0.0018439270571761006\n",
      "train loss:0.00015425562565269768\n",
      "train loss:0.0005133255845074915\n",
      "train loss:0.00013878155242396515\n",
      "train loss:0.0037055853053059827\n",
      "train loss:0.0008320463294609708\n",
      "train loss:0.005227495607675568\n",
      "train loss:0.012611021049891945\n",
      "train loss:0.0020832534860674282\n",
      "train loss:0.002916771375297427\n",
      "train loss:0.0020471432916807698\n",
      "train loss:0.0011514335934989584\n",
      "train loss:0.01267347972627175\n",
      "train loss:0.0029141390784555975\n",
      "train loss:0.006234794502377563\n",
      "train loss:0.0005726122659607129\n",
      "train loss:0.0005239181644716234\n",
      "train loss:0.0008037443781035956\n",
      "train loss:0.003232703159921542\n",
      "train loss:0.002158593045092311\n",
      "train loss:0.01028132450965786\n",
      "train loss:0.004565726308867048\n",
      "train loss:0.0014805636381979906\n",
      "train loss:0.0019505662483284179\n",
      "train loss:0.001610524751049207\n",
      "train loss:8.691023495373914e-05\n",
      "train loss:0.008453652643577232\n",
      "train loss:0.021082137325559986\n",
      "train loss:0.0007567605559828902\n",
      "train loss:0.0012362836921319812\n",
      "train loss:0.0005287939921443353\n",
      "train loss:0.00142966915297455\n",
      "train loss:0.0002549005530908315\n",
      "train loss:0.0012257797970404182\n",
      "train loss:0.0010730564661874979\n",
      "train loss:0.0017281616778840245\n",
      "train loss:0.0020753613182742463\n",
      "train loss:0.001583079245143169\n",
      "train loss:0.0014653915972947823\n",
      "train loss:0.0003783916512465576\n",
      "train loss:0.0009948866507935815\n",
      "train loss:0.00022938190491716937\n",
      "train loss:0.0005738398821340323\n",
      "train loss:0.0013650616672717488\n",
      "train loss:0.005304958894182865\n",
      "train loss:0.01940906910880373\n",
      "train loss:0.0030500108902208546\n",
      "train loss:0.004452207914739959\n",
      "train loss:0.0010322278697544262\n",
      "train loss:0.00027083113517415623\n",
      "train loss:0.002252649298451631\n",
      "train loss:0.0012002186746307422\n",
      "train loss:0.004674507107929989\n",
      "train loss:0.001981479504977062\n",
      "train loss:0.0017655197689539505\n",
      "train loss:0.0011648038105309439\n",
      "train loss:0.0005470921611931251\n",
      "train loss:0.0004375510406897897\n",
      "train loss:0.00013571710992919337\n",
      "train loss:0.0011226704953434083\n",
      "train loss:0.00887946252568093\n",
      "train loss:0.004551888453951804\n",
      "train loss:0.0013927189354925476\n",
      "train loss:0.006860422881482635\n",
      "train loss:0.0014159491973888007\n",
      "train loss:9.17229386195512e-05\n",
      "train loss:0.0007626951839607457\n",
      "train loss:0.0018157859459389774\n",
      "train loss:0.0015827825143572172\n",
      "train loss:0.011299387722414747\n",
      "train loss:0.0027784744928754483\n",
      "train loss:0.000968861644855689\n",
      "train loss:0.008752683559678972\n",
      "train loss:0.00216700338285467\n",
      "train loss:0.0006700197466955672\n",
      "train loss:0.007262496616552866\n",
      "train loss:0.0037420738811450066\n",
      "train loss:0.004428085299640377\n",
      "train loss:0.00016430219202813665\n",
      "train loss:0.0005704472074345299\n",
      "train loss:0.019562270481498802\n",
      "train loss:0.007230428271550226\n",
      "train loss:0.0425574141835844\n",
      "train loss:0.0004862148667575697\n",
      "train loss:0.004790710928542353\n",
      "train loss:0.0008957594098504651\n",
      "train loss:0.0022665171173000824\n",
      "train loss:0.0035199118816074165\n",
      "train loss:0.0003530260781530082\n",
      "train loss:0.0014066858696468573\n",
      "train loss:0.001814208510951179\n",
      "train loss:0.005955128967129197\n",
      "train loss:0.0008572236455922192\n",
      "train loss:0.0027608370662344406\n",
      "train loss:0.001374794246099894\n",
      "train loss:0.0020223291360682797\n",
      "train loss:0.009286763870480347\n",
      "train loss:0.0029292798570541884\n",
      "train loss:0.0005983781682056432\n",
      "train loss:0.008852412809454624\n",
      "train loss:0.004097797569124259\n",
      "train loss:0.0021245728893412898\n",
      "train loss:0.0029376806736083516\n",
      "train loss:0.0019434903728765733\n",
      "train loss:0.0022608782190222773\n",
      "train loss:0.0002648967518136809\n",
      "train loss:0.003989185235255165\n",
      "train loss:0.005847741853443027\n",
      "train loss:0.00011732703119195383\n",
      "train loss:0.0007936693881857326\n",
      "train loss:0.01249612254772115\n",
      "train loss:0.0021400116316035523\n",
      "train loss:0.00281404849529305\n",
      "train loss:0.0011891128613095302\n",
      "train loss:0.0007047947178061371\n",
      "train loss:0.002232379664501986\n",
      "train loss:0.001857669959601097\n",
      "train loss:0.004295984039380808\n",
      "train loss:0.0010949572527651243\n",
      "train loss:0.0027825483939404277\n",
      "train loss:0.0002260221319198125\n",
      "train loss:0.002110655430159222\n",
      "train loss:0.000119120942690369\n",
      "train loss:0.00013476493485886133\n",
      "train loss:0.007067682382039806\n",
      "train loss:0.0001751155217817696\n",
      "train loss:0.0007184994775246442\n",
      "train loss:0.0005841123864880557\n",
      "train loss:0.01580247142021326\n",
      "train loss:0.002974324841690343\n",
      "train loss:0.0019407028427221023\n",
      "train loss:0.0014062928361676405\n",
      "train loss:0.004809934580825424\n",
      "train loss:0.00044101948632145697\n",
      "train loss:0.0009290859340908158\n",
      "train loss:0.000727477931678881\n",
      "train loss:0.0036829560001551504\n",
      "train loss:4.958416433184799e-05\n",
      "train loss:0.0015197641050905826\n",
      "train loss:0.000535691754393016\n",
      "train loss:0.002474264887831942\n",
      "train loss:0.001582249829324932\n",
      "train loss:8.967842280187513e-05\n",
      "train loss:0.00014955622836617822\n",
      "train loss:0.0008415170508765251\n",
      "train loss:0.0026154755235468334\n",
      "train loss:0.0018237738369160273\n",
      "train loss:0.011265481435803302\n",
      "train loss:0.0007506540094337536\n",
      "train loss:0.0007033584584606743\n",
      "train loss:0.0034714078513184473\n",
      "train loss:0.008992688625121937\n",
      "train loss:0.0028243773810139555\n",
      "train loss:0.0008580862704456837\n",
      "train loss:0.0005984744218202001\n",
      "train loss:0.0018421947030295201\n",
      "train loss:0.014588285410673505\n",
      "train loss:0.0005410487255741208\n",
      "train loss:0.0006131419187865376\n",
      "train loss:0.0019236912635368563\n",
      "train loss:0.0017436837794945433\n",
      "train loss:0.004002874569916145\n",
      "train loss:0.0012641878694233668\n",
      "train loss:0.0023447005066494146\n",
      "train loss:0.0012452764271242887\n",
      "train loss:0.0024318697580055213\n",
      "train loss:0.0011228559060676734\n",
      "train loss:0.0019726803578522926\n",
      "train loss:0.0009905394644195659\n",
      "train loss:0.0015305501300776248\n",
      "train loss:0.0025052557349205117\n",
      "train loss:0.012635257485124032\n",
      "train loss:0.0002296497998587021\n",
      "train loss:0.0017525284372091195\n",
      "train loss:0.0014732668469897457\n",
      "train loss:0.0004018968879018604\n",
      "train loss:0.0012212111104913978\n",
      "train loss:0.0015930926962160433\n",
      "train loss:9.797767654340868e-05\n",
      "train loss:0.0013676794805075403\n",
      "train loss:0.00020847891734442986\n",
      "train loss:0.007180697874197727\n",
      "train loss:0.0001071580209259227\n",
      "train loss:0.00046142903724054346\n",
      "train loss:0.003779437520844251\n",
      "train loss:0.0028985564592568114\n",
      "train loss:0.0004572499786270602\n",
      "train loss:0.0017662636376923684\n",
      "train loss:0.0009611634940656392\n",
      "train loss:0.0005576860939759397\n",
      "train loss:0.000378260891649318\n",
      "train loss:0.0025365006387403676\n",
      "train loss:0.0035785163492583023\n",
      "train loss:0.0023637992306753215\n",
      "train loss:0.00014714905458364016\n",
      "train loss:0.0017142253030227993\n",
      "train loss:0.0019609647042904844\n",
      "train loss:0.0021603785370725346\n",
      "train loss:0.002954888305058398\n",
      "train loss:0.0009336973378056028\n",
      "train loss:0.0004863024631879476\n",
      "train loss:0.00448943870289812\n",
      "train loss:0.0050084547726521236\n",
      "train loss:0.0002005735997328298\n",
      "train loss:0.007061222784779326\n",
      "train loss:0.0006803091999961344\n",
      "train loss:0.000677922441590545\n",
      "train loss:4.1867876206108866e-05\n",
      "train loss:0.00014846225911487916\n",
      "train loss:0.00023322396561112902\n",
      "train loss:7.931306992683223e-05\n",
      "train loss:0.0016647180436103748\n",
      "train loss:0.0007425977792398299\n",
      "train loss:0.001404956052260572\n",
      "train loss:0.0010221339898494023\n",
      "train loss:0.0065673158360509765\n",
      "train loss:0.002112755572887199\n",
      "train loss:0.00341982988758532\n",
      "train loss:0.0026009427119656754\n",
      "train loss:0.0006575146276362048\n",
      "train loss:0.010956887346070778\n",
      "train loss:0.0006030160063953336\n",
      "train loss:0.0010926549381804112\n",
      "train loss:8.370646334956662e-05\n",
      "train loss:0.00048666974195273424\n",
      "train loss:0.0019141218696217754\n",
      "train loss:0.0013375426337550505\n",
      "train loss:0.0025138917213821162\n",
      "train loss:0.00023610490874923946\n",
      "train loss:0.010497553713645606\n",
      "train loss:0.0007304904169911538\n",
      "train loss:0.0016994384056182674\n",
      "train loss:0.0005857802694086402\n",
      "train loss:0.0055413531838205046\n",
      "train loss:0.0031772119592042964\n",
      "train loss:0.0003552840317772872\n",
      "train loss:0.0026840435532801197\n",
      "train loss:0.00020815097437131623\n",
      "train loss:0.00042343247745683926\n",
      "train loss:0.004920055309430588\n",
      "train loss:0.0002291857982840884\n",
      "train loss:0.0014785801832549216\n",
      "train loss:0.015653055015540773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0030423084758425837\n",
      "train loss:8.080948104424286e-05\n",
      "train loss:2.8335265267952883e-05\n",
      "train loss:0.0013190985800584237\n",
      "train loss:0.0008568732398333562\n",
      "train loss:0.005663326438709993\n",
      "train loss:0.00070331226591367\n",
      "train loss:0.0018034998264721653\n",
      "train loss:0.038096297756347444\n",
      "train loss:0.001571126412174466\n",
      "train loss:0.0141364482908174\n",
      "=== epoch:16, train acc:0.998, test acc:0.988 ===\n",
      "train loss:0.002217280558735357\n",
      "train loss:0.000506642349981264\n",
      "train loss:0.0004782202168005764\n",
      "train loss:0.0021404395931931826\n",
      "train loss:0.0023489100792235774\n",
      "train loss:0.00070975429824744\n",
      "train loss:0.00398401411830907\n",
      "train loss:0.0031009619522737036\n",
      "train loss:0.030136181615448572\n",
      "train loss:0.002997279592575284\n",
      "train loss:0.012554886874049605\n",
      "train loss:0.0071180181548311\n",
      "train loss:0.011864985293879875\n",
      "train loss:0.02431541811776815\n",
      "train loss:0.003079165722830428\n",
      "train loss:0.0007390430602950526\n",
      "train loss:0.0036958474171213036\n",
      "train loss:0.000816565415438351\n",
      "train loss:0.0001107687757330748\n",
      "train loss:0.00033071239644811597\n",
      "train loss:0.06597192326965433\n",
      "train loss:0.00024186052826578408\n",
      "train loss:0.0011214020011682576\n",
      "train loss:0.0008820955411344357\n",
      "train loss:0.0011637196190146864\n",
      "train loss:0.0010201417884905025\n",
      "train loss:0.0009785493961988335\n",
      "train loss:0.001297351580945638\n",
      "train loss:0.00105598057581455\n",
      "train loss:0.0007851002357839846\n",
      "train loss:0.0001637349818002667\n",
      "train loss:0.0042104494746704095\n",
      "train loss:0.00025384593105055495\n",
      "train loss:0.0009675033794363028\n",
      "train loss:0.005510684476181829\n",
      "train loss:0.0005421105818454043\n",
      "train loss:0.00037821451068530127\n",
      "train loss:0.005872489604828639\n",
      "train loss:0.0018094694629710373\n",
      "train loss:0.0015992822018326787\n",
      "train loss:0.0024165527993476755\n",
      "train loss:0.0012669294864563968\n",
      "train loss:0.00027763469876393264\n",
      "train loss:0.0029800289602853703\n",
      "train loss:6.171687928455026e-05\n",
      "train loss:0.009629855721515278\n",
      "train loss:0.0008455526154514863\n",
      "train loss:0.0002698987003947244\n",
      "train loss:0.0006342435367162007\n",
      "train loss:0.00042939731037954973\n",
      "train loss:0.000517574339196585\n",
      "train loss:0.0006679674518567983\n",
      "train loss:0.0002729467456092978\n",
      "train loss:0.00025035903228270057\n",
      "train loss:1.6902885414476836e-05\n",
      "train loss:0.005094922012231547\n",
      "train loss:0.0012293728772202648\n",
      "train loss:0.003521100432471776\n",
      "train loss:0.00011354508382392679\n",
      "train loss:0.005230976565953464\n",
      "train loss:0.00029360191952866046\n",
      "train loss:0.0001065760392906293\n",
      "train loss:0.0016376762199988276\n",
      "train loss:0.0013190662770333175\n",
      "train loss:0.00019799349610017804\n",
      "train loss:0.0031069687334082225\n",
      "train loss:0.0011168236389007594\n",
      "train loss:0.004205344547450803\n",
      "train loss:0.0005637490362745604\n",
      "train loss:0.0005718141568457916\n",
      "train loss:0.00027018078298826696\n",
      "train loss:0.001448247907560209\n",
      "train loss:0.0008093833503967146\n",
      "train loss:0.0027819158947555724\n",
      "train loss:0.0003127425123673222\n",
      "train loss:0.005346766973688395\n",
      "train loss:6.55350217519832e-05\n",
      "train loss:0.0017244835922107806\n",
      "train loss:0.00018625667873838132\n",
      "train loss:0.00033992050767916705\n",
      "train loss:0.00048725984215906333\n",
      "train loss:0.0013896262734761277\n",
      "train loss:0.0003103468564781451\n",
      "train loss:0.00024192830786643718\n",
      "train loss:0.0010106972276372505\n",
      "train loss:0.0011067838760923474\n",
      "train loss:0.002400570036116806\n",
      "train loss:0.001550891688747451\n",
      "train loss:0.0009451303049380445\n",
      "train loss:0.0024144829737354416\n",
      "train loss:0.00015268663981235514\n",
      "train loss:0.00023901128728240012\n",
      "train loss:0.03381207906843182\n",
      "train loss:0.0034891897724756964\n",
      "train loss:2.925308377857217e-05\n",
      "train loss:0.0008456087631781368\n",
      "train loss:0.001623861730481272\n",
      "train loss:0.002876720757682054\n",
      "train loss:0.0005752913745779678\n",
      "train loss:0.0005208880118543298\n",
      "train loss:7.503427261472562e-05\n",
      "train loss:6.825361284486584e-05\n",
      "train loss:0.0003622694047864719\n",
      "train loss:0.0016076435343283962\n",
      "train loss:7.212784436888836e-05\n",
      "train loss:0.003393350835573881\n",
      "train loss:0.0010581703850411164\n",
      "train loss:0.0019909283779398525\n",
      "train loss:0.0005287709665371222\n",
      "train loss:0.0018950982050565427\n",
      "train loss:0.0013741515970869531\n",
      "train loss:8.170525029561414e-05\n",
      "train loss:0.0014348569446663213\n",
      "train loss:0.001906271528609805\n",
      "train loss:5.432221583604673e-05\n",
      "train loss:0.003617731126113248\n",
      "train loss:0.0030432724795583428\n",
      "train loss:0.0008336265955703323\n",
      "train loss:0.005120507258658697\n",
      "train loss:0.0006092379199722296\n",
      "train loss:0.00273224669506007\n",
      "train loss:1.0255053933623537e-05\n",
      "train loss:6.174230177720089e-05\n",
      "train loss:0.0027282125112350793\n",
      "train loss:0.0006010055482888474\n",
      "train loss:0.0035105563040944733\n",
      "train loss:0.002445919368480718\n",
      "train loss:0.002623371605940141\n",
      "train loss:0.00029875548779918255\n",
      "train loss:0.004577302927783025\n",
      "train loss:0.00046516594405669157\n",
      "train loss:0.0009812607973602263\n",
      "train loss:0.0002934941075088109\n",
      "train loss:0.006593720491778262\n",
      "train loss:0.0003919912001195284\n",
      "train loss:0.0017348993338622942\n",
      "train loss:0.0005810613592254963\n",
      "train loss:0.0008052421895815643\n",
      "train loss:0.002797686263827009\n",
      "train loss:0.0004748728142775872\n",
      "train loss:0.001089244842730428\n",
      "train loss:0.00010789417984112685\n",
      "train loss:0.002624135046205588\n",
      "train loss:0.00039749253625572266\n",
      "train loss:0.00104936389892939\n",
      "train loss:0.00036349879787943713\n",
      "train loss:0.0018920487717511026\n",
      "train loss:0.001496402848226652\n",
      "train loss:0.04129551859492733\n",
      "train loss:0.001631864829492606\n",
      "train loss:0.00383391822595649\n",
      "train loss:0.00038652291038249035\n",
      "train loss:0.003870693523081305\n",
      "train loss:0.0003377686575899629\n",
      "train loss:0.0019323744203621949\n",
      "train loss:0.00029135936033688656\n",
      "train loss:0.005288939488190483\n",
      "train loss:0.0003313494856637127\n",
      "train loss:0.00131595700125122\n",
      "train loss:0.0022459859330625207\n",
      "train loss:2.9629075737303684e-05\n",
      "train loss:0.00010838738084090373\n",
      "train loss:0.001768184473613876\n",
      "train loss:0.0014897234871005445\n",
      "train loss:0.0036132172839787114\n",
      "train loss:0.0027426037157731366\n",
      "train loss:0.0013854582280910654\n",
      "train loss:0.0023839687432474273\n",
      "train loss:0.001607351396145441\n",
      "train loss:0.0012673937429813374\n",
      "train loss:0.0031158422488683796\n",
      "train loss:0.000792860191972258\n",
      "train loss:0.0003553515337355826\n",
      "train loss:0.000963825665920216\n",
      "train loss:0.00039687630208862267\n",
      "train loss:0.0017721066787847537\n",
      "train loss:0.0025809683728015027\n",
      "train loss:0.0009671075366772509\n",
      "train loss:0.0005904615694841507\n",
      "train loss:0.0018239187567125944\n",
      "train loss:0.007570147889763246\n",
      "train loss:0.0014413911335305035\n",
      "train loss:0.0017864113083955859\n",
      "train loss:0.004157475264196655\n",
      "train loss:0.0010362113483595337\n",
      "train loss:0.002516400564361179\n",
      "train loss:0.00012765066889132618\n",
      "train loss:0.019812645503908016\n",
      "train loss:0.0051851581694411005\n",
      "train loss:0.005620794705669781\n",
      "train loss:0.0004167702873036126\n",
      "train loss:0.0003366426238785568\n",
      "train loss:0.0010468881686736366\n",
      "train loss:0.0011096803855005968\n",
      "train loss:0.010453339327961901\n",
      "train loss:0.014023827746771527\n",
      "train loss:0.0030760226996037867\n",
      "train loss:0.03686149418116433\n",
      "train loss:0.004080742743431824\n",
      "train loss:0.0006463426094267097\n",
      "train loss:0.000693934779761029\n",
      "train loss:0.002714568410985676\n",
      "train loss:0.0009913396925279978\n",
      "train loss:0.008126195944742998\n",
      "train loss:0.004531752204706937\n",
      "train loss:0.006110709244592911\n",
      "train loss:0.00033124022163288284\n",
      "train loss:0.0014843634066790976\n",
      "train loss:0.00043756782453029623\n",
      "train loss:0.005401884720625881\n",
      "train loss:0.001382059160877655\n",
      "train loss:0.002791880483387184\n",
      "train loss:0.0050964862271331264\n",
      "train loss:0.0033323102239430553\n",
      "train loss:0.005049593854286252\n",
      "train loss:0.006052733397937791\n",
      "train loss:0.001411656440433884\n",
      "train loss:0.004718364249889579\n",
      "train loss:0.004041034751232653\n",
      "train loss:0.0098984942637298\n",
      "train loss:0.0005955181067673472\n",
      "train loss:0.0011500507802945684\n",
      "train loss:0.003963164294614783\n",
      "train loss:0.004041367191936369\n",
      "train loss:0.0038584496296722366\n",
      "train loss:0.012701602750207883\n",
      "train loss:0.004482763633885503\n",
      "train loss:0.0036239177834918226\n",
      "train loss:0.0010143055425408305\n",
      "train loss:0.00014833475897320475\n",
      "train loss:0.0010477210581563779\n",
      "train loss:0.0014847965450325376\n",
      "train loss:0.0019737921220721456\n",
      "train loss:0.0014482388358695389\n",
      "train loss:0.004012742826091823\n",
      "train loss:0.002713477157269864\n",
      "train loss:0.0035264981034340377\n",
      "train loss:0.048290690812286895\n",
      "train loss:0.0022658448705052433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01308399099762317\n",
      "train loss:0.007473061654418016\n",
      "train loss:0.021573785201665512\n",
      "train loss:0.00786869459650659\n",
      "train loss:0.0032501828236483165\n",
      "train loss:0.0023593899858931388\n",
      "train loss:0.0015080176373251154\n",
      "train loss:0.002225547778833682\n",
      "train loss:0.0018241710190118649\n",
      "train loss:0.00018134427810199182\n",
      "train loss:0.00015907874611139985\n",
      "train loss:0.008525736093852897\n",
      "train loss:0.026505905192269596\n",
      "train loss:0.005606158020838651\n",
      "train loss:0.0020975533010515485\n",
      "train loss:0.0009534541956151594\n",
      "train loss:0.0012848981597337538\n",
      "train loss:0.008837314135248854\n",
      "train loss:0.0008557904939040444\n",
      "train loss:0.0026188085295358295\n",
      "train loss:0.0007364599087024466\n",
      "train loss:0.0004264477322671152\n",
      "train loss:0.00020077233032880808\n",
      "train loss:0.0021209219156684694\n",
      "train loss:0.0012069907006614744\n",
      "train loss:2.5519314667952015e-05\n",
      "train loss:0.0039925263817577415\n",
      "train loss:0.0028221262396135303\n",
      "train loss:0.0032353403665461074\n",
      "train loss:0.0032017566626349725\n",
      "train loss:0.0008155836225187828\n",
      "train loss:0.00019692605079580223\n",
      "train loss:0.00131488822027165\n",
      "train loss:0.00022042822913984113\n",
      "train loss:0.0027860344791963343\n",
      "train loss:0.00023785381265783613\n",
      "train loss:0.0021395541901053678\n",
      "train loss:0.030053665789869847\n",
      "train loss:0.025755580759977973\n",
      "train loss:0.0006717881231189404\n",
      "train loss:0.00092661437454766\n",
      "train loss:0.0017662293248573138\n",
      "train loss:0.005001175383255947\n",
      "train loss:0.0004672974006718136\n",
      "train loss:9.734549617026004e-05\n",
      "train loss:0.006538396956916168\n",
      "train loss:6.23344198727604e-05\n",
      "train loss:0.00033512456076591755\n",
      "train loss:0.003028978348975646\n",
      "train loss:0.0010148908838004751\n",
      "train loss:5.171592364249257e-05\n",
      "train loss:0.006011413636335689\n",
      "train loss:0.0030938561746763544\n",
      "train loss:0.000204025295554787\n",
      "train loss:5.460431091345851e-05\n",
      "train loss:0.006295651422623754\n",
      "train loss:0.00034228378980947333\n",
      "train loss:0.00014002586336915964\n",
      "train loss:0.023273664458294728\n",
      "train loss:0.005218988961385349\n",
      "train loss:0.00017334310450604768\n",
      "train loss:0.0007353749315748068\n",
      "train loss:0.004504018738608969\n",
      "train loss:0.0005727532926731718\n",
      "train loss:0.0022405668163297428\n",
      "train loss:0.001747746947140752\n",
      "train loss:0.007661158843917396\n",
      "train loss:0.0045330337105712664\n",
      "train loss:0.001495289563520181\n",
      "train loss:0.001259277718900603\n",
      "train loss:0.00041410048012229737\n",
      "train loss:0.0001350536299308505\n",
      "train loss:0.00241929251072581\n",
      "train loss:0.006199455024213585\n",
      "train loss:0.0006293218224236039\n",
      "train loss:0.0011048728695665904\n",
      "train loss:0.002082631671942475\n",
      "train loss:0.0322623262350477\n",
      "train loss:0.012629943876674137\n",
      "train loss:0.007799365435670176\n",
      "train loss:0.0010907842347935325\n",
      "train loss:0.0006855319260006079\n",
      "train loss:0.010410047134123255\n",
      "train loss:0.003961900990088256\n",
      "train loss:0.0030171083778133233\n",
      "train loss:0.0017525834426897196\n",
      "train loss:9.284977863450914e-05\n",
      "train loss:0.000947471187691681\n",
      "train loss:0.0003580686904078823\n",
      "train loss:0.0019046341125122884\n",
      "train loss:0.009608739769670032\n",
      "train loss:0.0027339791365919653\n",
      "train loss:0.0006027760011766977\n",
      "train loss:0.004031105514888772\n",
      "train loss:0.009983187005469383\n",
      "train loss:0.0013591654230757642\n",
      "train loss:0.00032084910887526075\n",
      "train loss:0.0030091050947625266\n",
      "train loss:0.02190835258229089\n",
      "train loss:0.0003001075073636984\n",
      "train loss:0.000994710224917281\n",
      "train loss:0.0026448908783444926\n",
      "train loss:0.0020500034634238686\n",
      "train loss:0.0051221722632204605\n",
      "train loss:0.0012914703078778043\n",
      "train loss:0.002296312114286405\n",
      "train loss:0.0009215170619769808\n",
      "train loss:0.003304770474743164\n",
      "train loss:0.0027386778671497133\n",
      "train loss:0.0004565884859106545\n",
      "train loss:0.0012424825585559012\n",
      "train loss:0.0033793608374325197\n",
      "train loss:0.000465779184863503\n",
      "train loss:0.0016143315700944732\n",
      "train loss:0.0003141734973942135\n",
      "train loss:0.0023708439749221782\n",
      "train loss:0.0023372961052258866\n",
      "train loss:0.00222233561463933\n",
      "train loss:0.0011174545769528656\n",
      "train loss:0.0013095112170924935\n",
      "train loss:0.00029304614283177043\n",
      "train loss:0.0021851260062660752\n",
      "train loss:0.0016655182174682439\n",
      "train loss:0.000752042321580743\n",
      "train loss:0.0021642198429317316\n",
      "train loss:6.102862801989085e-05\n",
      "train loss:0.0005531664826273169\n",
      "train loss:0.003250470954458437\n",
      "train loss:0.0007259315453172031\n",
      "train loss:0.00010683646787337126\n",
      "train loss:0.01014727405592072\n",
      "train loss:0.00199836954843319\n",
      "train loss:0.0008690027948083958\n",
      "train loss:0.0018982572343073495\n",
      "train loss:8.454096800070187e-05\n",
      "train loss:0.00011979029626835572\n",
      "train loss:0.00977528415465169\n",
      "train loss:0.007975852565724766\n",
      "train loss:0.007057922909053397\n",
      "train loss:0.002899785957444391\n",
      "train loss:0.009676971511008454\n",
      "train loss:0.0012047068268081483\n",
      "train loss:0.0003626884517265162\n",
      "train loss:7.105969776305881e-05\n",
      "train loss:0.0010970763733962005\n",
      "train loss:0.0008671272424884008\n",
      "train loss:0.0009554703935809886\n",
      "train loss:0.003427676172714578\n",
      "train loss:0.0019180492168093257\n",
      "train loss:0.0005479301759538984\n",
      "train loss:0.002577329105611572\n",
      "train loss:0.002003814062375228\n",
      "train loss:0.0018091841470948202\n",
      "train loss:0.0008245036649796407\n",
      "train loss:0.00040067699557765486\n",
      "train loss:0.0015832006436789343\n",
      "train loss:0.0015429340742926098\n",
      "train loss:0.005711437902623656\n",
      "train loss:0.0004914828528337887\n",
      "train loss:0.0006089750626302081\n",
      "train loss:0.0028132475626633045\n",
      "train loss:0.00036151898988886084\n",
      "train loss:0.004420685970060806\n",
      "train loss:0.0036769876098399885\n",
      "train loss:0.005617505176690553\n",
      "train loss:0.0003189437567648246\n",
      "train loss:0.001306282545273334\n",
      "train loss:0.004052866905065443\n",
      "train loss:0.0002250520824281229\n",
      "train loss:0.0006746499304029584\n",
      "train loss:0.00019801484401132442\n",
      "train loss:3.735937962407195e-05\n",
      "train loss:0.00018729175885161516\n",
      "train loss:0.00140614734816864\n",
      "train loss:0.0030307451630051233\n",
      "train loss:0.00792004989632098\n",
      "train loss:0.0008130955255139808\n",
      "train loss:0.002890473547398472\n",
      "train loss:0.0016649222661853408\n",
      "train loss:0.0013910059867423621\n",
      "train loss:0.007810270052703533\n",
      "train loss:0.0005153466658239672\n",
      "train loss:0.0011161640224192292\n",
      "train loss:0.00022821918984203678\n",
      "train loss:0.0005053054521075502\n",
      "train loss:0.00017621100340950595\n",
      "train loss:0.001099676753239232\n",
      "train loss:0.0022507051726087897\n",
      "train loss:0.0006732948138018864\n",
      "train loss:0.0024414690671219793\n",
      "train loss:0.0006163126031555171\n",
      "train loss:0.0022972671142595\n",
      "train loss:0.0005202247484695416\n",
      "train loss:0.0004593070766455045\n",
      "train loss:0.0010569398081644733\n",
      "train loss:0.005031700367881847\n",
      "train loss:0.0011361022243478018\n",
      "train loss:0.0005317679467136494\n",
      "train loss:0.01227218305122173\n",
      "train loss:0.0010175475257068135\n",
      "train loss:0.0012535455324498724\n",
      "train loss:0.0010881012161878844\n",
      "train loss:0.0004780613561382423\n",
      "train loss:0.0002761656417535812\n",
      "train loss:8.610443487436226e-05\n",
      "train loss:0.00033281730930856656\n",
      "train loss:0.0031991911189733387\n",
      "train loss:0.0009231019143416263\n",
      "train loss:0.0035402374221678618\n",
      "train loss:0.00043644445875428643\n",
      "train loss:0.00022184637782616826\n",
      "train loss:0.00015531311519907952\n",
      "train loss:0.0036356830966360588\n",
      "train loss:0.0075880691493849595\n",
      "train loss:0.0014344258118194233\n",
      "train loss:0.01203284212770383\n",
      "train loss:0.0024233132152612444\n",
      "train loss:0.0011407108304922057\n",
      "train loss:0.0011121838610524076\n",
      "train loss:0.003085526078546099\n",
      "train loss:0.0043392670246002515\n",
      "train loss:0.0059158403127711565\n",
      "train loss:0.0006202272516794758\n",
      "train loss:6.246256892465862e-05\n",
      "train loss:0.002018816707588133\n",
      "train loss:0.0002591747172120361\n",
      "train loss:0.0002345890433037068\n",
      "train loss:0.00030064976206135364\n",
      "train loss:0.0011155620878699158\n",
      "train loss:0.0025539511776066838\n",
      "train loss:0.0010094622903029451\n",
      "train loss:0.00026532256981098314\n",
      "train loss:0.000779974995938269\n",
      "train loss:0.0007586347680672076\n",
      "train loss:0.003623872749784752\n",
      "train loss:0.00010289952140872696\n",
      "train loss:0.0004923768027769715\n",
      "train loss:0.0011808446991905155\n",
      "train loss:0.002257441131228708\n",
      "train loss:0.0005921516608309132\n",
      "train loss:0.001312956469747507\n",
      "train loss:0.00042703918492952524\n",
      "train loss:0.0005124272762214085\n",
      "train loss:0.00422455456307523\n",
      "train loss:0.0010495607636375275\n",
      "train loss:0.0008656097466161521\n",
      "train loss:0.002047240190502501\n",
      "train loss:7.52192943093573e-05\n",
      "train loss:0.0008132682973514631\n",
      "train loss:0.001498684569342337\n",
      "train loss:0.0008532854726308079\n",
      "train loss:0.00185233192050564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003546757181915599\n",
      "train loss:0.003322087092761357\n",
      "train loss:0.0001349667577417146\n",
      "train loss:0.0005949759567992108\n",
      "train loss:0.006489233969047048\n",
      "train loss:0.002502623818412482\n",
      "train loss:0.00016616312497094523\n",
      "train loss:0.0009908432014247611\n",
      "train loss:0.0019007096143591382\n",
      "train loss:0.0035561918420210403\n",
      "train loss:0.0007858199567087957\n",
      "train loss:0.0018152477514775203\n",
      "train loss:0.00019236636513070228\n",
      "train loss:0.0014972700969064076\n",
      "train loss:0.0014768643520463461\n",
      "train loss:0.0024479370737041585\n",
      "train loss:0.0024587852590018306\n",
      "train loss:0.0024313462506616776\n",
      "train loss:0.000423431718922001\n",
      "train loss:0.0006074065050180109\n",
      "train loss:0.0024621923978205558\n",
      "train loss:0.00015623127304008493\n",
      "train loss:0.0007767714026740835\n",
      "train loss:0.002548202910633986\n",
      "train loss:0.0016879838637832477\n",
      "train loss:0.0039290467974514055\n",
      "train loss:0.002615031298211959\n",
      "train loss:0.0046558654224454895\n",
      "train loss:0.00194627607605349\n",
      "train loss:0.0007627136173494135\n",
      "train loss:0.00015576510000427305\n",
      "train loss:0.0008531068638942298\n",
      "train loss:0.0027950832815708563\n",
      "train loss:0.0008097791740432177\n",
      "train loss:0.00010299540599647057\n",
      "train loss:0.0018377952841797476\n",
      "train loss:0.0005970492489112707\n",
      "train loss:0.0008653753303281038\n",
      "train loss:0.0003313259339844095\n",
      "train loss:0.017199865640326585\n",
      "train loss:0.00449440182743952\n",
      "train loss:0.0004779900956774135\n",
      "train loss:0.0011428094087148153\n",
      "train loss:7.09519315026061e-05\n",
      "train loss:0.00011134543263298246\n",
      "train loss:0.0012506203298449647\n",
      "train loss:0.0001073683668749484\n",
      "train loss:0.0024350279017991867\n",
      "train loss:0.000309714085286884\n",
      "train loss:0.0002671402143011425\n",
      "train loss:0.0008926371665066504\n",
      "train loss:0.005692794048565168\n",
      "train loss:0.0046305006140881285\n",
      "train loss:0.0024844056376331284\n",
      "train loss:0.010709805067604597\n",
      "train loss:0.002884673797709539\n",
      "train loss:0.0003461333385997728\n",
      "train loss:0.006319824994797382\n",
      "train loss:0.000637749300550005\n",
      "train loss:0.00034669731508572707\n",
      "train loss:0.0005210604459100042\n",
      "train loss:0.00029811558561650077\n",
      "train loss:0.00814813264682814\n",
      "train loss:0.002160497113257697\n",
      "train loss:0.009963483863931184\n",
      "train loss:0.0025648880534026907\n",
      "train loss:0.0022927827990491577\n",
      "train loss:0.0003036161464854256\n",
      "train loss:0.001564669035903387\n",
      "train loss:0.002146875516277816\n",
      "train loss:0.014914715731136209\n",
      "train loss:0.00019284349654508207\n",
      "train loss:0.0006692166704956812\n",
      "train loss:0.000704906261576449\n",
      "train loss:0.00024237120921389403\n",
      "train loss:3.9675726872566974e-05\n",
      "train loss:0.0013963514024675561\n",
      "train loss:0.0012526103401913641\n",
      "train loss:0.008182660850760793\n",
      "train loss:0.0002581224298679559\n",
      "train loss:0.012195412647076052\n",
      "train loss:0.0023178997251979932\n",
      "train loss:0.0032938509812442986\n",
      "train loss:0.0006853976566325039\n",
      "train loss:0.0014440221342615642\n",
      "train loss:0.0229559836445163\n",
      "train loss:0.0004680328634436386\n",
      "train loss:0.001118982842726909\n",
      "train loss:0.001496228783275395\n",
      "train loss:0.0013436495278988092\n",
      "train loss:0.0008537961460707158\n",
      "train loss:0.016023568495730448\n",
      "train loss:0.00027359767634084416\n",
      "train loss:0.004690709316538078\n",
      "train loss:0.0036785814850412717\n",
      "train loss:0.005128989546778154\n",
      "train loss:0.0009876090732194765\n",
      "train loss:0.018812092227910665\n",
      "train loss:0.0007787257013304436\n",
      "train loss:0.001378394463318145\n",
      "train loss:0.00012529867602645525\n",
      "train loss:0.022455761496103944\n",
      "train loss:0.009634858135805047\n",
      "train loss:0.0008179345645693851\n",
      "train loss:0.0010521871290983297\n",
      "train loss:0.0020893422689942753\n",
      "train loss:0.008217836023187623\n",
      "train loss:0.0022254048509241127\n",
      "train loss:0.00031153881466022544\n",
      "=== epoch:17, train acc:0.995, test acc:0.984 ===\n",
      "train loss:0.00023381534452570078\n",
      "train loss:0.00015880004361130655\n",
      "train loss:0.0014620215640319925\n",
      "train loss:0.005441637356120415\n",
      "train loss:0.001442286991767609\n",
      "train loss:0.009084971653187677\n",
      "train loss:0.0002442993902824861\n",
      "train loss:0.0006184307282182021\n",
      "train loss:0.008261312818820681\n",
      "train loss:0.0064294385832681985\n",
      "train loss:0.0017545061226400946\n",
      "train loss:0.00023145651322466608\n",
      "train loss:2.7789499568377044e-05\n",
      "train loss:0.003306111510049444\n",
      "train loss:0.005739451074539282\n",
      "train loss:0.0029501350646826937\n",
      "train loss:0.0018587531701949002\n",
      "train loss:0.00026073699076110436\n",
      "train loss:0.000254135618812784\n",
      "train loss:0.003106729302533644\n",
      "train loss:0.011729844495421454\n",
      "train loss:0.00019527119284610454\n",
      "train loss:0.005819036735069541\n",
      "train loss:0.004264111493956097\n",
      "train loss:0.001261795915102229\n",
      "train loss:0.0007264932520290628\n",
      "train loss:0.0019814265984518407\n",
      "train loss:0.0019181329339862012\n",
      "train loss:0.0032917118929417593\n",
      "train loss:0.0021100129673989805\n",
      "train loss:0.0005290520396850378\n",
      "train loss:0.00044690160377227055\n",
      "train loss:0.0013438403827826656\n",
      "train loss:8.22920132678518e-05\n",
      "train loss:0.00013673198582131254\n",
      "train loss:0.004543841049306424\n",
      "train loss:0.0003695945852211035\n",
      "train loss:0.008129633430636938\n",
      "train loss:0.0017163252844112186\n",
      "train loss:0.0007941741386910405\n",
      "train loss:0.0004222968930315083\n",
      "train loss:0.0001215162360993515\n",
      "train loss:0.0009433459554098233\n",
      "train loss:0.0010701410303439731\n",
      "train loss:0.00041782656392420534\n",
      "train loss:0.0008068533614494409\n",
      "train loss:0.0018415541931800685\n",
      "train loss:0.00037916251706991797\n",
      "train loss:0.00015530840014336102\n",
      "train loss:0.0015606009359469223\n",
      "train loss:0.00043695358695768175\n",
      "train loss:0.0033622540874378797\n",
      "train loss:0.00559349465602113\n",
      "train loss:0.00022207182180081342\n",
      "train loss:0.0032348224372893623\n",
      "train loss:0.003669500361947754\n",
      "train loss:0.0004521983711209266\n",
      "train loss:0.001185187592987146\n",
      "train loss:0.0009189465644014535\n",
      "train loss:0.0012606491616534157\n",
      "train loss:0.01029193702916093\n",
      "train loss:0.001596048438531528\n",
      "train loss:0.001126691598598944\n",
      "train loss:0.00014281782800669893\n",
      "train loss:0.006790098845906217\n",
      "train loss:0.03339186171858723\n",
      "train loss:0.0023801772834809443\n",
      "train loss:0.011051346456420913\n",
      "train loss:0.0004049710322944335\n",
      "train loss:0.00016675125908386675\n",
      "train loss:0.013920158058810356\n",
      "train loss:0.0034168207484950165\n",
      "train loss:0.0006507049217187228\n",
      "train loss:0.0001884760229296203\n",
      "train loss:0.00019876275904361006\n",
      "train loss:0.004557632674237343\n",
      "train loss:0.0021389964317412137\n",
      "train loss:0.00479858809529758\n",
      "train loss:0.003067031994938756\n",
      "train loss:0.0020512135834172937\n",
      "train loss:0.0009453124536900134\n",
      "train loss:0.0013210251764712022\n",
      "train loss:0.004138798130001866\n",
      "train loss:0.0003627428643485478\n",
      "train loss:0.0008599471360897742\n",
      "train loss:0.0032267096878189076\n",
      "train loss:0.02299816422092542\n",
      "train loss:0.030266661905539324\n",
      "train loss:0.020384327344586565\n",
      "train loss:0.0026179370294027314\n",
      "train loss:0.00873666446566151\n",
      "train loss:0.012560548891333304\n",
      "train loss:0.0011393693152405087\n",
      "train loss:0.0002635603534837671\n",
      "train loss:0.00047821752047523444\n",
      "train loss:0.0012442843074945962\n",
      "train loss:0.0007943984930067391\n",
      "train loss:0.002145794781622598\n",
      "train loss:0.0026697573509817103\n",
      "train loss:0.001846288929845886\n",
      "train loss:0.012563873466721609\n",
      "train loss:0.0004188788373270564\n",
      "train loss:0.0012042354072569054\n",
      "train loss:0.0003802870889851099\n",
      "train loss:0.0008841743558972723\n",
      "train loss:0.001557900462093851\n",
      "train loss:0.0012477552303330928\n",
      "train loss:0.006792066067327251\n",
      "train loss:0.01974091343885014\n",
      "train loss:0.0003656108355062313\n",
      "train loss:0.0008383351351319349\n",
      "train loss:0.0025509028525501176\n",
      "train loss:0.0011907061808672259\n",
      "train loss:0.00027921438247166205\n",
      "train loss:0.002066588764605432\n",
      "train loss:0.000881737071940199\n",
      "train loss:0.0001852078047365881\n",
      "train loss:0.00018301077148456354\n",
      "train loss:0.0014937567729653087\n",
      "train loss:0.00013484499316318408\n",
      "train loss:0.0016558805143836492\n",
      "train loss:0.009960254060058994\n",
      "train loss:0.0010909965656901441\n",
      "train loss:0.0019368448255286763\n",
      "train loss:0.0023107783645387055\n",
      "train loss:0.0005935061996897589\n",
      "train loss:0.01698487303147292\n",
      "train loss:0.0021711430594355723\n",
      "train loss:0.00013630540586268255\n",
      "train loss:0.000587327805057992\n",
      "train loss:0.0006899300682532472\n",
      "train loss:0.0006001287386113636\n",
      "train loss:0.0017860069673706523\n",
      "train loss:0.006694970462934793\n",
      "train loss:0.007985376495930785\n",
      "train loss:0.006131566595978336\n",
      "train loss:0.0053418601184748145\n",
      "train loss:0.005441091471172003\n",
      "train loss:0.0015001467496767184\n",
      "train loss:0.0001703402171077484\n",
      "train loss:5.77568655561371e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.013723129701678502\n",
      "train loss:0.0004880863498995054\n",
      "train loss:0.0012182492985298168\n",
      "train loss:0.0005067137915015674\n",
      "train loss:0.009427835681146522\n",
      "train loss:0.0001404388370864165\n",
      "train loss:0.0004979317561018312\n",
      "train loss:0.0010533346523749218\n",
      "train loss:0.001266687481250056\n",
      "train loss:0.0021630437657155148\n",
      "train loss:0.007781852359332943\n",
      "train loss:0.009108359337500366\n",
      "train loss:0.0003838634317418232\n",
      "train loss:9.099791495817508e-05\n",
      "train loss:0.0003584319616014592\n",
      "train loss:0.001548011034277958\n",
      "train loss:0.0015830572420089666\n",
      "train loss:0.0025770958829007106\n",
      "train loss:0.00020538221292517916\n",
      "train loss:0.00020217449786296988\n",
      "train loss:0.0006616041325872866\n",
      "train loss:0.00023145207144793803\n",
      "train loss:0.0009093652512959596\n",
      "train loss:0.0003689581497163595\n",
      "train loss:0.0007577219250780927\n",
      "train loss:0.0005000791498918062\n",
      "train loss:0.0017471306547947331\n",
      "train loss:0.00041681646315502993\n",
      "train loss:0.00047715783892360276\n",
      "train loss:0.0007868135599987376\n",
      "train loss:0.0006072638215873683\n",
      "train loss:0.001849961095470224\n",
      "train loss:0.006843791053958154\n",
      "train loss:0.010747199203041378\n",
      "train loss:0.0003874681073218245\n",
      "train loss:0.000986705939717699\n",
      "train loss:0.0013402831026956702\n",
      "train loss:0.017956550140420198\n",
      "train loss:0.0009886396702844798\n",
      "train loss:0.00012799289113920483\n",
      "train loss:0.0058136416501243845\n",
      "train loss:0.003400007335723715\n",
      "train loss:0.0038696485676190185\n",
      "train loss:0.0005753625484794478\n",
      "train loss:0.002037007767185919\n",
      "train loss:0.02137768509329292\n",
      "train loss:0.0008119189960788969\n",
      "train loss:0.00035952704012461576\n",
      "train loss:0.003137609731219694\n",
      "train loss:0.0016721914172597408\n",
      "train loss:0.002637330228041271\n",
      "train loss:0.0009801555889449246\n",
      "train loss:0.0013585223026127654\n",
      "train loss:0.0017188994205362231\n",
      "train loss:0.015292845426854386\n",
      "train loss:0.0005654119361998643\n",
      "train loss:0.000987366850156196\n",
      "train loss:0.009463388265563916\n",
      "train loss:0.0007804343261928726\n",
      "train loss:0.000661336584302938\n",
      "train loss:0.004062657474294984\n",
      "train loss:0.00011600920195060714\n",
      "train loss:0.0010233448493392216\n",
      "train loss:0.003070202770881506\n",
      "train loss:0.0010224325812291186\n",
      "train loss:0.00043942644265487795\n",
      "train loss:0.009331817536781114\n",
      "train loss:0.0037042893645730284\n",
      "train loss:9.930559466624192e-05\n",
      "train loss:0.0018593388514376976\n",
      "train loss:0.0005110158457679196\n",
      "train loss:0.0034336690432548596\n",
      "train loss:0.00037220733597394517\n",
      "train loss:0.001458289306411664\n",
      "train loss:0.0006617917396371044\n",
      "train loss:0.0015957598262993416\n",
      "train loss:0.0005796895605389934\n",
      "train loss:0.0042289661911914835\n",
      "train loss:0.0016614956027155728\n",
      "train loss:0.0020362675280996023\n",
      "train loss:0.0011702594087881955\n",
      "train loss:0.003460479309695785\n",
      "train loss:0.0019011888838631264\n",
      "train loss:0.004101757534077643\n",
      "train loss:0.003695825678857442\n",
      "train loss:0.0019929816797183064\n",
      "train loss:0.0009271945645296281\n",
      "train loss:0.001629051678840649\n",
      "train loss:0.002550206652766999\n",
      "train loss:0.0008631284930422892\n",
      "train loss:0.0015272152974228877\n",
      "train loss:0.0008437897954390412\n",
      "train loss:0.0015859465895958073\n",
      "train loss:0.0034987530699514486\n",
      "train loss:0.00015037939405571023\n",
      "train loss:5.7232607006863587e-05\n",
      "train loss:0.0011003813675888108\n",
      "train loss:0.0029938989058655814\n",
      "train loss:0.0014247610015913597\n",
      "train loss:0.0012198662478889288\n",
      "train loss:0.0006605049117773661\n",
      "train loss:0.0005562351178522719\n",
      "train loss:0.00043157503117495244\n",
      "train loss:0.0009493135578799125\n",
      "train loss:0.001824835720385766\n",
      "train loss:0.00021273210409964878\n",
      "train loss:0.000689881588339132\n",
      "train loss:7.870243926141455e-05\n",
      "train loss:0.0006914394886841462\n",
      "train loss:0.00017082463969483823\n",
      "train loss:0.004622279972153564\n",
      "train loss:0.0001058620161115834\n",
      "train loss:0.0005282536209649795\n",
      "train loss:0.00235525045096726\n",
      "train loss:0.0016936357260343665\n",
      "train loss:0.003456663462858608\n",
      "train loss:3.8043558981993906e-05\n",
      "train loss:0.002153819493039264\n",
      "train loss:0.0006659288352503312\n",
      "train loss:0.0037425804057998236\n",
      "train loss:0.0005543338419448882\n",
      "train loss:0.0002722332281348213\n",
      "train loss:0.00031977976575260587\n",
      "train loss:0.001552837944123914\n",
      "train loss:0.002898431425295454\n",
      "train loss:0.0013158867481092257\n",
      "train loss:0.004249039020375553\n",
      "train loss:0.007050860326728669\n",
      "train loss:0.0016954150731205483\n",
      "train loss:0.00033659564761439844\n",
      "train loss:0.0015767879836837118\n",
      "train loss:0.0005734325212968488\n",
      "train loss:0.001281507336147559\n",
      "train loss:0.000680941496873785\n",
      "train loss:0.0013478968859213048\n",
      "train loss:0.0004484563683571153\n",
      "train loss:0.0011084052981883644\n",
      "train loss:7.256469535625546e-05\n",
      "train loss:3.318838634957168e-05\n",
      "train loss:0.004291859635176151\n",
      "train loss:0.0034380841042842974\n",
      "train loss:0.0007165873754247358\n",
      "train loss:0.0018849042222628936\n",
      "train loss:0.0025138313944508147\n",
      "train loss:0.00018745492191984153\n",
      "train loss:0.009913354518610605\n",
      "train loss:0.0017045015430844606\n",
      "train loss:8.131845760979719e-05\n",
      "train loss:0.0020954278577905573\n",
      "train loss:0.0014894985776833485\n",
      "train loss:0.0008849009293424692\n",
      "train loss:0.003557458241686312\n",
      "train loss:8.153484811384254e-05\n",
      "train loss:0.0015955281012533676\n",
      "train loss:0.0004682050455081848\n",
      "train loss:0.0013961973126580816\n",
      "train loss:0.0007943682260396695\n",
      "train loss:0.0017491271187202318\n",
      "train loss:7.539233265753024e-05\n",
      "train loss:0.0010760647758876354\n",
      "train loss:0.0007816181163118733\n",
      "train loss:0.0021919557982398377\n",
      "train loss:0.007237401580425154\n",
      "train loss:0.0001877215086830111\n",
      "train loss:0.003626418780766132\n",
      "train loss:0.00044920460138220334\n",
      "train loss:0.0002129783747993693\n",
      "train loss:0.0015703863242517812\n",
      "train loss:0.0008362467580372578\n",
      "train loss:0.0013904101177204967\n",
      "train loss:4.893976735690568e-05\n",
      "train loss:0.002250224296371453\n",
      "train loss:0.01873215573933415\n",
      "train loss:0.0016001519202998036\n",
      "train loss:0.0032532693063708844\n",
      "train loss:0.0012042014087356567\n",
      "train loss:0.004562280277767936\n",
      "train loss:0.0031807168360283777\n",
      "train loss:0.010278719376886071\n",
      "train loss:0.008674870385396542\n",
      "train loss:0.003201330297395391\n",
      "train loss:0.0026324547097259627\n",
      "train loss:0.003044810655491501\n",
      "train loss:0.0003027465762756341\n",
      "train loss:0.0035501275540523293\n",
      "train loss:0.0002710421023103815\n",
      "train loss:0.00011227828725623717\n",
      "train loss:0.00013535474859070724\n",
      "train loss:0.010147957451731048\n",
      "train loss:0.0030389868425728128\n",
      "train loss:0.0013417440190201108\n",
      "train loss:0.0026233663037311594\n",
      "train loss:0.0012248517422024548\n",
      "train loss:0.00012664474671512897\n",
      "train loss:0.016944520338039542\n",
      "train loss:0.008921805239115508\n",
      "train loss:0.000823790483500854\n",
      "train loss:0.0003462542621988955\n",
      "train loss:0.000507676691181327\n",
      "train loss:0.00033993341587461925\n",
      "train loss:0.005169790144919069\n",
      "train loss:0.0024072106085812873\n",
      "train loss:0.0007986522760571464\n",
      "train loss:0.008327917213046557\n",
      "train loss:6.67807451453171e-05\n",
      "train loss:0.0024324003367015568\n",
      "train loss:0.0009850793414549418\n",
      "train loss:0.0019382679294551073\n",
      "train loss:0.0009562559680837595\n",
      "train loss:0.0002494114849592409\n",
      "train loss:0.0009172841493584341\n",
      "train loss:0.001960382687232283\n",
      "train loss:0.0017221682730649114\n",
      "train loss:0.0005106096563102188\n",
      "train loss:0.0006411484804499983\n",
      "train loss:0.0002353214049054102\n",
      "train loss:0.0009695750507143307\n",
      "train loss:0.0006966642332558642\n",
      "train loss:0.004248670075590648\n",
      "train loss:0.00023177536435194378\n",
      "train loss:0.0002755608558808779\n",
      "train loss:0.00014899352006467382\n",
      "train loss:0.00014167755008204246\n",
      "train loss:0.00026962211608920575\n",
      "train loss:0.001081696582630251\n",
      "train loss:0.0018115364143646423\n",
      "train loss:0.00877842503625697\n",
      "train loss:0.0022599722491338198\n",
      "train loss:0.00022790186847550196\n",
      "train loss:7.404728865067547e-05\n",
      "train loss:0.00054308682930722\n",
      "train loss:0.00013650604770347867\n",
      "train loss:0.0001793200950356678\n",
      "train loss:0.0003757364476488376\n",
      "train loss:0.0036939269628538367\n",
      "train loss:0.0005437598349827146\n",
      "train loss:6.549583954161502e-05\n",
      "train loss:0.0015931127884460544\n",
      "train loss:0.0007982531550448302\n",
      "train loss:0.0013914935226251148\n",
      "train loss:0.00216143897972428\n",
      "train loss:0.0041711450397318465\n",
      "train loss:0.0003842373401131049\n",
      "train loss:0.002997905811634761\n",
      "train loss:0.0008931121292549343\n",
      "train loss:3.123033303616036e-05\n",
      "train loss:0.0003209053889060703\n",
      "train loss:0.00017116616801564935\n",
      "train loss:0.00013294226853027106\n",
      "train loss:0.0001528830859508254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.000454520821544092\n",
      "train loss:0.0005998247732239895\n",
      "train loss:0.00021759761798118615\n",
      "train loss:0.0007448377807896889\n",
      "train loss:0.00016154026394129149\n",
      "train loss:0.00015503354629253855\n",
      "train loss:0.0004142010982683459\n",
      "train loss:0.0020322573694138836\n",
      "train loss:0.0014819137843421581\n",
      "train loss:0.0006140437242928831\n",
      "train loss:0.0007901304260247487\n",
      "train loss:0.0018324520574473965\n",
      "train loss:0.001578993203719915\n",
      "train loss:0.0008845861754903696\n",
      "train loss:0.0026264422917453233\n",
      "train loss:0.0048042508589953145\n",
      "train loss:0.0009836318416858202\n",
      "train loss:0.0016575714920040133\n",
      "train loss:0.000736746543021931\n",
      "train loss:0.00020981423194590655\n",
      "train loss:0.005430055211908318\n",
      "train loss:0.0002966832660871869\n",
      "train loss:0.0002644501111660343\n",
      "train loss:0.0003444259120601461\n",
      "train loss:6.20642203455057e-05\n",
      "train loss:0.00044163129592105757\n",
      "train loss:0.002499575210068836\n",
      "train loss:0.0016247653632279967\n",
      "train loss:0.0017285314012918049\n",
      "train loss:0.00012122093721449297\n",
      "train loss:6.525561164587023e-05\n",
      "train loss:0.0016119592927986387\n",
      "train loss:0.0030967174049049083\n",
      "train loss:0.002509955491227943\n",
      "train loss:0.010413553229132304\n",
      "train loss:5.4566204217820855e-05\n",
      "train loss:7.270315861372182e-05\n",
      "train loss:0.0006821216680535022\n",
      "train loss:0.0009022562924851513\n",
      "train loss:0.0016326492046484457\n",
      "train loss:0.0006365847346393679\n",
      "train loss:0.0002902583506762388\n",
      "train loss:0.0004915538836086652\n",
      "train loss:8.348298476737355e-05\n",
      "train loss:6.499023535160978e-05\n",
      "train loss:0.0001249903503195242\n",
      "train loss:8.616414093779696e-06\n",
      "train loss:0.00036013107973562904\n",
      "train loss:8.294323023845586e-05\n",
      "train loss:0.0011306265334364415\n",
      "train loss:0.00246870055401446\n",
      "train loss:0.0035749651441893213\n",
      "train loss:0.001088655747980985\n",
      "train loss:0.00046828382938340587\n",
      "train loss:0.002572812131253658\n",
      "train loss:0.002697985923223486\n",
      "train loss:0.0003819612250775057\n",
      "train loss:9.784674991348969e-05\n",
      "train loss:0.0003618023515154149\n",
      "train loss:0.0018366933821756378\n",
      "train loss:0.0011305678114194378\n",
      "train loss:0.0005785461937770184\n",
      "train loss:0.00012745997195161212\n",
      "train loss:0.0006021287304770046\n",
      "train loss:0.0017577579532761275\n",
      "train loss:0.0008391423128648008\n",
      "train loss:0.00047186765446309163\n",
      "train loss:0.0004571846720506992\n",
      "train loss:0.0005445811266110431\n",
      "train loss:9.125939137568925e-05\n",
      "train loss:0.00014686838899610353\n",
      "train loss:0.0011633425916405516\n",
      "train loss:0.0007774205514998348\n",
      "train loss:0.0019153898025214757\n",
      "train loss:0.0003256651329637455\n",
      "train loss:0.0006946062970980445\n",
      "train loss:0.002613887794686596\n",
      "train loss:0.0037484588825371047\n",
      "train loss:5.7527555515879194e-05\n",
      "train loss:0.0008898779272176475\n",
      "train loss:0.00028063060869279693\n",
      "train loss:0.00012781213428450204\n",
      "train loss:0.0012414432933331538\n",
      "train loss:0.0003914025657193032\n",
      "train loss:0.0010537921374276949\n",
      "train loss:0.001410859271816049\n",
      "train loss:0.00149967813757958\n",
      "train loss:5.739225323163383e-05\n",
      "train loss:0.0004991417740512665\n",
      "train loss:0.0005937243078454491\n",
      "train loss:0.0010447946470892571\n",
      "train loss:0.00039327455575990683\n",
      "train loss:0.0007674035896084324\n",
      "train loss:4.81460394440004e-05\n",
      "train loss:0.00011044881393766106\n",
      "train loss:0.00046038436857435576\n",
      "train loss:0.0007792988086164224\n",
      "train loss:0.000608043663760049\n",
      "train loss:0.0006975554747205045\n",
      "train loss:0.0002500748329665014\n",
      "train loss:6.570059501725805e-05\n",
      "train loss:2.639786381215933e-05\n",
      "train loss:0.0006641085481115905\n",
      "train loss:0.0012004661919962551\n",
      "train loss:0.0003215368479871646\n",
      "train loss:0.00035600537705087886\n",
      "train loss:0.0011977718001119461\n",
      "train loss:0.00020078243151252123\n",
      "train loss:7.819279506480863e-05\n",
      "train loss:0.001812739886528541\n",
      "train loss:0.00018655807782329043\n",
      "train loss:0.0006370336255765799\n",
      "train loss:0.00018504203528751792\n",
      "train loss:0.0003953232254051229\n",
      "train loss:0.00011425989603657216\n",
      "train loss:0.0016672129262926274\n",
      "train loss:0.00028864222050462815\n",
      "train loss:0.0003324446244421594\n",
      "train loss:0.0004034555418654292\n",
      "train loss:0.0004469780185497765\n",
      "train loss:0.0001830389423743603\n",
      "train loss:0.0007795926624152547\n",
      "train loss:0.00035014963562618044\n",
      "train loss:0.00019128772199857678\n",
      "train loss:0.0012416218992458109\n",
      "train loss:0.0015844034351917937\n",
      "train loss:0.0006780628223926804\n",
      "train loss:0.00011353844508537528\n",
      "train loss:0.0032696936214171783\n",
      "train loss:0.00010621970932557406\n",
      "train loss:0.0013131177762603116\n",
      "train loss:0.0017663931871867565\n",
      "train loss:0.00012388233599146392\n",
      "train loss:0.00010181581915600197\n",
      "train loss:0.0003048041243728392\n",
      "train loss:0.00986826344406645\n",
      "train loss:0.0026283000910971794\n",
      "train loss:0.004444752342567519\n",
      "train loss:0.00014673121414451735\n",
      "train loss:0.0005195742855106017\n",
      "train loss:0.00020193633311916796\n",
      "train loss:0.001365678049761124\n",
      "train loss:0.002358136414227889\n",
      "train loss:0.00023696163342734969\n",
      "train loss:0.0002482239112998343\n",
      "train loss:0.00035613824654931095\n",
      "train loss:0.007178699768763755\n",
      "train loss:0.0005447468612076481\n",
      "train loss:0.00012071973969282741\n",
      "train loss:5.499575713024659e-05\n",
      "train loss:0.0003788773874465168\n",
      "train loss:6.326117135552694e-05\n",
      "train loss:0.03365171438290906\n",
      "train loss:0.00032114558715377704\n",
      "train loss:0.0007380100041222922\n",
      "train loss:0.00013878926352790835\n",
      "train loss:0.00031068979690483645\n",
      "train loss:0.002924889655507271\n",
      "train loss:0.0014558900108373066\n",
      "train loss:0.0010040777350473506\n",
      "train loss:0.0001627705631935825\n",
      "train loss:0.0020063297866048384\n",
      "train loss:0.0007905043158882262\n",
      "train loss:0.0004678256089627213\n",
      "train loss:0.00014803062947992617\n",
      "train loss:0.004672320244701756\n",
      "train loss:0.00015079956601563846\n",
      "train loss:0.01389763076991798\n",
      "train loss:0.0012744263988813459\n",
      "train loss:0.0011465740301286477\n",
      "train loss:0.002865344421915497\n",
      "train loss:0.00024147425535172461\n",
      "train loss:0.0006521341872536878\n",
      "train loss:4.2698496410748353e-05\n",
      "train loss:0.0010770863824737101\n",
      "train loss:1.6838765021164043e-05\n",
      "train loss:0.0009154482822173539\n",
      "train loss:1.4060382685279137e-05\n",
      "train loss:0.00026028554105433574\n",
      "train loss:0.0004430081560448468\n",
      "train loss:0.002246339056531931\n",
      "train loss:0.0016552289633258927\n",
      "train loss:0.00042458290415788155\n",
      "train loss:0.0007549578950298053\n",
      "train loss:0.0068719435396399\n",
      "train loss:0.0012476944838921886\n",
      "train loss:0.0024313567614172565\n",
      "train loss:0.00039219268831137814\n",
      "train loss:0.0008385463657420444\n",
      "train loss:0.002161190782299387\n",
      "train loss:0.0002534587561671246\n",
      "train loss:0.0003665087434507097\n",
      "train loss:0.012296515297831054\n",
      "train loss:0.00029624407820576243\n",
      "train loss:0.0003542564398175821\n",
      "train loss:0.00031572820211051657\n",
      "train loss:0.0004123238465262133\n",
      "train loss:3.43115749294809e-05\n",
      "train loss:0.001702669869829274\n",
      "train loss:0.002093870040397956\n",
      "train loss:0.0002831659575442205\n",
      "train loss:0.0009286145555826319\n",
      "train loss:0.0017701651949242278\n",
      "train loss:0.0095888650256135\n",
      "train loss:0.002122776675091349\n",
      "train loss:0.0004933609398549643\n",
      "train loss:0.0006608065225789086\n",
      "train loss:0.0023758623499279025\n",
      "train loss:0.004397730808812326\n",
      "=== epoch:18, train acc:0.999, test acc:0.988 ===\n",
      "train loss:0.0004411765421997785\n",
      "train loss:0.003403358406422187\n",
      "train loss:6.341534857766493e-05\n",
      "train loss:0.00034660827033732895\n",
      "train loss:0.00027418012215917514\n",
      "train loss:0.00020741386924753966\n",
      "train loss:0.0008938498082716774\n",
      "train loss:0.00042991652677448067\n",
      "train loss:0.0061088253840705905\n",
      "train loss:0.012049231006417981\n",
      "train loss:0.0002549058343290438\n",
      "train loss:0.0015394712169450996\n",
      "train loss:0.0009340098931489979\n",
      "train loss:0.00010959839756169592\n",
      "train loss:0.00241827210090608\n",
      "train loss:0.0035744516328785753\n",
      "train loss:0.00021810959611999304\n",
      "train loss:0.0012141382787555608\n",
      "train loss:3.923449276167409e-05\n",
      "train loss:0.0006554635202326066\n",
      "train loss:0.0006164221977404835\n",
      "train loss:0.0005214887176471179\n",
      "train loss:0.0002892151244059894\n",
      "train loss:0.001403718401081765\n",
      "train loss:0.022810599998419244\n",
      "train loss:0.001632802748431688\n",
      "train loss:0.0025588345244996298\n",
      "train loss:0.00015865049011922437\n",
      "train loss:0.00021515555389309057\n",
      "train loss:0.0016483340839571253\n",
      "train loss:0.003030037452702085\n",
      "train loss:0.006435838764145536\n",
      "train loss:0.0015672884945753134\n",
      "train loss:0.0038553782221730525\n",
      "train loss:0.0022643557604215573\n",
      "train loss:0.0006707546403019252\n",
      "train loss:0.0003145993681679589\n",
      "train loss:0.002692756349191612\n",
      "train loss:0.0009434088388634047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0007865894515477294\n",
      "train loss:0.0015169506667719263\n",
      "train loss:0.0015301335306656559\n",
      "train loss:0.0009012963124311977\n",
      "train loss:9.14932798529015e-05\n",
      "train loss:0.0012536873505439505\n",
      "train loss:0.00019251335775756116\n",
      "train loss:0.0009988875196726488\n",
      "train loss:0.08145177680428847\n",
      "train loss:0.0004233855344523715\n",
      "train loss:0.0014703023310895524\n",
      "train loss:0.0030649235824136423\n",
      "train loss:0.0001707619313641927\n",
      "train loss:0.0014184665731491342\n",
      "train loss:0.0003059689684521559\n",
      "train loss:0.0009544545076633679\n",
      "train loss:0.005687989598792097\n",
      "train loss:0.0003782872875527653\n",
      "train loss:9.877097281764231e-05\n",
      "train loss:0.00012306689591695896\n",
      "train loss:0.000254499839943244\n",
      "train loss:0.0017356505271238843\n",
      "train loss:0.00010317079769709057\n",
      "train loss:0.00039533135143188605\n",
      "train loss:0.003718964133722002\n",
      "train loss:0.0005407958887598207\n",
      "train loss:0.0009201912348942976\n",
      "train loss:0.0039819218740428245\n",
      "train loss:0.010853695308101987\n",
      "train loss:0.0002137836452120013\n",
      "train loss:0.0011358251786700443\n",
      "train loss:0.0011935331015316035\n",
      "train loss:0.0018555542167778309\n",
      "train loss:0.0018361245763292742\n",
      "train loss:0.000371849907280272\n",
      "train loss:0.0006763583360472461\n",
      "train loss:0.001226286097958453\n",
      "train loss:0.00360314331125545\n",
      "train loss:0.0034842005425626456\n",
      "train loss:0.0017400057116635215\n",
      "train loss:0.0034007900241064576\n",
      "train loss:0.00035501646340445006\n",
      "train loss:0.00036784089096058366\n",
      "train loss:0.0001110619086626736\n",
      "train loss:0.0008389976339664336\n",
      "train loss:0.0005084262810341223\n",
      "train loss:0.00040110911009041245\n",
      "train loss:0.0005365931989581269\n",
      "train loss:0.004736872190361128\n",
      "train loss:8.978356239651864e-05\n",
      "train loss:0.00041264924529047344\n",
      "train loss:0.0012634761888103193\n",
      "train loss:0.001167690157772348\n",
      "train loss:0.004580291702802494\n",
      "train loss:0.0003310324025016433\n",
      "train loss:0.002176619020055959\n",
      "train loss:0.0005614850267905825\n",
      "train loss:0.0020706804582052416\n",
      "train loss:0.0005559798760939891\n",
      "train loss:0.003959194940591068\n",
      "train loss:0.0023204530428811037\n",
      "train loss:0.0008846440083244998\n",
      "train loss:0.00014932466330540894\n",
      "train loss:0.0001080390730363354\n",
      "train loss:0.0030891320561800247\n",
      "train loss:0.001080712163416942\n",
      "train loss:0.00016544976820135994\n",
      "train loss:0.0012559940494366057\n",
      "train loss:0.0016494518177469952\n",
      "train loss:0.00014828465928787304\n",
      "train loss:0.0002857708447965442\n",
      "train loss:8.42883554488607e-05\n",
      "train loss:0.0017136865492095707\n",
      "train loss:7.579155290216545e-05\n",
      "train loss:2.238517379658609e-05\n",
      "train loss:0.001471677404859387\n",
      "train loss:0.0008319417175243353\n",
      "train loss:0.00020504099622934937\n",
      "train loss:0.004393961185198903\n",
      "train loss:0.0008353607330453942\n",
      "train loss:0.003366027643419375\n",
      "train loss:0.00046723011808163725\n",
      "train loss:0.004202372208234374\n",
      "train loss:0.00029311827976255436\n",
      "train loss:0.00020672309636431425\n",
      "train loss:0.0047124108424625045\n",
      "train loss:0.00033406510239612086\n",
      "train loss:0.0002559531945761967\n",
      "train loss:0.0012343010696212026\n",
      "train loss:0.0015039320601904762\n",
      "train loss:0.0034658893564137993\n",
      "train loss:0.00045545664823622975\n",
      "train loss:0.00027559319698271446\n",
      "train loss:0.0006836744721985022\n",
      "train loss:0.0003732172969090932\n",
      "train loss:0.0009962184361126047\n",
      "train loss:0.0009823328740954478\n",
      "train loss:0.0011962759933119792\n",
      "train loss:0.0002473086678538979\n",
      "train loss:0.0005737139793702\n",
      "train loss:0.0005447170810367817\n",
      "train loss:0.0003341601716812169\n",
      "train loss:5.868826559576148e-05\n",
      "train loss:0.00012284677472661123\n",
      "train loss:0.0004511455073391957\n",
      "train loss:0.0008978841313878912\n",
      "train loss:0.0011615736022165105\n",
      "train loss:0.001864010382836964\n",
      "train loss:0.0008453319044352021\n",
      "train loss:0.0009521800505644183\n",
      "train loss:0.00012490311938844197\n",
      "train loss:0.0002644116238752135\n",
      "train loss:0.0001786602614506078\n",
      "train loss:0.000952740484651776\n",
      "train loss:0.0005699136243971467\n",
      "train loss:0.0008598162842501172\n",
      "train loss:0.002568341573664869\n",
      "train loss:0.00031413256607048525\n",
      "train loss:0.00012900521606819577\n",
      "train loss:8.69098539843756e-05\n",
      "train loss:0.0003708554982657925\n",
      "train loss:0.0003641237167090613\n",
      "train loss:0.004549891967944342\n",
      "train loss:0.00021467827156833346\n",
      "train loss:0.0017043779985558478\n",
      "train loss:0.001510614735874451\n",
      "train loss:0.0003846420359407024\n",
      "train loss:0.0005242109676782245\n",
      "train loss:8.91160638416397e-05\n",
      "train loss:0.0003152944841114469\n",
      "train loss:0.00016480100391242405\n",
      "train loss:6.695122066712291e-05\n",
      "train loss:0.0036942800044494723\n",
      "train loss:0.002133449034961734\n",
      "train loss:0.0011475837814526545\n",
      "train loss:0.0003575029558962729\n",
      "train loss:0.00024074672020567723\n",
      "train loss:0.012230048420634496\n",
      "train loss:0.009051625821181481\n",
      "train loss:7.582591758145614e-05\n",
      "train loss:0.0005337542216684681\n",
      "train loss:0.0008756599595151162\n",
      "train loss:0.00048021478070375665\n",
      "train loss:0.0022881183421666344\n",
      "train loss:0.00020632692361083436\n",
      "train loss:0.0010813618793004897\n",
      "train loss:0.0008263363798900027\n",
      "train loss:0.0008328672559203709\n",
      "train loss:0.007755921105862293\n",
      "train loss:0.0011393144652363703\n",
      "train loss:0.00018205592876128804\n",
      "train loss:0.01424652660728799\n",
      "train loss:0.00016010421203086652\n",
      "train loss:0.001730376192341041\n",
      "train loss:0.00013060567281518288\n",
      "train loss:0.000656261473548809\n",
      "train loss:0.016681856643896705\n",
      "train loss:0.0012367672740877934\n",
      "train loss:0.00035946852947929596\n",
      "train loss:0.0019534322794189144\n",
      "train loss:0.0013070123177581067\n",
      "train loss:0.00025837368356985345\n",
      "train loss:0.0002790816453270143\n",
      "train loss:0.011081736432711497\n",
      "train loss:0.0015914943763805534\n",
      "train loss:0.00022848053613512738\n",
      "train loss:0.0017504123857682201\n",
      "train loss:0.0007654523560456992\n",
      "train loss:0.004672923957007547\n",
      "train loss:0.0005014667407951599\n",
      "train loss:0.0009134879025493803\n",
      "train loss:0.0016603688509722542\n",
      "train loss:0.0026447194323642453\n",
      "train loss:0.0001629990517248277\n",
      "train loss:0.00018790262573160674\n",
      "train loss:0.021738100609558927\n",
      "train loss:0.00048425560351094825\n",
      "train loss:0.007066825252304251\n",
      "train loss:0.0022561465244003254\n",
      "train loss:0.0009039722351605853\n",
      "train loss:0.001897213670097514\n",
      "train loss:0.0006103209292914423\n",
      "train loss:0.005228221172508279\n",
      "train loss:0.0017986386413250657\n",
      "train loss:0.0004155334584545953\n",
      "train loss:3.1720232121094536e-05\n",
      "train loss:0.00044274650931481216\n",
      "train loss:0.00015951810711523472\n",
      "train loss:0.01550574616803554\n",
      "train loss:0.00019968937359855803\n",
      "train loss:0.0005578318971635271\n",
      "train loss:0.001283918252057511\n",
      "train loss:0.004184556130314427\n",
      "train loss:0.001676709738591309\n",
      "train loss:0.00013673218221627547\n",
      "train loss:0.000830467788966328\n",
      "train loss:0.002710996802184772\n",
      "train loss:0.0004434794591942029\n",
      "train loss:0.00043395284507712024\n",
      "train loss:0.0018530221948417607\n",
      "train loss:5.4050796998837043e-05\n",
      "train loss:0.0005731513674198629\n",
      "train loss:0.00011499205310035065\n",
      "train loss:0.0003516139654157826\n",
      "train loss:0.0005465471893281672\n",
      "train loss:6.161471833928856e-05\n",
      "train loss:0.0017852521931892493\n",
      "train loss:0.0016234145076715431\n",
      "train loss:0.0026611567491279645\n",
      "train loss:9.497335574791778e-05\n",
      "train loss:0.0004099221700387911\n",
      "train loss:9.456682168354192e-05\n",
      "train loss:0.0006305968925220749\n",
      "train loss:0.0016320183315019477\n",
      "train loss:0.0009082746478039276\n",
      "train loss:9.025021487163723e-05\n",
      "train loss:0.000563649966774234\n",
      "train loss:0.0017137983253214656\n",
      "train loss:0.0005578033964063203\n",
      "train loss:0.0016088377772032236\n",
      "train loss:1.699566163302721e-05\n",
      "train loss:0.0004056565342886372\n",
      "train loss:0.0013740852759011846\n",
      "train loss:0.00032195654906729763\n",
      "train loss:0.0058457783046390955\n",
      "train loss:1.7644732729425077e-05\n",
      "train loss:0.0002526867769991414\n",
      "train loss:0.001580135164442364\n",
      "train loss:0.003738754669161593\n",
      "train loss:4.959875523266137e-05\n",
      "train loss:4.3550849619652527e-05\n",
      "train loss:6.0787072549089883e-05\n",
      "train loss:0.0014655816844482764\n",
      "train loss:0.00023093547415065058\n",
      "train loss:0.0011363303038646516\n",
      "train loss:6.71905784640979e-05\n",
      "train loss:3.8515296457971297e-05\n",
      "train loss:0.00016959392668652455\n",
      "train loss:0.0007131765031424521\n",
      "train loss:0.0006780860895367255\n",
      "train loss:0.0015374106481062194\n",
      "train loss:0.0007210955401011833\n",
      "train loss:0.00041300980508165357\n",
      "train loss:0.0009224917626372004\n",
      "train loss:0.0028339352460077082\n",
      "train loss:0.0005293416418074982\n",
      "train loss:0.010471397581521437\n",
      "train loss:6.514841254760818e-05\n",
      "train loss:0.0007547897634860138\n",
      "train loss:0.0016946229035427179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0008403496020104879\n",
      "train loss:0.0004931367319573512\n",
      "train loss:0.0010872749245562788\n",
      "train loss:0.0013421476485319529\n",
      "train loss:0.000756074099013138\n",
      "train loss:0.0049649323791523025\n",
      "train loss:0.0008535651445384343\n",
      "train loss:0.005674603908772272\n",
      "train loss:0.0014842009489768953\n",
      "train loss:0.0002993735707199056\n",
      "train loss:0.0008795758205678974\n",
      "train loss:0.00034631967650645225\n",
      "train loss:0.0010959156248579894\n",
      "train loss:0.0002791667256797534\n",
      "train loss:0.004615775342486906\n",
      "train loss:0.00015118164155105183\n",
      "train loss:0.00034339089882411274\n",
      "train loss:3.896834656699715e-05\n",
      "train loss:0.0021915013265825806\n",
      "train loss:0.0026906448280014524\n",
      "train loss:5.7572541154551065e-05\n",
      "train loss:0.00029596603085927606\n",
      "train loss:6.226057926949803e-05\n",
      "train loss:3.359665328921448e-05\n",
      "train loss:0.0012995097911480315\n",
      "train loss:9.619202142598194e-05\n",
      "train loss:0.0004244787896450309\n",
      "train loss:0.00018295918011783724\n",
      "train loss:0.0020774632326985023\n",
      "train loss:0.0010548032065533781\n",
      "train loss:5.688284840426819e-05\n",
      "train loss:0.00040447896377226615\n",
      "train loss:0.0007726776687169983\n",
      "train loss:0.0014941017316873425\n",
      "train loss:0.0003699239220896147\n",
      "train loss:7.592211480936583e-05\n",
      "train loss:0.00029491789844627333\n",
      "train loss:0.0002604676902654476\n",
      "train loss:0.0004252764689486935\n",
      "train loss:0.0023874300491544837\n",
      "train loss:0.00029519370579524936\n",
      "train loss:0.02549165622079133\n",
      "train loss:0.00010969985772825463\n",
      "train loss:0.0007592843700609476\n",
      "train loss:0.0005603373932727433\n",
      "train loss:0.000580016846317694\n",
      "train loss:0.0013345976200747408\n",
      "train loss:0.0031943718740063257\n",
      "train loss:2.4931444074310716e-05\n",
      "train loss:0.0008268453149287533\n",
      "train loss:0.00030398864183842555\n",
      "train loss:0.001515583814486584\n",
      "train loss:0.00012140905451343693\n",
      "train loss:0.0008618657872662159\n",
      "train loss:0.00012406509879112686\n",
      "train loss:0.0001533220469870162\n",
      "train loss:0.00031089348926512545\n",
      "train loss:0.0016647765694570624\n",
      "train loss:0.0010472772768434638\n",
      "train loss:0.015697422658161795\n",
      "train loss:0.0028088773304712667\n",
      "train loss:0.0040729175895435135\n",
      "train loss:5.406869459299033e-05\n",
      "train loss:8.547069727915352e-05\n",
      "train loss:0.00043008918648447053\n",
      "train loss:2.5708722241205348e-05\n",
      "train loss:0.000685992324203244\n",
      "train loss:0.0017815726135495056\n",
      "train loss:0.0009651519508761682\n",
      "train loss:3.079774569201788e-05\n",
      "train loss:0.0003257150307500731\n",
      "train loss:0.0006324632165025835\n",
      "train loss:0.0003367662583523804\n",
      "train loss:0.0002557193280922137\n",
      "train loss:0.0020976488122373756\n",
      "train loss:6.36497854819907e-05\n",
      "train loss:0.00020458496204237765\n",
      "train loss:0.0012901730969562752\n",
      "train loss:0.0017820046873423382\n",
      "train loss:0.0003721291506463134\n",
      "train loss:7.65708874149748e-05\n",
      "train loss:0.0018180377533670823\n",
      "train loss:0.0008269848147995755\n",
      "train loss:0.0007002206957344613\n",
      "train loss:0.0029691730531459398\n",
      "train loss:0.00030165872735476654\n",
      "train loss:0.00022393212481147106\n",
      "train loss:0.0009866916103305138\n",
      "train loss:0.00010398105719170552\n",
      "train loss:0.000776440671186944\n",
      "train loss:0.00011690958985484687\n",
      "train loss:0.00170467014467304\n",
      "train loss:5.887965587478504e-05\n",
      "train loss:6.75072267606452e-05\n",
      "train loss:0.000514061613004233\n",
      "train loss:0.0024225159977539603\n",
      "train loss:0.00019189966307307598\n",
      "train loss:0.00021511383035689702\n",
      "train loss:2.4944116851342042e-05\n",
      "train loss:0.00026097712596581186\n",
      "train loss:0.0007000583658975409\n",
      "train loss:2.2858486575565518e-05\n",
      "train loss:0.00013587690590303414\n",
      "train loss:0.0023594161855627852\n",
      "train loss:0.00012062690843759874\n",
      "train loss:0.0008800425285635153\n",
      "train loss:0.0006619805829811114\n",
      "train loss:7.058369894835808e-05\n",
      "train loss:0.00011300077087945013\n",
      "train loss:0.00021792261996765288\n",
      "train loss:0.0003391603766391203\n",
      "train loss:1.47036064073398e-05\n",
      "train loss:0.00011309176841136899\n",
      "train loss:3.0576427205126424e-05\n",
      "train loss:0.00033423276062503643\n",
      "train loss:0.00032459886410452936\n",
      "train loss:0.0004444969160602776\n",
      "train loss:0.00027755123758311536\n",
      "train loss:0.0002883137729910566\n",
      "train loss:0.0008604684401553718\n",
      "train loss:3.293287395507445e-05\n",
      "train loss:0.0014709539902834615\n",
      "train loss:0.0009206371939046647\n",
      "train loss:4.020879735419306e-05\n",
      "train loss:0.0006186099511774402\n",
      "train loss:6.120098769286696e-05\n",
      "train loss:0.0004629983825498092\n",
      "train loss:2.553123322427628e-05\n",
      "train loss:0.002557946512147201\n",
      "train loss:0.0015829830802153854\n",
      "train loss:0.00033945753075306757\n",
      "train loss:0.00011812142704166919\n",
      "train loss:0.001109387682423277\n",
      "train loss:0.0003240991693247448\n",
      "train loss:0.00022505167401854894\n",
      "train loss:0.001806732030138028\n",
      "train loss:0.0005875575088394263\n",
      "train loss:0.0002865056073968291\n",
      "train loss:7.06510044912832e-05\n",
      "train loss:2.507039520080519e-05\n",
      "train loss:0.00567546212230505\n",
      "train loss:0.0016754313627710055\n",
      "train loss:0.0005963725748192712\n",
      "train loss:0.0012246948476365503\n",
      "train loss:0.00017861661011891954\n",
      "train loss:0.0002673224678348769\n",
      "train loss:0.00011361094600039089\n",
      "train loss:0.0008313904892470297\n",
      "train loss:0.0024439395926042816\n",
      "train loss:0.0006252595944466748\n",
      "train loss:1.995218743747047e-05\n",
      "train loss:0.00013348524230112946\n",
      "train loss:0.00015624299778789033\n",
      "train loss:0.00021694355680302417\n",
      "train loss:0.002038959716866689\n",
      "train loss:0.0015724922054579206\n",
      "train loss:0.00034427823919741133\n",
      "train loss:0.0018891559718525743\n",
      "train loss:0.0004419725674958978\n",
      "train loss:0.0016022840416153423\n",
      "train loss:0.0005185499301045524\n",
      "train loss:2.6906538472123206e-05\n",
      "train loss:0.0008298323396525157\n",
      "train loss:0.0001020767785969089\n",
      "train loss:0.00015173908697594082\n",
      "train loss:0.0012640244220353664\n",
      "train loss:0.0014545152335304116\n",
      "train loss:0.0009897757530664343\n",
      "train loss:0.0006144630787992486\n",
      "train loss:0.00024755264352124747\n",
      "train loss:0.0017498810382538482\n",
      "train loss:0.002326734559869286\n",
      "train loss:0.00013757791554408925\n",
      "train loss:0.00016968767314478963\n",
      "train loss:0.00046711082434808113\n",
      "train loss:0.00038994243603395157\n",
      "train loss:0.001890006253329032\n",
      "train loss:0.000294876096087363\n",
      "train loss:0.0017987502705072425\n",
      "train loss:0.0001254335986212208\n",
      "train loss:0.00010049738953082585\n",
      "train loss:8.078042579258768e-05\n",
      "train loss:9.260290896151319e-05\n",
      "train loss:0.00045992858408509606\n",
      "train loss:0.0002229585672968049\n",
      "train loss:0.0003368282786233444\n",
      "train loss:0.0005056568780578127\n",
      "train loss:0.004261949764388619\n",
      "train loss:0.0018298499369695331\n",
      "train loss:0.001035099686076573\n",
      "train loss:0.0024649812222333426\n",
      "train loss:5.389502847175725e-06\n",
      "train loss:0.000484356892300295\n",
      "train loss:1.0657194440418293e-05\n",
      "train loss:0.0003587205004176399\n",
      "train loss:2.308444451400976e-05\n",
      "train loss:0.00018249354174342807\n",
      "train loss:0.0013561228829367005\n",
      "train loss:0.0005081969636514786\n",
      "train loss:0.002880069264406201\n",
      "train loss:0.00022479135732178868\n",
      "train loss:0.0014378716407983305\n",
      "train loss:0.00046903477092700817\n",
      "train loss:9.278713167740741e-05\n",
      "train loss:0.00013104277487441357\n",
      "train loss:0.00018259802128786092\n",
      "train loss:0.0006651161498588266\n",
      "train loss:2.120987550604241e-05\n",
      "train loss:0.0012750047283299184\n",
      "train loss:8.580812463446509e-05\n",
      "train loss:5.251654622044059e-05\n",
      "train loss:7.233502914415117e-05\n",
      "train loss:0.000492831208383409\n",
      "train loss:8.236871606874741e-05\n",
      "train loss:0.0008778527556943102\n",
      "train loss:0.0001061047752111875\n",
      "train loss:0.0019154689366930849\n",
      "train loss:0.00018306140288274877\n",
      "train loss:0.0003614404344567828\n",
      "train loss:0.001648595419089003\n",
      "train loss:7.5741081318754534e-06\n",
      "train loss:0.00011748777690583015\n",
      "train loss:0.0006504212187590016\n",
      "train loss:0.0006830532812248981\n",
      "train loss:0.0013150398316577876\n",
      "train loss:0.0015089357985277419\n",
      "train loss:0.0006539737097283433\n",
      "train loss:0.0003230234754124321\n",
      "train loss:0.00015978197755168183\n",
      "train loss:0.00016693851118944274\n",
      "train loss:0.0007693649744255486\n",
      "train loss:0.001052677664706306\n",
      "train loss:0.00046578222552337437\n",
      "train loss:0.0009009329885274034\n",
      "train loss:0.0007793876895029269\n",
      "train loss:0.00034538051726071815\n",
      "train loss:0.0001058017065036234\n",
      "train loss:0.001339709573868878\n",
      "train loss:0.004837494063953096\n",
      "train loss:0.0012981063112277157\n",
      "train loss:0.00040553875210926066\n",
      "train loss:5.8843260120146816e-05\n",
      "train loss:0.004600888652410049\n",
      "train loss:0.00012361323948580517\n",
      "train loss:0.0005249151103152482\n",
      "train loss:0.0005784699999125006\n",
      "train loss:0.00018622965415813084\n",
      "train loss:0.0007541937243017092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0020899961802103737\n",
      "train loss:9.380896042737017e-05\n",
      "train loss:0.0011502016772133065\n",
      "train loss:0.0014101375191630033\n",
      "train loss:0.0002766491775485939\n",
      "train loss:0.000474631703487499\n",
      "train loss:3.563299975593322e-05\n",
      "train loss:0.0007670570671548348\n",
      "train loss:0.00025955722297252683\n",
      "train loss:0.001064907814425024\n",
      "train loss:0.0003507806112351646\n",
      "train loss:0.000583610248957412\n",
      "train loss:3.158432423035607e-05\n",
      "train loss:0.0003391865750421401\n",
      "train loss:0.0022056785646380377\n",
      "train loss:0.002005076074122843\n",
      "train loss:0.0008671838577605952\n",
      "train loss:0.0004467773349715065\n",
      "train loss:0.017057958330286848\n",
      "train loss:0.00045614687834751966\n",
      "train loss:0.00040426303376302333\n",
      "train loss:0.0004755911527932682\n",
      "train loss:0.0004427439353122036\n",
      "train loss:0.04872156920341431\n",
      "train loss:0.00022136448766205664\n",
      "train loss:6.408754657390508e-05\n",
      "train loss:0.0009495098884820531\n",
      "train loss:0.0001347190057376991\n",
      "train loss:0.00016340095243606547\n",
      "train loss:0.001990144577136994\n",
      "train loss:0.0006484035432600859\n",
      "train loss:0.0005438910810146292\n",
      "train loss:0.0015436507408653122\n",
      "train loss:0.0001598294412148963\n",
      "train loss:0.00031942579499901917\n",
      "train loss:0.00017773901589659464\n",
      "train loss:7.687671182875702e-06\n",
      "train loss:0.0009960194191180993\n",
      "train loss:1.722974362910782e-05\n",
      "train loss:0.0017593927692289369\n",
      "train loss:0.0006717083090706403\n",
      "train loss:8.891374075155456e-05\n",
      "train loss:0.00019388737787918176\n",
      "train loss:0.0016017415086310787\n",
      "train loss:0.00011765447782845602\n",
      "train loss:9.108308218297929e-05\n",
      "train loss:0.0003510826736454683\n",
      "train loss:0.0001440368309562148\n",
      "train loss:9.461918874634846e-05\n",
      "train loss:0.0004897442434147787\n",
      "train loss:0.000758858167127594\n",
      "train loss:0.000474408407750557\n",
      "train loss:0.00018932278783739798\n",
      "train loss:0.0002266899322190531\n",
      "train loss:0.0017029304297396224\n",
      "train loss:0.0006971138883201891\n",
      "train loss:0.0007194691821802856\n",
      "train loss:0.0006105004270474808\n",
      "train loss:0.00011120001419705737\n",
      "train loss:0.000852613079977961\n",
      "train loss:0.0012349817110048212\n",
      "train loss:0.0016140430361252255\n",
      "train loss:0.002003808085805817\n",
      "=== epoch:19, train acc:1.0, test acc:0.987 ===\n",
      "train loss:2.0823460461513022e-05\n",
      "train loss:0.0004142868245068286\n",
      "train loss:0.0008128201585148483\n",
      "train loss:0.002578803732443435\n",
      "train loss:0.0015306222876885602\n",
      "train loss:9.137732581147562e-05\n",
      "train loss:0.0024284154579317947\n",
      "train loss:7.201743477852882e-05\n",
      "train loss:0.0002702335586814078\n",
      "train loss:0.0007219405224506496\n",
      "train loss:0.003396719232740609\n",
      "train loss:0.00021713604183687312\n",
      "train loss:0.0009174245260973214\n",
      "train loss:0.00019372055464347455\n",
      "train loss:0.00025692465334678575\n",
      "train loss:0.00014483445992115725\n",
      "train loss:0.001968642305366856\n",
      "train loss:0.000996577643220247\n",
      "train loss:0.0005378935163615209\n",
      "train loss:0.0006862493134001151\n",
      "train loss:0.002746780276395324\n",
      "train loss:0.0005546056924416872\n",
      "train loss:0.0010121269986640197\n",
      "train loss:0.0003875041574591509\n",
      "train loss:0.0014004350346438885\n",
      "train loss:3.560426547678978e-05\n",
      "train loss:0.000553807575096435\n",
      "train loss:0.00011025302513342952\n",
      "train loss:0.0004141212823059662\n",
      "train loss:0.00012749079621223052\n",
      "train loss:0.00041507253258543756\n",
      "train loss:0.0027250591215492986\n",
      "train loss:0.0001564318864527519\n",
      "train loss:0.024078385846250046\n",
      "train loss:0.0002962940658230207\n",
      "train loss:0.0007952303090549065\n",
      "train loss:0.0003683070793506651\n",
      "train loss:0.0007717545995917871\n",
      "train loss:0.00027969347405789935\n",
      "train loss:0.0010481230450721409\n",
      "train loss:0.00015771248809455372\n",
      "train loss:0.00019981940100917384\n",
      "train loss:0.004595088911227243\n",
      "train loss:0.00043344086712380646\n",
      "train loss:0.0003545431445466435\n",
      "train loss:5.070395040150516e-05\n",
      "train loss:0.002916246300759892\n",
      "train loss:0.0021635121090174693\n",
      "train loss:0.0003916852754693131\n",
      "train loss:0.0008537692015332741\n",
      "train loss:0.0010864678915961116\n",
      "train loss:0.001043592603698435\n",
      "train loss:0.00016739591039535066\n",
      "train loss:8.512060053095591e-05\n",
      "train loss:0.0003653478498183654\n",
      "train loss:0.0016611904565391978\n",
      "train loss:0.0006041679983995794\n",
      "train loss:0.0010445366090083253\n",
      "train loss:0.01325386964405302\n",
      "train loss:3.3152936830316264e-06\n",
      "train loss:0.0004566398368231479\n",
      "train loss:0.00015630592333347828\n",
      "train loss:0.0005250222146772859\n",
      "train loss:0.00040771170463513133\n",
      "train loss:4.703280424487258e-05\n",
      "train loss:0.00030814595999154726\n",
      "train loss:0.0016853339538570559\n",
      "train loss:0.0025427648019014865\n",
      "train loss:0.0006186710554277844\n",
      "train loss:0.0007396629141291803\n",
      "train loss:6.917447744046784e-05\n",
      "train loss:0.001071493775223652\n",
      "train loss:0.001156486576527565\n",
      "train loss:0.00019747508997661138\n",
      "train loss:0.001275625634907533\n",
      "train loss:0.0028362585215637444\n",
      "train loss:0.001283221886706487\n",
      "train loss:9.469003606029652e-05\n",
      "train loss:0.0002997055425099099\n",
      "train loss:0.0023688022717650737\n",
      "train loss:0.00029446527206469894\n",
      "train loss:0.004772445303991544\n",
      "train loss:7.366215541027677e-05\n",
      "train loss:5.116481268792848e-05\n",
      "train loss:0.0002964271061348778\n",
      "train loss:0.00015036369322724927\n",
      "train loss:0.0011335347469481438\n",
      "train loss:0.001343637350564113\n",
      "train loss:0.00022426430793021402\n",
      "train loss:0.0026416326095325317\n",
      "train loss:0.00045265071805074004\n",
      "train loss:0.0008222802789363994\n",
      "train loss:0.0003655990988582528\n",
      "train loss:0.0004180879568186735\n",
      "train loss:5.524044638001021e-05\n",
      "train loss:0.0005752918347660392\n",
      "train loss:0.00052844204711949\n",
      "train loss:0.0017204659796179042\n",
      "train loss:0.0010598043801604356\n",
      "train loss:0.0010371320033767996\n",
      "train loss:0.0013018365401997222\n",
      "train loss:0.0011924839352372406\n",
      "train loss:0.001808516701522528\n",
      "train loss:0.00027300507484963446\n",
      "train loss:0.0010674793556828103\n",
      "train loss:0.0010862211128278387\n",
      "train loss:0.00017824319866361068\n",
      "train loss:6.573011700943984e-05\n",
      "train loss:3.713953009540842e-05\n",
      "train loss:0.0002479968138718779\n",
      "train loss:0.00179436987684808\n",
      "train loss:0.00016541526733822797\n",
      "train loss:0.0002646888107875727\n",
      "train loss:0.000172898893366387\n",
      "train loss:0.0005237164209336588\n",
      "train loss:0.0001963801942686511\n",
      "train loss:0.00016336537125072545\n",
      "train loss:0.0033247130107671814\n",
      "train loss:0.00010674851535365453\n",
      "train loss:0.00014923729272339943\n",
      "train loss:0.001357913739119514\n",
      "train loss:0.00018161794161193168\n",
      "train loss:0.0009201301253670879\n",
      "train loss:0.0019835103833243566\n",
      "train loss:0.0004540208838568641\n",
      "train loss:0.0015339636697418607\n",
      "train loss:0.00045222672240843674\n",
      "train loss:0.00010063154427037967\n",
      "train loss:0.0015660430070758998\n",
      "train loss:0.008423676565458628\n",
      "train loss:0.0008923409582925854\n",
      "train loss:7.063523223472924e-05\n",
      "train loss:0.000979403613028711\n",
      "train loss:0.0005521046139752286\n",
      "train loss:0.001941992928289674\n",
      "train loss:0.0003543747487693014\n",
      "train loss:0.00021605113237699384\n",
      "train loss:0.0010540273723023846\n",
      "train loss:0.0011278192194648024\n",
      "train loss:0.0018634222519362362\n",
      "train loss:0.0007884838672613992\n",
      "train loss:0.002057344847393835\n",
      "train loss:0.000903484265684584\n",
      "train loss:0.0006035092306013816\n",
      "train loss:0.000291275331523666\n",
      "train loss:0.0007137463771504206\n",
      "train loss:0.0007850596425179727\n",
      "train loss:0.00017305810941248663\n",
      "train loss:0.00030430490817067617\n",
      "train loss:0.00018646608391328\n",
      "train loss:0.0018914637112410274\n",
      "train loss:0.0004074591231090192\n",
      "train loss:0.0013755939648549367\n",
      "train loss:0.0010431682786705234\n",
      "train loss:0.0003754046893987696\n",
      "train loss:0.0001452607960457585\n",
      "train loss:0.0013742164985854545\n",
      "train loss:0.00015203127312594068\n",
      "train loss:0.0015916750932048473\n",
      "train loss:0.001091677504814452\n",
      "train loss:0.0013654336542114993\n",
      "train loss:0.00018753047477377386\n",
      "train loss:0.0001445759889531371\n",
      "train loss:0.00014599734869651814\n",
      "train loss:2.430932199273943e-05\n",
      "train loss:0.0032032958588782325\n",
      "train loss:0.0018193981224193289\n",
      "train loss:0.00850013734784946\n",
      "train loss:0.0002897723914718943\n",
      "train loss:0.001278879559726603\n",
      "train loss:0.0009398884078074379\n",
      "train loss:0.0003226582573854515\n",
      "train loss:0.0007073481163460156\n",
      "train loss:0.002015579904708917\n",
      "train loss:0.002702153724037976\n",
      "train loss:0.0027755515989199607\n",
      "train loss:0.0006152877239853472\n",
      "train loss:0.0021437371032736272\n",
      "train loss:0.0007828987313673303\n",
      "train loss:0.0007155367797197597\n",
      "train loss:0.0007436349524658288\n",
      "train loss:0.00023344977448335597\n",
      "train loss:0.0006909976718278355\n",
      "train loss:0.000500232534584999\n",
      "train loss:0.0005215050938547042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004833044324872217\n",
      "train loss:0.0007501411309753198\n",
      "train loss:0.0008113555551467929\n",
      "train loss:0.00027280421228241037\n",
      "train loss:0.0008120616645190725\n",
      "train loss:0.00020629663850560577\n",
      "train loss:0.0008349153643967336\n",
      "train loss:0.00025586935685764824\n",
      "train loss:0.0008910727215405393\n",
      "train loss:0.0005742701725416242\n",
      "train loss:4.135300776174909e-05\n",
      "train loss:0.0009269673853514792\n",
      "train loss:0.0009690015488156349\n",
      "train loss:0.00029706255662679675\n",
      "train loss:0.00029347949214332764\n",
      "train loss:0.0006350933174931957\n",
      "train loss:0.004157082082434296\n",
      "train loss:0.000684110153535783\n",
      "train loss:0.0003519310399539386\n",
      "train loss:0.00026935592186101134\n",
      "train loss:0.0003301113701096372\n",
      "train loss:0.000303648796651023\n",
      "train loss:0.0005050975955027624\n",
      "train loss:0.0005290580078908825\n",
      "train loss:0.0015304529559171396\n",
      "train loss:0.0006561876912135791\n",
      "train loss:0.00020494735989706509\n",
      "train loss:0.0011278689769402366\n",
      "train loss:0.000624886645967137\n",
      "train loss:0.0002858334731912388\n",
      "train loss:0.00046921961324634926\n",
      "train loss:0.0002229910389295949\n",
      "train loss:0.0012878492759285868\n",
      "train loss:6.025191951642132e-05\n",
      "train loss:0.003304889907655496\n",
      "train loss:0.00023745968479356954\n",
      "train loss:9.739592664291907e-05\n",
      "train loss:0.0015712886008062074\n",
      "train loss:0.0018760037277146106\n",
      "train loss:0.00038333437222983483\n",
      "train loss:0.0006593506088886561\n",
      "train loss:6.567911305456211e-05\n",
      "train loss:0.00011427237208090215\n",
      "train loss:0.0002003254791661649\n",
      "train loss:8.664962446149006e-05\n",
      "train loss:7.94147453661868e-05\n",
      "train loss:0.0018330481816290212\n",
      "train loss:0.0009839027668365127\n",
      "train loss:9.874259579188547e-05\n",
      "train loss:0.0015788955184086713\n",
      "train loss:0.000777036723162584\n",
      "train loss:0.0008213708459203356\n",
      "train loss:0.00010019499957157111\n",
      "train loss:0.0004190478076794997\n",
      "train loss:0.0002477853025740933\n",
      "train loss:0.00045497377148596816\n",
      "train loss:0.00038291701552873106\n",
      "train loss:0.0005114715311831633\n",
      "train loss:0.00721179421409623\n",
      "train loss:0.00040070140140151326\n",
      "train loss:0.0013837151761297635\n",
      "train loss:0.001436436371597971\n",
      "train loss:0.000190051443458549\n",
      "train loss:6.447072703941477e-05\n",
      "train loss:0.0007590969564349523\n",
      "train loss:0.004696609011531341\n",
      "train loss:0.0006827378070199011\n",
      "train loss:1.1205697307177666e-05\n",
      "train loss:0.0009381700575933665\n",
      "train loss:0.006259675755615466\n",
      "train loss:0.0010103355797833225\n",
      "train loss:0.001540639832633559\n",
      "train loss:0.002363914339097662\n",
      "train loss:0.006569101080811038\n",
      "train loss:0.0001035222502053136\n",
      "train loss:0.0019525546716761602\n",
      "train loss:0.0001795614743211666\n",
      "train loss:0.00023833533141582016\n",
      "train loss:0.00048190687600981936\n",
      "train loss:0.0009650025903311733\n",
      "train loss:0.013992038407436003\n",
      "train loss:0.00026616862825261595\n",
      "train loss:0.013399891770081057\n",
      "train loss:0.0008894416571777921\n",
      "train loss:3.91507575842113e-05\n",
      "train loss:0.0009240839239899205\n",
      "train loss:0.024267854286506848\n",
      "train loss:0.0001454980417452355\n",
      "train loss:0.00046492647523268914\n",
      "train loss:0.0008018882328297015\n",
      "train loss:0.00010944279816813986\n",
      "train loss:0.00027117365127300513\n",
      "train loss:0.0005587854610778567\n",
      "train loss:0.009136750538457862\n",
      "train loss:0.00047126825593512075\n",
      "train loss:0.0013372218517891052\n",
      "train loss:0.0034022679348455127\n",
      "train loss:0.0013312916711369373\n",
      "train loss:0.0004939070488628054\n",
      "train loss:0.026502264097098212\n",
      "train loss:0.0021481769913280677\n",
      "train loss:0.0004203539985617051\n",
      "train loss:0.001308949484336205\n",
      "train loss:0.0009200644014047593\n",
      "train loss:0.00441476697952963\n",
      "train loss:0.001198525275290244\n",
      "train loss:0.00012252691688524636\n",
      "train loss:0.0007685946841035337\n",
      "train loss:0.024265703150816168\n",
      "train loss:0.0069340051128109715\n",
      "train loss:0.00045826754677415053\n",
      "train loss:3.0105233181703083e-05\n",
      "train loss:0.00036961082576186875\n",
      "train loss:0.0008842644562107529\n",
      "train loss:0.0018896727522086155\n",
      "train loss:0.0011554761153495297\n",
      "train loss:0.0019222583983312775\n",
      "train loss:0.0001711637056676941\n",
      "train loss:0.0012682089757213675\n",
      "train loss:0.0020908173218651986\n",
      "train loss:0.0012037371534152626\n",
      "train loss:0.001907492791057276\n",
      "train loss:0.0015084587949786414\n",
      "train loss:0.0013406878889919633\n",
      "train loss:0.0027664973654747986\n",
      "train loss:0.0008235003803918657\n",
      "train loss:0.002054674365971722\n",
      "train loss:0.000157899335059091\n",
      "train loss:5.072611058444772e-05\n",
      "train loss:0.001920115034989895\n",
      "train loss:0.001705192461779106\n",
      "train loss:0.002225662298332402\n",
      "train loss:0.0013874422803783018\n",
      "train loss:0.0019416000485826736\n",
      "train loss:0.00017474459813059598\n",
      "train loss:0.0008077702264613912\n",
      "train loss:0.00023339306842481186\n",
      "train loss:0.005350230316757326\n",
      "train loss:0.000653039838364955\n",
      "train loss:0.00012719494223536586\n",
      "train loss:0.0001295632566133135\n",
      "train loss:0.0005929690804200842\n",
      "train loss:0.0023921553800002908\n",
      "train loss:0.0032449602553047806\n",
      "train loss:0.00011403004064229224\n",
      "train loss:0.0004016044570104087\n",
      "train loss:0.0020749517801226277\n",
      "train loss:0.003972948867026378\n",
      "train loss:0.0026144942538928557\n",
      "train loss:0.00041061117680949686\n",
      "train loss:0.0005626666859699467\n",
      "train loss:0.0008040484139511309\n",
      "train loss:0.0008452626130620499\n",
      "train loss:0.0016623112502407833\n",
      "train loss:0.004482124284521712\n",
      "train loss:0.0009975211997068215\n",
      "train loss:0.0021661037846622934\n",
      "train loss:0.001958216375599761\n",
      "train loss:0.001135948999980797\n",
      "train loss:0.0026589777319491847\n",
      "train loss:0.007640943084575511\n",
      "train loss:0.0005083130588367053\n",
      "train loss:0.0021483677446810885\n",
      "train loss:0.0025856087493917913\n",
      "train loss:5.450081385080101e-05\n",
      "train loss:0.0029704379849503516\n",
      "train loss:0.0016657005553480373\n",
      "train loss:0.0006851708651724941\n",
      "train loss:0.0010132981709921763\n",
      "train loss:0.006641380434402767\n",
      "train loss:0.0005059395817395186\n",
      "train loss:0.00040435833885059386\n",
      "train loss:0.0011464617897916456\n",
      "train loss:0.0005296406451636352\n",
      "train loss:0.00014229387034734353\n",
      "train loss:0.005371658109781627\n",
      "train loss:0.00010510749943127434\n",
      "train loss:0.0013289315220155046\n",
      "train loss:0.0004079019445089552\n",
      "train loss:0.00016114977955827836\n",
      "train loss:0.000832829682184324\n",
      "train loss:6.026482710118353e-05\n",
      "train loss:0.0009560413319728493\n",
      "train loss:0.0024729897328788627\n",
      "train loss:0.0022973036063300848\n",
      "train loss:0.00023081555882432158\n",
      "train loss:0.0023220857953911477\n",
      "train loss:0.0007301605785782598\n",
      "train loss:0.02612126146945233\n",
      "train loss:0.0008806785661524535\n",
      "train loss:0.0009825701997380374\n",
      "train loss:0.003820766713544766\n",
      "train loss:0.0002644391398015881\n",
      "train loss:0.00023561183809064047\n",
      "train loss:0.0021461253252537814\n",
      "train loss:0.00046073516912331614\n",
      "train loss:0.00034941650775416653\n",
      "train loss:0.0003549048984725152\n",
      "train loss:0.0015677070682758398\n",
      "train loss:0.0031895191375522756\n",
      "train loss:0.000764919192482951\n",
      "train loss:0.003911620801113548\n",
      "train loss:0.005499256925486751\n",
      "train loss:0.0011444840907745678\n",
      "train loss:0.002126474888455302\n",
      "train loss:0.0013845259162404402\n",
      "train loss:0.001000469279687422\n",
      "train loss:0.00020470524485533987\n",
      "train loss:6.623409719061163e-05\n",
      "train loss:0.0004319444932078683\n",
      "train loss:0.0001641500338588074\n",
      "train loss:0.0011614151972035238\n",
      "train loss:0.00015936127193417682\n",
      "train loss:0.0006186018898503079\n",
      "train loss:0.003672007566188633\n",
      "train loss:0.0002584818160968072\n",
      "train loss:0.00021019213598876755\n",
      "train loss:0.0002586148514236366\n",
      "train loss:0.0019293836155944459\n",
      "train loss:0.0010948838112381561\n",
      "train loss:0.002943024705056541\n",
      "train loss:0.0006388690483676501\n",
      "train loss:0.001215572921158601\n",
      "train loss:0.0002653470605048117\n",
      "train loss:0.0019822237595503393\n",
      "train loss:0.00039740273081115355\n",
      "train loss:0.0010557154279400352\n",
      "train loss:0.0016586446376762557\n",
      "train loss:7.026395688711117e-05\n",
      "train loss:2.4286334084045632e-05\n",
      "train loss:0.0011462357817477776\n",
      "train loss:0.0009241629528686232\n",
      "train loss:7.404331889928958e-05\n",
      "train loss:0.0017226196581646197\n",
      "train loss:0.003677073376839219\n",
      "train loss:0.004391258995474766\n",
      "train loss:3.819754208769662e-05\n",
      "train loss:0.0008464448104344838\n",
      "train loss:0.0007319952820350809\n",
      "train loss:0.00020498259703615208\n",
      "train loss:0.002200329899900019\n",
      "train loss:0.0027329665754485676\n",
      "train loss:0.00013247248999402443\n",
      "train loss:0.0006864548928974174\n",
      "train loss:0.0010627483546014416\n",
      "train loss:0.0002970616057907854\n",
      "train loss:1.582150866217292e-05\n",
      "train loss:0.0011651048499787629\n",
      "train loss:0.0034932119953598084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.001312148006935903\n",
      "train loss:0.0005706559449525344\n",
      "train loss:0.008300734862754119\n",
      "train loss:0.0009028180320905337\n",
      "train loss:0.003245421781487651\n",
      "train loss:0.005870734332676489\n",
      "train loss:5.664182616192457e-05\n",
      "train loss:0.001355036891720941\n",
      "train loss:0.000534608911594418\n",
      "train loss:0.0001490155932060694\n",
      "train loss:4.664016631455775e-05\n",
      "train loss:0.0007360976612709395\n",
      "train loss:0.0027853408308700076\n",
      "train loss:0.0008438416462615015\n",
      "train loss:0.0004351248869141961\n",
      "train loss:0.0013142284418768391\n",
      "train loss:0.0024916409442762816\n",
      "train loss:0.0005168595043537179\n",
      "train loss:0.0004699181735196574\n",
      "train loss:0.0015677327580308933\n",
      "train loss:0.0006449371844829792\n",
      "train loss:0.00015759177723474597\n",
      "train loss:0.0012009018692863522\n",
      "train loss:0.00021572187443500858\n",
      "train loss:0.00030857413691421845\n",
      "train loss:0.0002202702960626881\n",
      "train loss:0.0005593872257864447\n",
      "train loss:0.0010632415678682532\n",
      "train loss:0.0002968203149049917\n",
      "train loss:0.001326943675271012\n",
      "train loss:0.0014492564294263735\n",
      "train loss:0.0010684157061741498\n",
      "train loss:0.0019008969533524578\n",
      "train loss:1.6317819662679618e-05\n",
      "train loss:7.527328868827658e-05\n",
      "train loss:0.0025160964882057313\n",
      "train loss:9.979021093977978e-06\n",
      "train loss:0.0013530651125704006\n",
      "train loss:5.615703313223502e-05\n",
      "train loss:5.477189189130559e-05\n",
      "train loss:0.0010216718485465718\n",
      "train loss:0.0015685668736768643\n",
      "train loss:1.3753568193873454e-05\n",
      "train loss:8.032482531491194e-05\n",
      "train loss:0.0025821900137160143\n",
      "train loss:0.000918325042377252\n",
      "train loss:0.000849959555784581\n",
      "train loss:0.0005579823797991516\n",
      "train loss:0.0004709686097323132\n",
      "train loss:0.00029462324831332497\n",
      "train loss:6.539890392871707e-05\n",
      "train loss:0.00011530280131099354\n",
      "train loss:0.0012935418969580903\n",
      "train loss:0.00321418406762989\n",
      "train loss:0.0031762528009228502\n",
      "train loss:0.00029822091808356216\n",
      "train loss:0.00043654125140046634\n",
      "train loss:6.195783984643597e-05\n",
      "train loss:0.0036164480715718977\n",
      "train loss:0.0001826775195307646\n",
      "train loss:0.00246660121593154\n",
      "train loss:0.0006266617361833027\n",
      "train loss:0.006460996961300811\n",
      "train loss:0.0003967560726161896\n",
      "train loss:0.0033844788265357867\n",
      "train loss:0.0001705692185482846\n",
      "train loss:0.0022111156023357195\n",
      "train loss:0.0038237175604162914\n",
      "train loss:0.0005611814777571297\n",
      "train loss:0.0011827476565548665\n",
      "train loss:3.154204352200467e-05\n",
      "train loss:9.931369819006638e-05\n",
      "train loss:0.002153323537556956\n",
      "train loss:0.00013303136729711715\n",
      "train loss:0.002263550161834096\n",
      "train loss:6.582147461303831e-06\n",
      "train loss:0.0011997326394843843\n",
      "train loss:0.0033926576340871316\n",
      "train loss:3.0242362902066555e-05\n",
      "train loss:3.0739171166975354e-05\n",
      "train loss:0.0002655173701271783\n",
      "train loss:0.01436744465289715\n",
      "train loss:0.006417411390242328\n",
      "train loss:0.00016741280950868876\n",
      "train loss:0.0019890370154480195\n",
      "train loss:0.0014084728540708301\n",
      "train loss:0.0005407948094351814\n",
      "train loss:0.0005756189779675438\n",
      "train loss:0.0004904496133582427\n",
      "train loss:0.0007745021900345459\n",
      "train loss:0.00023927871064459948\n",
      "train loss:0.0014364019039435566\n",
      "train loss:0.000508601876479144\n",
      "train loss:0.0004784906391697688\n",
      "train loss:0.0020439608064496584\n",
      "train loss:0.00020996875758721862\n",
      "train loss:0.00023150167648102512\n",
      "train loss:0.0007874889179887409\n",
      "train loss:0.0017058005283320469\n",
      "train loss:0.0004851194213799831\n",
      "train loss:0.0004897328205041679\n",
      "train loss:0.0008786686176281928\n",
      "train loss:0.00033311498231269513\n",
      "train loss:0.0006462804058502205\n",
      "train loss:0.0003682172224840008\n",
      "train loss:0.00032451927413217627\n",
      "train loss:0.0013193589763346467\n",
      "train loss:0.0008799940120472156\n",
      "train loss:3.580970782543242e-05\n",
      "train loss:0.0005736070501520137\n",
      "train loss:2.0102563686799313e-05\n",
      "train loss:0.0007468017188888451\n",
      "train loss:0.0005181237685640426\n",
      "train loss:6.189266159609484e-05\n",
      "train loss:7.73136753703302e-05\n",
      "train loss:0.00015498353695966998\n",
      "train loss:2.8319444240891843e-05\n",
      "train loss:0.00011157253436567926\n",
      "train loss:0.0006649807203791082\n",
      "train loss:4.7524858046250636e-05\n",
      "train loss:0.0007897786659916257\n",
      "train loss:0.0004876304115524579\n",
      "train loss:0.0032100299157416384\n",
      "train loss:0.0004063994972149772\n",
      "train loss:0.0005893259562264909\n",
      "train loss:0.0001807602973924639\n",
      "train loss:4.837459208571886e-05\n",
      "train loss:0.0003384166751816107\n",
      "train loss:3.6615443076938435e-05\n",
      "train loss:0.00033989985760887883\n",
      "train loss:0.0013132533986433734\n",
      "train loss:6.744598930369166e-05\n",
      "train loss:0.0015168142717014313\n",
      "train loss:7.73331669764482e-05\n",
      "train loss:6.349772818900294e-05\n",
      "train loss:0.005230891174046164\n",
      "train loss:0.0005716716814803111\n",
      "train loss:0.00029962623037054983\n",
      "train loss:0.00022528838994488346\n",
      "train loss:0.0014349438863864553\n",
      "train loss:0.0037015346666613986\n",
      "train loss:0.0014685238729114547\n",
      "train loss:0.0008955548217128115\n",
      "train loss:0.0015657729408931418\n",
      "train loss:0.00012683632512715015\n",
      "train loss:0.00029597331940572945\n",
      "train loss:0.00022620291745429816\n",
      "train loss:0.0014055520225716522\n",
      "train loss:0.00020046443364697377\n",
      "train loss:0.0026112600949053356\n",
      "train loss:0.006337753145440527\n",
      "train loss:0.004316342043685834\n",
      "train loss:0.0025422205340737717\n",
      "train loss:0.0041134537674853\n",
      "train loss:0.0038904902135535897\n",
      "train loss:0.0012019543934183028\n",
      "train loss:0.00028212659385220044\n",
      "train loss:0.0013312428798796525\n",
      "train loss:8.560680121303271e-05\n",
      "train loss:0.015594611384415293\n",
      "train loss:0.0003229764748534593\n",
      "train loss:0.02266311820987531\n",
      "train loss:0.004335761754862253\n",
      "train loss:0.00320464057784838\n",
      "train loss:0.005336543437466816\n",
      "train loss:0.00016749574456424759\n",
      "=== epoch:20, train acc:0.996, test acc:0.989 ===\n",
      "train loss:0.0004088545255952532\n",
      "train loss:0.0003117717151493882\n",
      "train loss:0.00029666309568748464\n",
      "train loss:0.0008931505672786023\n",
      "train loss:0.0002802931114315046\n",
      "train loss:0.000449807720904681\n",
      "train loss:0.0049830635256132546\n",
      "train loss:0.00018690888721907943\n",
      "train loss:0.00012365797401421737\n",
      "train loss:0.0035346704593464382\n",
      "train loss:0.009326073965128929\n",
      "train loss:0.0024924028573476125\n",
      "train loss:0.0022742597290098965\n",
      "train loss:0.0005340381532538986\n",
      "train loss:0.001647535389648127\n",
      "train loss:0.00024754158312135897\n",
      "train loss:2.5615522708100942e-05\n",
      "train loss:0.0003623091634830363\n",
      "train loss:0.0011539249785465471\n",
      "train loss:0.0008116095509140102\n",
      "train loss:0.0010534575350670146\n",
      "train loss:0.0010561135122263265\n",
      "train loss:0.027603402863355598\n",
      "train loss:0.0030103233043901317\n",
      "train loss:0.002928330349256696\n",
      "train loss:0.0009596346498254965\n",
      "train loss:0.0005601040403426195\n",
      "train loss:0.0006911169036124651\n",
      "train loss:0.005882936314300838\n",
      "train loss:0.0010609013980078577\n",
      "train loss:0.0006274213225915701\n",
      "train loss:0.00047936785620319305\n",
      "train loss:0.00014662786217531053\n",
      "train loss:0.023120666458613232\n",
      "train loss:0.0008757601082414711\n",
      "train loss:0.0015197658813622214\n",
      "train loss:0.002459010396498973\n",
      "train loss:0.00227920047185044\n",
      "train loss:0.0012074845816005598\n",
      "train loss:0.00033925101474790905\n",
      "train loss:0.00037250436665591647\n",
      "train loss:0.00367057749999254\n",
      "train loss:0.0029582127261058443\n",
      "train loss:0.00017832727873730758\n",
      "train loss:0.014969295621374277\n",
      "train loss:0.00026348337528525633\n",
      "train loss:0.0009213513335784397\n",
      "train loss:0.0004222342985422544\n",
      "train loss:0.0027595205929138067\n",
      "train loss:0.0006911956358096482\n",
      "train loss:0.000653584494930126\n",
      "train loss:0.0006847344714964662\n",
      "train loss:0.00739711561912652\n",
      "train loss:0.006009039263140228\n",
      "train loss:0.0034216779756753475\n",
      "train loss:0.00012796625029808852\n",
      "train loss:0.0016077242998513987\n",
      "train loss:0.0004275786674930546\n",
      "train loss:0.020774317993993638\n",
      "train loss:0.0024015807236369845\n",
      "train loss:0.00795512043748732\n",
      "train loss:0.002940949732457757\n",
      "train loss:0.0007175021361189999\n",
      "train loss:0.0017844077667305098\n",
      "train loss:0.0024775549984078758\n",
      "train loss:0.00021219480555067816\n",
      "train loss:0.003748162298470404\n",
      "train loss:0.0011593931901432123\n",
      "train loss:0.0005798633072482094\n",
      "train loss:0.0014568665676374024\n",
      "train loss:0.0022160927474433483\n",
      "train loss:0.00018503650199297512\n",
      "train loss:0.00010238879119082917\n",
      "train loss:0.004339996623776555\n",
      "train loss:0.00043825493968723455\n",
      "train loss:0.00012586950871183237\n",
      "train loss:0.0025825504634316406\n",
      "train loss:0.00018598154530300113\n",
      "train loss:0.003701201359142168\n",
      "train loss:0.0012021055232941994\n",
      "train loss:0.0069492985499427385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0012742151779330713\n",
      "train loss:0.00023909690718880224\n",
      "train loss:0.0007325239225870999\n",
      "train loss:8.735112214691508e-05\n",
      "train loss:0.001127720187059411\n",
      "train loss:0.0010081136765535703\n",
      "train loss:0.00103992068452995\n",
      "train loss:0.0004970726130745775\n",
      "train loss:0.003483102286078829\n",
      "train loss:0.0007780763963521059\n",
      "train loss:0.0010765568786518334\n",
      "train loss:0.0008319786714838206\n",
      "train loss:0.0002904083430580399\n",
      "train loss:0.0071638041690669915\n",
      "train loss:0.0017417824005970845\n",
      "train loss:0.003578028286624874\n",
      "train loss:0.0006618968113667907\n",
      "train loss:0.00046027079463626183\n",
      "train loss:0.0004615937412269508\n",
      "train loss:4.0421169889535936e-05\n",
      "train loss:8.882569505523765e-05\n",
      "train loss:0.0012927101797264515\n",
      "train loss:0.00040050546072082456\n",
      "train loss:0.0010758031846389206\n",
      "train loss:0.0009684534705088908\n",
      "train loss:0.004576283328976927\n",
      "train loss:0.001188809308362972\n",
      "train loss:0.006746142283223407\n",
      "train loss:0.0013156071270639177\n",
      "train loss:0.000994493319650513\n",
      "train loss:0.00021156702025859004\n",
      "train loss:0.0038569961836860274\n",
      "train loss:0.0007029830598650779\n",
      "train loss:0.00260369550230571\n",
      "train loss:0.00993923082174495\n",
      "train loss:0.0003275690392469016\n",
      "train loss:0.0008143956248878333\n",
      "train loss:0.0005842805444798376\n",
      "train loss:0.005087951799583056\n",
      "train loss:0.003500288303426596\n",
      "train loss:0.0005401461218231253\n",
      "train loss:0.0002208088881595979\n",
      "train loss:0.0021022864961274886\n",
      "train loss:0.002977350878045013\n",
      "train loss:0.0009184882675535587\n",
      "train loss:0.000329440293896794\n",
      "train loss:0.0004522416945272993\n",
      "train loss:0.0007722105588258306\n",
      "train loss:0.0019527218312788243\n",
      "train loss:2.8198054671140275e-05\n",
      "train loss:0.0008403845725493045\n",
      "train loss:0.003974953604421078\n",
      "train loss:0.0001930215723252398\n",
      "train loss:0.0014127974579169792\n",
      "train loss:0.008110135047509952\n",
      "train loss:0.0001105227711725088\n",
      "train loss:0.003966708893278304\n",
      "train loss:0.0015569027749962013\n",
      "train loss:0.00025554770043265574\n",
      "train loss:0.00032090236290770917\n",
      "train loss:0.0009290851177979854\n",
      "train loss:0.00038391384250588114\n",
      "train loss:0.00012018154372106193\n",
      "train loss:0.0017542390057778178\n",
      "train loss:0.0006475379526593212\n",
      "train loss:0.0020954589887073613\n",
      "train loss:0.0001856617159953817\n",
      "train loss:0.0003188237128787735\n",
      "train loss:0.001923535051943424\n",
      "train loss:0.0012182845298226211\n",
      "train loss:0.0012997463574121893\n",
      "train loss:0.0012908069512178849\n",
      "train loss:0.0024723986289456328\n",
      "train loss:0.0030244651668825647\n",
      "train loss:0.00023861195549364125\n",
      "train loss:0.0018023077635909038\n",
      "train loss:1.893492267827439e-05\n",
      "train loss:0.0012041575503465476\n",
      "train loss:3.5102217895692e-05\n",
      "train loss:0.00019105693688862608\n",
      "train loss:0.0005006362365097061\n",
      "train loss:0.00023999039489860843\n",
      "train loss:0.0007302185806914066\n",
      "train loss:0.000697372712604965\n",
      "train loss:0.00048242355156317675\n",
      "train loss:0.00027712256976738684\n",
      "train loss:7.19402044923023e-05\n",
      "train loss:0.0010532270576902216\n",
      "train loss:0.0013966916444067097\n",
      "train loss:0.001002608598282405\n",
      "train loss:0.0009253044621110019\n",
      "train loss:0.0010469694625117874\n",
      "train loss:0.01368164793669751\n",
      "train loss:0.0003265852264089222\n",
      "train loss:0.0005107551432951838\n",
      "train loss:0.0005080341799214576\n",
      "train loss:0.0005481263319055712\n",
      "train loss:0.005110898697416409\n",
      "train loss:0.0001877872954284247\n",
      "train loss:0.00041994654845516717\n",
      "train loss:0.0003745152115094289\n",
      "train loss:0.00022845798647859252\n",
      "train loss:0.00018263205652956706\n",
      "train loss:4.734062409641339e-05\n",
      "train loss:1.0580470498811776e-05\n",
      "train loss:5.247421408340194e-05\n",
      "train loss:0.0008890366822875287\n",
      "train loss:0.0009518844563308084\n",
      "train loss:0.007660791800787949\n",
      "train loss:0.003706930953090068\n",
      "train loss:2.903958749599113e-05\n",
      "train loss:0.0012469698956496956\n",
      "train loss:0.0033040830656565286\n",
      "train loss:0.00178331321584517\n",
      "train loss:0.0015910629102187121\n",
      "train loss:0.0004117817067768366\n",
      "train loss:4.1697743760752663e-05\n",
      "train loss:0.0006858746496278274\n",
      "train loss:2.755448974209608e-05\n",
      "train loss:5.472365029803337e-05\n",
      "train loss:7.212126034125553e-05\n",
      "train loss:0.0011887062605971874\n",
      "train loss:0.000512355117778241\n",
      "train loss:0.0006121785501528144\n",
      "train loss:0.0007568097915528289\n",
      "train loss:0.0005546549385046406\n",
      "train loss:0.00035885328841094575\n",
      "train loss:0.000324661683641193\n",
      "train loss:9.961298666844235e-05\n",
      "train loss:0.00011934269393027375\n",
      "train loss:0.001105323513485673\n",
      "train loss:4.08022103780661e-05\n",
      "train loss:0.0011551370974852433\n",
      "train loss:0.0001328911377590808\n",
      "train loss:0.0013154631645808346\n",
      "train loss:0.00015777285045462795\n",
      "train loss:7.745409043467571e-06\n",
      "train loss:0.0006684130634097359\n",
      "train loss:1.8359803338293787e-05\n",
      "train loss:0.0011787550777396646\n",
      "train loss:0.0006330134007442966\n",
      "train loss:0.0012702635951953734\n",
      "train loss:7.764608740405475e-05\n",
      "train loss:0.0006113723895092414\n",
      "train loss:0.0007083221941586013\n",
      "train loss:0.0008466168498618029\n",
      "train loss:0.005804563841691149\n",
      "train loss:0.0031771799262716952\n",
      "train loss:0.006263606178305082\n",
      "train loss:0.000664689633837821\n",
      "train loss:0.00027675905009573974\n",
      "train loss:0.0015137640107918968\n",
      "train loss:0.0004910579626042764\n",
      "train loss:0.001376737091134078\n",
      "train loss:0.0004982418834126684\n",
      "train loss:0.0010939728194725017\n",
      "train loss:0.001664177299245839\n",
      "train loss:0.00121254627693158\n",
      "train loss:0.002435381571109797\n",
      "train loss:0.001101737768729088\n",
      "train loss:0.0012939251759194806\n",
      "train loss:0.004329953318013971\n",
      "train loss:0.0018598524199384073\n",
      "train loss:0.004255584635475091\n",
      "train loss:0.0038406713282976824\n",
      "train loss:4.4514863729292706e-05\n",
      "train loss:0.001894530067056458\n",
      "train loss:0.0018347336979790297\n",
      "train loss:0.0001417837487637427\n",
      "train loss:0.0033807335303276957\n",
      "train loss:0.019193776738030837\n",
      "train loss:0.00048697700444249643\n",
      "train loss:0.0022085162109392303\n",
      "train loss:0.0025326780899602597\n",
      "train loss:0.0009573953473614158\n",
      "train loss:0.0015574534719321898\n",
      "train loss:0.0017484893003583632\n",
      "train loss:0.000373778607416294\n",
      "train loss:0.001579998551603139\n",
      "train loss:0.001313796196287826\n",
      "train loss:0.0028814870711305236\n",
      "train loss:0.010166604946756395\n",
      "train loss:0.0005224333038903607\n",
      "train loss:5.7250320994979657e-05\n",
      "train loss:0.0020391063743981108\n",
      "train loss:0.00010236115050424122\n",
      "train loss:0.00016119709223365297\n",
      "train loss:0.0005541585613397268\n",
      "train loss:0.00019714359699287773\n",
      "train loss:0.0008387654712844265\n",
      "train loss:3.888841200590731e-05\n",
      "train loss:0.0008843809200288508\n",
      "train loss:5.336313679396557e-05\n",
      "train loss:0.00023418659536769676\n",
      "train loss:0.002508336286644658\n",
      "train loss:3.4374172381361755e-05\n",
      "train loss:0.0010669414466785573\n",
      "train loss:0.0007850345302958423\n",
      "train loss:6.622789577378065e-05\n",
      "train loss:0.0013053684851988428\n",
      "train loss:0.004598410776580661\n",
      "train loss:0.0004484530190254986\n",
      "train loss:0.00010201501809092095\n",
      "train loss:0.0005943296593937749\n",
      "train loss:0.000465251511442904\n",
      "train loss:0.0012385045675573489\n",
      "train loss:0.00011386235176827869\n",
      "train loss:0.0005884320860652865\n",
      "train loss:0.0005468879110243766\n",
      "train loss:0.0006391144439593572\n",
      "train loss:0.00010081249808142281\n",
      "train loss:0.00015372682330263128\n",
      "train loss:0.0013988459140489194\n",
      "train loss:0.0020193210779770113\n",
      "train loss:0.00044933997683109473\n",
      "train loss:0.00018777181086563504\n",
      "train loss:0.0013908954607766096\n",
      "train loss:0.0009199420294416733\n",
      "train loss:0.0005255958240840762\n",
      "train loss:0.0004952462956674557\n",
      "train loss:3.9029527751964006e-05\n",
      "train loss:0.0010638200138117812\n",
      "train loss:0.00021679743355725367\n",
      "train loss:0.00019169353791645996\n",
      "train loss:0.0005005103788987525\n",
      "train loss:0.0006523592421492116\n",
      "train loss:0.00014407689452895276\n",
      "train loss:3.7232216341975074e-05\n",
      "train loss:2.0556806135513758e-05\n",
      "train loss:0.001150044600392638\n",
      "train loss:4.232599850943558e-05\n",
      "train loss:0.002220600262383592\n",
      "train loss:0.000636678806327886\n",
      "train loss:0.00091107216041449\n",
      "train loss:0.00025644923303550757\n",
      "train loss:0.0039012726601783\n",
      "train loss:0.0016000926857446859\n",
      "train loss:0.0006224497348300557\n",
      "train loss:0.0015321960375609452\n",
      "train loss:0.008097208916116112\n",
      "train loss:0.00030805649180330074\n",
      "train loss:1.959548696275835e-05\n",
      "train loss:3.5172537740865686e-05\n",
      "train loss:0.0030607523567726972\n",
      "train loss:0.001189400759274261\n",
      "train loss:0.00019536447373227003\n",
      "train loss:0.002574524718397467\n",
      "train loss:0.00018275527795369128\n",
      "train loss:3.8140813968715046e-05\n",
      "train loss:0.0025106812521159616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0003451454581782383\n",
      "train loss:0.006681399690689833\n",
      "train loss:0.0012179640472175955\n",
      "train loss:0.0002459623023888224\n",
      "train loss:0.0004771190926548511\n",
      "train loss:1.5701754266980807e-05\n",
      "train loss:2.9133923099086204e-05\n",
      "train loss:0.015199139150224042\n",
      "train loss:6.53609265165323e-05\n",
      "train loss:0.000548852436850413\n",
      "train loss:0.0001311744424194994\n",
      "train loss:0.00021753882044721462\n",
      "train loss:5.738072573196066e-05\n",
      "train loss:7.044523309458497e-05\n",
      "train loss:0.0004233093765749944\n",
      "train loss:0.0005626975498571566\n",
      "train loss:0.0010079301607436716\n",
      "train loss:8.161244998893075e-05\n",
      "train loss:0.002013070158286524\n",
      "train loss:0.0006389990848452237\n",
      "train loss:0.0005326881801308827\n",
      "train loss:0.002175273710511424\n",
      "train loss:8.9866463844552e-05\n",
      "train loss:0.0006928451228690165\n",
      "train loss:0.0013540569011185827\n",
      "train loss:0.004432682646205881\n",
      "train loss:4.0950567823995796e-05\n",
      "train loss:0.0005987271983831815\n",
      "train loss:0.0003384643069992738\n",
      "train loss:0.0012446928830557509\n",
      "train loss:0.0010381330619147159\n",
      "train loss:0.00181872590800362\n",
      "train loss:0.0007084469170934021\n",
      "train loss:0.0005564616747224127\n",
      "train loss:0.001245173671517794\n",
      "train loss:0.0011013807460428131\n",
      "train loss:0.0002645287579041579\n",
      "train loss:2.454603221978145e-05\n",
      "train loss:5.684604877544954e-05\n",
      "train loss:0.00028497173177053243\n",
      "train loss:0.0013077827220139618\n",
      "train loss:0.00041820639001543424\n",
      "train loss:0.0006998137457700656\n",
      "train loss:0.0009030783501515649\n",
      "train loss:0.0006309926497664612\n",
      "train loss:0.0022227928954825634\n",
      "train loss:0.0009857554472510715\n",
      "train loss:0.0009265427894461745\n",
      "train loss:4.552950833066657e-05\n",
      "train loss:0.0001786330173598012\n",
      "train loss:0.00018184067974362316\n",
      "train loss:0.00021119142996878682\n",
      "train loss:0.000380411300806468\n",
      "train loss:0.00021788595234208897\n",
      "train loss:0.0022176566503092207\n",
      "train loss:0.0007881921254623902\n",
      "train loss:0.00019934609451489421\n",
      "train loss:0.0008825262597379579\n",
      "train loss:0.0011084183515604157\n",
      "train loss:0.0006839645610910661\n",
      "train loss:0.000626664762388577\n",
      "train loss:0.0013563771073565533\n",
      "train loss:0.00044711814351791\n",
      "train loss:0.0011981647165934812\n",
      "train loss:0.00022829229763948495\n",
      "train loss:0.00046406708624959414\n",
      "train loss:3.859661181235431e-05\n",
      "train loss:0.0007853927567417975\n",
      "train loss:0.0015423840775509621\n",
      "train loss:0.06141456983702332\n",
      "train loss:0.0016158866790531433\n",
      "train loss:0.00023229650586410213\n",
      "train loss:0.0009143592660755353\n",
      "train loss:0.0011524305997565956\n",
      "train loss:0.0004374434233592865\n",
      "train loss:0.00010527071784046936\n",
      "train loss:0.0002539498054888089\n",
      "train loss:0.0028939038976238556\n",
      "train loss:0.00011362150664637914\n",
      "train loss:0.00024258011152752425\n",
      "train loss:0.0009333114945357913\n",
      "train loss:0.0004688151323524273\n",
      "train loss:0.00029781412496823723\n",
      "train loss:0.001556684009569561\n",
      "train loss:0.0007798845313637924\n",
      "train loss:0.0007779256259119509\n",
      "train loss:0.0006734015503505327\n",
      "train loss:0.0001560621680960468\n",
      "train loss:5.286785828036209e-05\n",
      "train loss:0.001591678727904971\n",
      "train loss:0.0002571375642849061\n",
      "train loss:0.0004559151878708019\n",
      "train loss:0.00038819013495558415\n",
      "train loss:4.4388317811837444e-05\n",
      "train loss:0.0013540573735903124\n",
      "train loss:4.8768893672851376e-05\n",
      "train loss:0.0033051217523698785\n",
      "train loss:9.744068342646385e-05\n",
      "train loss:0.00011746439879219232\n",
      "train loss:0.0010992928424612375\n",
      "train loss:0.00017370790564831537\n",
      "train loss:0.002805017839932492\n",
      "train loss:0.00013857137091272955\n",
      "train loss:1.691136814726871e-05\n",
      "train loss:0.00011297056931571633\n",
      "train loss:0.0011328639313934739\n",
      "train loss:0.001170311204226115\n",
      "train loss:0.000522913563079303\n",
      "train loss:0.0005138190848630506\n",
      "train loss:0.00029298124116444447\n",
      "train loss:0.001967311809560118\n",
      "train loss:9.694569473246497e-05\n",
      "train loss:0.0002778351926323421\n",
      "train loss:9.40455101725887e-05\n",
      "train loss:0.0006211827572943258\n",
      "train loss:5.263585290342885e-05\n",
      "train loss:0.0002362681365842624\n",
      "train loss:0.005166775702242839\n",
      "train loss:3.0690641260122266e-05\n",
      "train loss:0.00022585702463899594\n",
      "train loss:0.002747970874777183\n",
      "train loss:0.0025533882916733783\n",
      "train loss:5.411113021456969e-05\n",
      "train loss:3.2386412329803166e-05\n",
      "train loss:0.00013821127242458244\n",
      "train loss:1.2292263852106644e-05\n",
      "train loss:0.00025676609281621295\n",
      "train loss:6.60499424457892e-05\n",
      "train loss:0.00208246372645888\n",
      "train loss:0.00022641751085084836\n",
      "train loss:0.0013196199382317852\n",
      "train loss:4.0730472272554436e-05\n",
      "train loss:9.44573110959236e-05\n",
      "train loss:0.0007981380982792787\n",
      "train loss:0.000182322863478223\n",
      "train loss:0.0006855740095332546\n",
      "train loss:0.000544509688263291\n",
      "train loss:0.00032798284670897696\n",
      "train loss:6.660631515671872e-05\n",
      "train loss:6.728756305663092e-05\n",
      "train loss:9.112716113383629e-05\n",
      "train loss:0.0004977558171627608\n",
      "train loss:0.0004304576230836512\n",
      "train loss:0.0010098787793545378\n",
      "train loss:0.0013439463022214511\n",
      "train loss:0.0001099857437299509\n",
      "train loss:4.501645764031911e-05\n",
      "train loss:0.000929218757068978\n",
      "train loss:7.397589991939449e-05\n",
      "train loss:4.3933850655381334e-05\n",
      "train loss:0.01475330598420306\n",
      "train loss:3.529415539663121e-05\n",
      "train loss:0.0010093026227213408\n",
      "train loss:0.0010276932382211376\n",
      "train loss:0.0008431401743081382\n",
      "train loss:0.00011252569581371273\n",
      "train loss:0.00043927011589357876\n",
      "train loss:0.0002717437770989155\n",
      "train loss:0.0035593662815685385\n",
      "train loss:0.0013999290303670466\n",
      "train loss:0.002718990922525545\n",
      "train loss:0.00038726851350297714\n",
      "train loss:0.0003582652789014322\n",
      "train loss:0.007875081836461066\n",
      "train loss:0.00015377974433222985\n",
      "train loss:0.0007208052568919342\n",
      "train loss:5.461965123357752e-05\n",
      "train loss:0.0003053623091086232\n",
      "train loss:0.002960332564475447\n",
      "train loss:0.0005294187645524291\n",
      "train loss:0.0015857895347109708\n",
      "train loss:0.00012608728560478623\n",
      "train loss:5.579895191006832e-05\n",
      "train loss:0.0002179621019278059\n",
      "train loss:8.809341062484998e-05\n",
      "train loss:9.847510278842215e-05\n",
      "train loss:0.0015738309066237299\n",
      "train loss:0.000377417004738065\n",
      "train loss:0.0008557793605447557\n",
      "train loss:0.0011233668406445852\n",
      "train loss:0.0010422707100836632\n",
      "train loss:0.00045839647705507163\n",
      "train loss:3.1979594131892766e-05\n",
      "train loss:3.899352455281838e-05\n",
      "train loss:0.00041451681349819456\n",
      "train loss:0.00019943867296588993\n",
      "train loss:0.0006220474489769554\n",
      "train loss:7.449675656219652e-05\n",
      "train loss:5.142047685012003e-05\n",
      "train loss:0.00041460306090862205\n",
      "train loss:0.00013497155154583754\n",
      "train loss:8.675236119120458e-05\n",
      "train loss:0.00015590977756778495\n",
      "train loss:0.00026722124967397414\n",
      "train loss:7.091973589740108e-05\n",
      "train loss:0.00013899936315954936\n",
      "train loss:0.0012827620631545508\n",
      "train loss:0.0002686179436550612\n",
      "train loss:5.263124838310396e-05\n",
      "train loss:0.0012978510785919785\n",
      "train loss:0.0011567299952676665\n",
      "train loss:0.00030365070826210503\n",
      "train loss:0.0021631207259742596\n",
      "train loss:0.0009436452478790678\n",
      "train loss:0.0005585926196612505\n",
      "train loss:0.00047595504190622666\n",
      "train loss:6.776424144327008e-05\n",
      "train loss:4.482700362893697e-05\n",
      "train loss:6.249550933145547e-05\n",
      "train loss:1.1674233577140001e-05\n",
      "train loss:0.0022860832440748905\n",
      "train loss:0.00022059835043269061\n",
      "train loss:0.001401725267508752\n",
      "train loss:0.0010127069780017728\n",
      "train loss:0.0004441719147274779\n",
      "train loss:0.0012305804082973519\n",
      "train loss:0.0008684783069818215\n",
      "train loss:0.0019323888170065826\n",
      "train loss:1.1475776439757587e-05\n",
      "train loss:0.0008873697121873671\n",
      "train loss:0.0006348430878306981\n",
      "train loss:0.00011618146587125155\n",
      "train loss:1.2118635675333257e-05\n",
      "train loss:0.0008550567675949647\n",
      "train loss:1.810608065135317e-05\n",
      "train loss:7.64206119483486e-05\n",
      "train loss:0.0017155397022872376\n",
      "train loss:9.759337643503046e-05\n",
      "train loss:0.00034973494134959976\n",
      "train loss:9.815123295788827e-05\n",
      "train loss:0.00042388122373076295\n",
      "train loss:0.00017463596467481922\n",
      "train loss:0.0021271038627307267\n",
      "train loss:0.0002524611814917812\n",
      "train loss:0.00036144419855828493\n",
      "train loss:0.0008450438650240022\n",
      "train loss:0.0002937617305118847\n",
      "train loss:0.001272968143433911\n",
      "train loss:0.002145236001738941\n",
      "train loss:4.332827772797556e-05\n",
      "train loss:0.0002453219631476544\n",
      "train loss:0.0022770343064100703\n",
      "train loss:7.998251764130632e-05\n",
      "train loss:0.0002973947623443071\n",
      "train loss:0.0005373392559297471\n",
      "train loss:0.0004714284765860194\n",
      "train loss:0.0010420252608982963\n",
      "train loss:0.0001864017901649384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00012387798341173263\n",
      "train loss:0.0074510112164878324\n",
      "train loss:0.00011988752709244697\n",
      "train loss:0.00444067212322607\n",
      "train loss:0.0008456927250438643\n",
      "train loss:5.26964568384006e-05\n",
      "train loss:0.0030461832811188127\n",
      "train loss:1.1964958912687762e-05\n",
      "train loss:0.0004940863855632769\n",
      "train loss:0.0014801674677555547\n",
      "train loss:0.00031020284912166153\n",
      "train loss:0.0001298848801480761\n",
      "train loss:0.0002511358081243982\n",
      "train loss:0.0004311552842737761\n",
      "train loss:0.0008454286664269366\n",
      "train loss:0.00048827933023050667\n",
      "train loss:0.00021956788403726813\n",
      "train loss:0.0013437363908640212\n",
      "train loss:9.714463418573763e-05\n",
      "train loss:0.00044688568911892387\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.989\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 처리에 시간이 걸릴 때 데이터 일부로만 실행\n",
    "# x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "# x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
