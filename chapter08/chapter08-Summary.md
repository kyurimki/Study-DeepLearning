# Chapter 8. 딥러닝
## 8.1 더 깊게
- MNIST 데이터셋의 손글씨 숫자를 인식하는 CNN을 만들고자 한다.

### 8.1.1 더 깊은 신경망으로

![image](https://user-images.githubusercontent.com/61455647/116556947-f6deee80-a938-11eb-8ba6-bfbbaefbaafc.png)

- 이 신경망의 특징
	- 3*3의 작은 필터를 사용
	- 층이 깊어지면서 채널 수가 늘어난다.
	- 풀링 계층으로 중간 데이터의 공간 크기를 줄인다.
	- 활성화 함수는 ReLU
	- 완전연결 계층 뒤에 드롭아웃 계층 사용
	- Adam으로 최적화
	- 가중치 초기값은 He의 초기값
- 이 신경망의 정확도는 99.38%이다.
- 아래는 인식에 실패한 예: 인간도 판단하기 어려움

![image](https://user-images.githubusercontent.com/61455647/116558036-fd219a80-a939-11eb-8800-a0e8eb01dd79.png)

### 8.1.2 정확도를 높이려면
- **데이터 확장 data augmentation**
	- 입력 이미지(훈련 이미지)를 알고리즘을 동원해 인위적으로 확장
	- 입력 이미지에 미세한 변화를 주어 이미지의 개수를 늘리는 것, 데이터 개수가 적을 때 효과적
	- crop: 이미지 일부를 잘라냄
	- flip: 좌우를 뒤집음(이미지의 대칭성을 고려하지 않아도 되는 경우에만 가능)
	- 외형 변화나 스케일 변화
- 데이터 확장으로 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝의 인식 수준을 개선할 수 있다.

### 8.1.3 깊게 하는 이유
- 층의 깊이에 비례해 정확도가 높아진다.
- **신경망의 매개변수 수가 줄어든다.**: 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은 수준의 표현력을 달성할 수 있다.

![image](https://user-images.githubusercontent.com/61455647/116560208-204d4980-a93c-11eb-80fd-4a78b0deefbb.png)

- 위의 예처럼 5*5의 합성곱 연산 1회는 3\*3의 합성곱 연산 2회를 수행해 대체할 수 있다.
	- 매개변수의 수는 전자는 5*5=25, 후자는 2\*3\*3=18개 -> 매개변수 수는 층을 반복할수록 적어지고, 그 차이는 층이 깊어질수록 커진다.
- **학습의 효율성이 높아진다.**
	- 층을 깊게 해 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다.
	- ex. 개를 인식하는 문제
		- 얕은 신경망: 개의 특징 대부분은 한 번에 이해해야 한다.
		- 깊은 신경망: 학습해야 할 문제를 계층적으로 분해할 수 있음 -> 각 층이 학습해야 할 문제를 더 단순한 문제로 대체
	- 정보를 계층적으로 전달할 수 있다. <=> 층을 깊게 해 각 층이 학습해야 할 문제를 '풀기 쉬운 단순한 문제'로 분해할 수 있어 효율적으로 학습할 수 있다.

## 8.2 딥러닝의 초기 역사
- 딥러닝이 주목 받게 된 계기는 ILSVRC(ImageNet Large Scale Visual Recognition Challenge) 2012년 대회

### 8.2.1 이미지넷(ImageNet)
- 100만 장이 넘는 이미지를 담고 있는 데이터셋
- 다양한 종류의 이미지를 포함, 각 이미지에는 레이블(클래스 이름) 이 붙어 있음
- ILSVRC 대회의 시험 항목 중 1000개 클래스 **분류**가 있음
- 아래 그래프는 ILSVRC 분류 부문 우승팀 성적 중 top-5 error를 막대 그래프로 나타낸 것.
	- top-5 error: 확률이 가장 높다고 생각하는 후보 클래스 5개 안에 정답이 포함되지 않은 비율

![image](https://user-images.githubusercontent.com/61455647/116565286-aec3ca00-a940-11eb-954b-4895e30bc6d5.png)

- 2012년 이후 선두는 항상 딥러닝 방식

### 8.2.2 VGG

![image](https://user-images.githubusercontent.com/61455647/116565916-3f020f00-a941-11eb-84cd-223ce2fa8fce.png)

- 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN
- 비중 있는 층(합성곱 계층과 완전연결 계층)을 16층(or 19층)으로 심화(층의 깊이에 따라 VGG16, VGG19로 구분)
- 3*3의 작은 필터를 사용한 합성곱 계층을 연속으로 거침
- 합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리 반복
- 마지막에는 완전연결 계층을 통과시켜 결과 출력

### 8.2.3 GoogLeNet

![image](https://user-images.githubusercontent.com/61455647/116566147-7670bb80-a941-11eb-8030-df38f3215d87.png)

- 세로 방향 깊이뿐 아니라 가로 방향도 깊음
- **인셉션 구조**
	- 가로 방향에 폭이 있음
	- 크기가 다른 필터와 풀링을 여러 개 적용해 결과 결합
- 인셉션 구조를 하나의 빌딩 블록으로 사용
- 1*1 크기의 필터를 사용한 합성곱 계층이 많은 곳에 사용
	- 1*1의 합성곱 연산 = 채널 쪽으로 크기를 줄임 -> 매개변수 제거화 고속 처리에 기여

![image](https://user-images.githubusercontent.com/61455647/116567093-470e7e80-a942-11eb-826a-5a8db312bc34.png)

### 8.2.4 ResNet(Residual Network)
- 마이크로소프트의 팀이 개발
- 딥러닝의 학습에 층이 지나치게 깊으면 학습이 잘 되지 않고, 성능이 떨어지는 경우도 있음
- **스킵 연결 skip connection**
	- 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조 -> *F(x)* 가 *F(x)+x* 가 됨
	- 입력 데이터를 그대로 흘림
	- 역전파 때 신호 감쇠를 막아줌 -> 효율적인 학습

![image](https://user-images.githubusercontent.com/61455647/116568146-34e11000-a943-11eb-90fc-59ca961c5474.png)

- VGG 신경망을 기반에 스킵 연결로 층을 깊게 함.

![image](https://user-images.githubusercontent.com/61455647/116568571-8b4e4e80-a943-11eb-92dd-7a8003318eca.png)

- 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 함
- 150층 이상으로 해도 정확도가 오름

## 8.3 더 빠르게(딥러닝 고속화)
### 8.3.1 풀어야 할 숙제
- AlexNet의 forward 처리(순전파)에서 각 층이 소비하는 시간
	- 합성곱 계층의 처리 시간: GPU=95%, CPU=89%

![image](https://user-images.githubusercontent.com/61455647/116569161-14658580-a944-11eb-8356-dad45e9b171c.png)

- 합성곱 계층에서 이뤄지는 연산을 어떻게 고속으로 효율적으로 처리하느냐가 딥러닝의 과제

### 8.3.2 GPU를 활용한 고속화
- **GPU 컴퓨팅**: GPU로 범용 수치 연산을 수행하는 것
	- 목적: GPU는 병렬 수치 연산을 고속으로 처리할 수 있으니 다양한 용도로 활용하자.
- 대량의 단일 곱셈-누산(or 큰 행렬의 곱) 수행
- CPU에 비해 GPU로 빠른 결과를 얻을 수 있음(40여 일 vs. 6일)
- 딥러닝에 NVIDIA의 GPU가 AMD보다 좀 더 유리: CUDA를 통해 cuDNN 라이브러리를 사용할 수 있기 때문

### 8.3.3 분산 학습
- 심층 신경망 학습에 오랜 시간이 걸리기 때문에, 1회 학습에 걸리는 시간을 최대한 단축하고 싶음
- **수평 확장 scale out**(= 분산 학습): 다수의 GPU와 기기로 계산 분산
	- ex. 구글의 텐서플로, MS의 CNTK(Computational Network Toolkit)

### 8.3.4 연산 정밀도와 비트 줄이기
- 계산 능력 외에 메모리 용량과 버스 대역폭이 고속화의 병목이 될 수 있음
	- 메모리 용량 면: 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장
	- 버스 대역폭 면: GPU나 CPU의 버스에 흐르는 데이터가 많아져 한계 이상이면 병목 발생
- -> 네트워크로 주고받는 데이터의 비트 수를 최소로 만들어야 함
- 많은 비트를 사용할수록 계산의 오차는 줄지만, 계산에 드는 비용과 메모리 사용량이 늘고 버스 대역폭에 부담
- 딥러닝은 높은 수치 정밀도(수치를 몇 비트로 표현하는가)를 요구 X ∵ 신경망의 견고성
- -> 16비트의 반정밀도(half-precision)이어도 학습에 문제 X

## 8.4 딥러닝의 활용
- 딥러닝은 사물 인식뿐 아니라 많은 문제에 적용 가능
### 8.4.1 사물 검출
- 이미지 속에 담긴 사물의 위치와 종류(클래스)를 알아내는 기술
- 이미지 어딘가에 있을 사물의 위치까지 알아내야 하기 때문에 사물 인식보다 어려움

![image](https://user-images.githubusercontent.com/61455647/116574396-a2dc0600-a948-11eb-93f6-3e3374565b67.png)

- **R-CNN**(Regions with Convolutional Neural Network)
	- 2. 후보 영역 추출-3. CNN 특징 계산: 사물이 위치한 영역을 찾아내고, 추출한 각 영역에 CNN을 적용해 클래스 분류
	- 후보 영역 추출에 컴퓨터 비전의 다양한 기법을 사용할 수 있음. R-CNN에서는 Selective Search 기법이 사용됨.
	- 후보 영역 추출까지 CNN으로 처리하는 Faster R-CNN 기법도 등장함.

### 8.4.2 분할(Segmentation)
- 이미지를 픽셀 수준에서 분류
- 픽셀 단위로 객체마다 채색된 지도(supervised) 데이터를 사용해 학습 -> 추론 단계에서 입력 이미지의 모든 픽셀 분류
- 모든 픽셀 대상으로 하나씩 추론 작업 실행 -> 픽셀의 수만큼 forward 처리가 필요해 긴 시간 소요 -> FCN 고안
- FCN(Fully Convolutional Network)
	- 한 번의 forward 처리로 모든 픽셀의 클래스 분류
	- = 합성곱 계층만으로 구성된 네트워크
	- 완전연결 계층을 같은 기능을 하는 합성곱 계층으로 바꿈 -> 공간 볼륨을 마지막까지 유지
	- 마지막에 공간 크기를 확대하는 처리 도입
		- 줄어둔 중간 데이터를 입력 이미지와 같은 크기로 확대할 수 있음
		- 이중 선형 보간(bilinear interpolation)에 의한 선형 확대 by 역합성곱(deconvolution) 연산

### 8.4.3 사진 캡션 생성
- 컴퓨터 비전 + 자연어
- 사진을 입력하면 사진을 설명하는 글(사진 캡션)을 자동으로 생성
- NIC(Neural Image Caption) 모델
	- 심층 CNN + 자연어를 다루는 순환 신경망(Recurrent Neural Network, RNN)으로 구성
		- RNN: 순환적 관계를 갖는 신경망, 연속된 데이터를 다룰 때 많이 사용
	- CNN으로 사진에서 특징 추출 -> RNN에서 추출된 특징을 초기값으로 텍스트를 순환적으로 생성
- 멀티모달 처리(multimodal processing): 여러 종류의 정보를 조합하고 처리하는 것

## 8.5 딥러닝의 미래
### 8.5.1 이미지 스타일(화풍) 변환
- 두 이미지(콘텐츠 이미지+스타일 이미지)를 입력해 새로운 그림을 생성하는 연구
- 네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습 -> 입력 이미지를 콘텐츠 이미지 형태로 흉내
- 스타일 행렬 도입 -> 스타일 이미지의 화풍 흡수 -> 스타일 행렬의 오차를 줄이도록 학습

### 8.5.2 이미지 생성
- 학습 후 입력 이미지 없이 새로운 이미지를 그려내는 연구
- DCGAN(Deep Convolutional Generative Adversarial Network) 기법
	- 이미지를 생성하는 과정을 모델화
	- 모델을 대량의 이미지를 사용해 학습 -> 모델을 이용해 새로운 그림 생성
	- 생성자와 식별자 2개의 신경망 이용
		- 생성자(Generator): 진짜와 똑같은 이미지 생성
		- 식별자(Discriminator): 생성자가 생성한 이미지인지, 아니면 실제로 촬영된 이미지인지 판정
	- 생성자와 식별자를 겨루도록 학습시켜 생성자는 더 정교한 가짜 이미지 생성 기술을 학습, 식별자는 더 정확하게 판정할 수 있도록 발전 -> GAN(Generative Adversarial Network) 기술

### 8.5.3 자율 주행
- 주위 환경을 올바르게 인식하는 기술이 가장 중요
- SegNet
	- CNN 기반 신경망
	- 주변 환경을 정확하게 인식해냄
	- 입력 이미지를 분할해 픽셀 수준에서 판정

### 8.5.4 Deep Q-Network(강화학습)
- **강화학습**(Reinforcement Learning)
	- 시행착오 과정에서 스스로 학습하게 하려는 분야
	- 에이전트는 환경에 맞게 행동을 선택하고, 그 행동에 의해 환경이 변한다.
	- 환경이 변화하면 에이전트는 보상을 얻음 -> 더 나은 보상을 받는 쪽으로 에이전트의 행동 지침을 바로잡는 것
	- 보상은 정해진 것이 아니라 '예정 보상'임

![image](https://user-images.githubusercontent.com/61455647/116578528-7924de00-a94c-11eb-83f9-f7ae41819b56.png)

- **Deep Q-Network**(DQN)
	- Q학습이라는 강화학습 알고리즘을 기초로 함
		- Q학습: 최적 행동 가치 함수로 최적인 행동을 정함
	- 비디오 게임 자율 학습
		- INPUT: 게임 영상 프레임(4개 연속한 프레임)
		- OUTPUT: 게임을 제어하는 움직임에 대해 각 동작의 가치

![image](https://user-images.githubusercontent.com/61455647/116579200-1e3fb680-a94d-11eb-850b-d2ab63516105.png)
